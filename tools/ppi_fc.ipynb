{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ROI: LO, Hemisphere: left\n",
      "Both FC and PPI files exist for LO left. Skipping...\n",
      "Processing ROI: LO, Hemisphere: right\n",
      "Both FC and PPI files exist for LO right. Skipping...\n",
      "Processing ROI: pIPS, Hemisphere: left\n",
      "Both FC and PPI files exist for pIPS left. Skipping...\n",
      "Processing ROI: pIPS, Hemisphere: right\n",
      "Processing run combination: [1, 2]\n",
      "Saved FC result for pIPS right\n",
      "Saved PPI result for pIPS right\n"
     ]
    }
   ],
   "source": [
    "# runs 2nd level analyses for PPI and FC\n",
    "import sys\n",
    "sys.path.insert(0, '/user_data/csimmon2/git_repos/ptoc')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import gc\n",
    "from nilearn import image, input_data\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import warnings\n",
    "import ptoc_params as params\n",
    "import argparse\n",
    "\n",
    "raw_dir = params.raw_dir\n",
    "results_dir = params.results_dir\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up run combinations like obj script\n",
    "run_num = 2  # Adjust based on your data\n",
    "runs = list(range(1, run_num + 1))\n",
    "run_combos = [[rn1, rn2] for rn1 in range(1, run_num + 1) \n",
    "              for rn2 in range(rn1 + 1, run_num + 1)]\n",
    "tr = 1\n",
    "vols = 341\n",
    "\n",
    "def extract_roi_timeseries(img, roi_mask, hemisphere='left'):\n",
    "    \"\"\"Extract ROI timeseries using parcels and hemisphere masking.\"\"\"\n",
    "    roi_data = roi_mask.get_fdata()\n",
    "    mid_x = roi_data.shape[0] // 2\n",
    "    \n",
    "    hemi_mask = np.zeros_like(roi_data)\n",
    "    if hemisphere == 'left':\n",
    "        hemi_mask[:mid_x, :, :] = 1\n",
    "    else:\n",
    "        hemi_mask[mid_x:, :, :] = 1\n",
    "    \n",
    "    combined_mask = roi_data * hemi_mask\n",
    "    mask_img = nib.Nifti1Image(combined_mask, roi_mask.affine)\n",
    "    \n",
    "    roi_masker = input_data.NiftiMasker(mask_img, standardize=True)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    return np.mean(seed_time_series, axis=1).reshape(-1, 1)\n",
    "\n",
    "def make_psy_cov(runs, ss, temp_dir):\n",
    "    \"\"\"Create psychological covariates for specified runs.\"\"\"\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    times = np.arange(0, vols * len(runs), tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for run in runs:\n",
    "        ss_num = ss.split('-')[1].replace('spaceloc', '')\n",
    "        tool_cov_file = f'{cov_dir}/ToolLoc_spaceloc{ss_num}_run{run}_tool.txt'\n",
    "        nontool_cov_file = f'{cov_dir}/ToolLoc_spaceloc{ss_num}_run{run}_non_tool.txt'\n",
    "\n",
    "        if os.path.exists(tool_cov_file) and os.path.exists(nontool_cov_file):\n",
    "            tool_cov = pd.read_csv(tool_cov_file, sep='\\t', header=None, \n",
    "                                 names=['onset', 'duration', 'value'])\n",
    "            nontool_cov = pd.read_csv(nontool_cov_file, sep='\\t', header=None, \n",
    "                                    names=['onset', 'duration', 'value'])\n",
    "            nontool_cov['value'] *= -1\n",
    "\n",
    "            # Adjust onsets for concatenated runs\n",
    "            run_offset = vols * runs.index(run)\n",
    "            tool_cov['onset'] += run_offset\n",
    "            nontool_cov['onset'] += run_offset\n",
    "            \n",
    "            full_cov = pd.concat([full_cov, tool_cov, nontool_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset'])\n",
    "    cov = full_cov.to_numpy()\n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    return psy\n",
    "\n",
    "def conduct_analyses(sub, rois=['LO', 'pIPS']):\n",
    "    import glob  # Add at top\n",
    "    \n",
    "    temp_dir = f'{raw_dir}/{sub}/ses-01/derivatives/fsl/toolloc'\n",
    "    roi_dir = f'{raw_dir}/{sub}/ses-01/derivatives/rois'\n",
    "    out_dir = f'/user_data/csimmon2/temp_derivatives/{sub}/ses-01/derivatives'\n",
    "    os.makedirs(f'{out_dir}/fc', exist_ok=True)\n",
    "    \n",
    "    mask_path = f'{raw_dir}/{sub}/ses-01/anat/{sub}_ses-01_T1w_brain_mask.nii.gz'\n",
    "    whole_brain_mask = nib.load(mask_path)\n",
    "    brain_masker = input_data.NiftiMasker(whole_brain_mask, standardize=True)\n",
    "\n",
    "    run_combos = [[rn1, rn2] for rn1 in range(1, run_num + 1) \n",
    "                  for rn2 in range(rn1 + 1, run_num + 1)]\n",
    "\n",
    "    for rr in rois:\n",
    "        roi_path = f'{roi_dir}/parcels/{rr}.nii.gz'\n",
    "        roi_img = nib.load(roi_path)\n",
    "        \n",
    "        for hemi in ['left', 'right']:\n",
    "            print(f\"Processing ROI: {rr}, Hemisphere: {hemi}\")\n",
    "            \n",
    "            fc_file = f'{out_dir}/fc/{sub}_{rr}_{hemi}_toolloc_fc_native.nii.gz'\n",
    "            ppi_file = f'{out_dir}/fc/{sub}_{rr}_{hemi}_toolloc_ppi_native.nii.gz'\n",
    "            \n",
    "            do_fc = not os.path.exists(fc_file)\n",
    "            do_ppi = not os.path.exists(ppi_file)\n",
    "            \n",
    "            if not do_fc and not do_ppi:\n",
    "                print(f'Both FC and PPI files exist for {rr} {hemi}. Skipping...')\n",
    "                continue\n",
    "            \n",
    "            for rc in run_combos:\n",
    "                print(f\"Processing run combination: {rc}\")\n",
    "                \n",
    "                filtered_list = []\n",
    "                for run in rc:\n",
    "                    curr_run = image.load_img(\n",
    "                        f'{temp_dir}/run-0{run}/1stLevel.feat/filtered_func_data_reg.nii.gz')\n",
    "                    curr_run = image.clean_img(curr_run, standardize=True)\n",
    "                    filtered_list.append(curr_run)\n",
    "\n",
    "                img4d = image.concat_imgs(filtered_list)\n",
    "                phys = extract_roi_timeseries(img4d, roi_img, hemisphere=hemi)\n",
    "                brain_time_series = brain_masker.fit_transform(img4d)\n",
    "                \n",
    "                if do_fc:\n",
    "                    correlations = np.dot(brain_time_series.T, phys) / phys.shape[0]\n",
    "                    correlations = np.arctanh(correlations)\n",
    "                    correlations = correlations.reshape(1, -1)\n",
    "                    correlation_img = brain_masker.inverse_transform(correlations)\n",
    "                    temp_fc_file = f'{out_dir}/fc/{sub}_{rr}_{hemi}_run{rc[0]}{rc[1]}_fc_temp.nii.gz'\n",
    "                    nib.save(correlation_img, temp_fc_file)\n",
    "                \n",
    "                if do_ppi:\n",
    "                    psy = make_psy_cov(rc, sub, f'{raw_dir}/{sub}/ses-01')\n",
    "                    \n",
    "                    min_length = min(psy.shape[0], phys.shape[0])\n",
    "                    psy = psy[:min_length]\n",
    "                    phys = phys[:min_length]\n",
    "                    brain_time_series = brain_time_series[:min_length]\n",
    "                    \n",
    "                    ppi = psy * phys\n",
    "                    correlations = np.dot(brain_time_series.T, ppi) / ppi.shape[0]\n",
    "                    correlations = np.arctanh(correlations)\n",
    "                    correlations = correlations.reshape(1, -1)\n",
    "                    correlation_img = brain_masker.inverse_transform(correlations)\n",
    "                    temp_ppi_file = f'{out_dir}/fc/{sub}_{rr}_{hemi}_run{rc[0]}{rc[1]}_ppi_temp.nii.gz'\n",
    "                    nib.save(correlation_img, temp_ppi_file)\n",
    "                \n",
    "                del img4d, phys, brain_time_series, correlations, correlation_img\n",
    "                if 'ppi' in locals(): del ppi\n",
    "                gc.collect()\n",
    "            \n",
    "            # After processing all run combinations, average temp files\n",
    "            if do_fc:\n",
    "                temp_fc_files = sorted(glob.glob(f'{out_dir}/fc/{sub}_{rr}_{hemi}_run*_fc_temp.nii.gz'))\n",
    "                mean_fc = image.mean_img(temp_fc_files)\n",
    "                nib.save(mean_fc, fc_file)\n",
    "                for f in temp_fc_files: os.remove(f)\n",
    "                print(f'Saved FC result for {rr} {hemi}')\n",
    "            \n",
    "            if do_ppi:\n",
    "                temp_ppi_files = sorted(glob.glob(f'{out_dir}/fc/{sub}_{rr}_{hemi}_run*_ppi_temp.nii.gz'))\n",
    "                mean_ppi = image.mean_img(temp_ppi_files)\n",
    "                nib.save(mean_ppi, ppi_file)\n",
    "                for f in temp_ppi_files: os.remove(f)\n",
    "                print(f'Saved PPI result for {rr} {hemi}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rois = ['LO', 'pIPS']\n",
    "    sub = 'sub-spaceloc1007'\n",
    "    conduct_analyses(sub, rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used by Python: 0.06 GB\n",
      "Total system memory used: 3.5%\n"
     ]
    }
   ],
   "source": [
    "# check memory usage\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "print(f\"Memory used by Python: {process.memory_info().rss / 1024**3:.2f} GB\")\n",
    "print(f\"Total system memory used: {psutil.virtual_memory().percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                 1\n",
      "task            ToolLoc\n",
      "roi               raIPS\n",
      "hemisphere            r\n",
      "x             21.764348\n",
      "y            -49.382429\n",
      "z             54.596119\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded: '/lab_data/behrmannlab/vlad/hemispace/sub-spaceloc1007/ses-01/derivatives/rois/spheres/sphere_coords.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mprint\u001b[39m(curr_coords)\n\u001b[1;32m     46\u001b[0m         roi_coords\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi_dir\u001b[38;5;241m.\u001b[39mformat(sub\u001b[38;5;241m=\u001b[39mss)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/spheres/sphere_coords.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mextract_roi_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[83], line 46\u001b[0m, in \u001b[0;36mextract_roi_coords\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m                 roi_coords \u001b[38;5;241m=\u001b[39m roi_coords\u001b[38;5;241m.\u001b[39mappend(curr_coords, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(curr_coords)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mroi_coords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroi_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/spheres/sphere_coords.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/core/generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3718\u001b[0m )\n\u001b[0;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/io/formats/format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1188\u001b[0m )\n\u001b[0;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded: '/lab_data/behrmannlab/vlad/hemispace/sub-spaceloc1007/ses-01/derivatives/rois/spheres/sphere_coords.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nilearn import image, plotting\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import ptoc_params as params\n",
    "\n",
    "\n",
    "# Set directories\n",
    "raw_dir = params.raw_dir\n",
    "sub_dir = '/user_data/csimmon2/temp_derivatives/{sub}/ses-01'\n",
    "roi_dir = os.path.join(raw_dir, '{sub}/ses-01/derivatives/rois')\n",
    "parcel_dir = os.path.join(raw_dir, '{sub}/ses-01/derivatives/rois/parcels')\n",
    "subs = ['sub-spaceloc1007', 'sub-spaceloc1008', 'sub-spaceloc1009', 'sub-spaceloc1010', 'sub-spaceloc1011']\n",
    "\n",
    "\n",
    "# Define parcels\n",
    "parcels = ['pIPS', 'LO', 'PFS', 'aIPS']\n",
    "run_combos = [[1, 2], [2, 1]]\n",
    "\n",
    "def extract_roi_coords():\n",
    "    roi_coords = pd.DataFrame(columns=['index', 'task', 'roi', 'hemisphere', 'x', 'y', 'z'])\n",
    "\n",
    "    for ss in subs:\n",
    "        os.makedirs(f\"{sub_dir.format(sub=ss)}/spheres\", exist_ok=True)\n",
    "\n",
    "        for rcn, rc in enumerate(run_combos):\n",
    "            for run_num in rc:\n",
    "                all_runs = [image.load_img(f\"{sub_dir.format(sub=ss)}/derivatives/stats/zstat3_reg_run{run_num}.nii.gz\")]\n",
    "                mean_zstat = image.mean_img(all_runs)\n",
    "                affine = mean_zstat.affine\n",
    "\n",
    "                # Process each parcel\n",
    "                for pr in parcels:\n",
    "                    roi = image.load_img(f\"{parcel_dir.format(sub=ss)}/{pr}.nii.gz\")\n",
    "                    roi = image.math_img('img > 0', img=roi)\n",
    "\n",
    "                    coords = plotting.find_xyz_cut_coords(mean_zstat, mask_img=roi, activation_threshold=0.99)\n",
    "                    masked_stat = image.math_img('img1 * img2', img1=roi, img2=mean_zstat)\n",
    "                    np_coords = np.where(image.get_data(masked_stat) == np.max(image.get_data(masked_stat)))\n",
    "\n",
    "                    for lr in ['l', 'r']:\n",
    "                        curr_coords = pd.Series([rcn, 'ToolLoc', f\"{lr}{pr}\", lr] + list(coords), index=roi_coords.columns)\n",
    "                        roi_coords = roi_coords.append(curr_coords, ignore_index=True)\n",
    "        print(curr_coords)\n",
    "        roi_coords.to_csv(f\"{roi_dir.format(sub=ss)}/spheres/sphere_coords.csv\", index=False)\n",
    "\n",
    "extract_roi_coords()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
