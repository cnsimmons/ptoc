{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: sub-spaceloc1001\n",
      "Processing ROI: LO, Hemisphere: left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csimmon2/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/image/image.py:211: UserWarning: The parameter 'fwhm' for smoothing is specified as 0. Setting it to None (no smoothing will be performed)\n",
      "  warnings.warn(\"The parameter 'fwhm' for smoothing is specified \"\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 32.5 GiB for an array with shape (208, 240, 256, 682) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 182\u001b[0m\n\u001b[1;32m    179\u001b[0m rois \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mLO\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpIPS\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    181\u001b[0m \u001b[39m# Run the analysis\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m conduct_analyses(study_dir, raw_dir, subs, rois, run_num\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[2], line 144\u001b[0m, in \u001b[0;36mconduct_analyses\u001b[0;34m(study_dir, raw_dir, subs, rois, run_num)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m# Extract ROI time series\u001b[39;00m\n\u001b[1;32m    143\u001b[0m phys, _ \u001b[39m=\u001b[39m extract_roi_timeseries(img4d, roi_img, hemisphere\u001b[39m=\u001b[39mhemi)\n\u001b[0;32m--> 144\u001b[0m brain_time_series \u001b[39m=\u001b[39m brain_masker\u001b[39m.\u001b[39;49mfit_transform(img4d)\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m do_fc:\n\u001b[1;32m    147\u001b[0m     \u001b[39m# FC Analysis\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     correlations \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(brain_time_series\u001b[39m.\u001b[39mT, phys) \u001b[39m/\u001b[39m phys\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/maskers/base_masker.py:289\u001b[0m, in \u001b[0;36mBaseMasker.fit_transform\u001b[0;34m(self, X, y, confounds, sample_mask, **fit_params)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params\n\u001b[1;32m    286\u001b[0m                         )\u001b[39m.\u001b[39mtransform(X, confounds\u001b[39m=\u001b[39mconfounds,\n\u001b[1;32m    287\u001b[0m                                     sample_mask\u001b[39m=\u001b[39msample_mask)\n\u001b[1;32m    288\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X,\n\u001b[1;32m    290\u001b[0m                                                 confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[1;32m    291\u001b[0m                                                 sample_mask\u001b[39m=\u001b[39;49msample_mask\n\u001b[1;32m    292\u001b[0m                                                 )\n\u001b[1;32m    293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask_img \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/maskers/base_masker.py:233\u001b[0m, in \u001b[0;36mBaseMasker.transform\u001b[0;34m(self, imgs, confounds, sample_mask)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fitted()\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m confounds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhigh_variance_confounds:\n\u001b[0;32m--> 233\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_single_imgs(imgs,\n\u001b[1;32m    234\u001b[0m                                       confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[1;32m    235\u001b[0m                                       sample_mask\u001b[39m=\u001b[39;49msample_mask)\n\u001b[1;32m    237\u001b[0m \u001b[39m# Compute high variance confounds if requested\u001b[39;00m\n\u001b[1;32m    238\u001b[0m all_confounds \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:570\u001b[0m, in \u001b[0;36mNiftiMasker.transform_single_imgs\u001b[0;34m(self, imgs, confounds, sample_mask, copy)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39m# Ignore the mask-computing params: they are not useful and will\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39m# just invalid the cache for no good reason\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m# target_shape and target_affine are conveyed implicitly in mask_img\u001b[39;00m\n\u001b[1;32m    558\u001b[0m params \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mclass_inspect\u001b[39m.\u001b[39mget_params(\n\u001b[1;32m    559\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m,\n\u001b[1;32m    560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m     ],\n\u001b[1;32m    568\u001b[0m )\n\u001b[0;32m--> 570\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache(\n\u001b[1;32m    571\u001b[0m     _filter_and_mask,\n\u001b[1;32m    572\u001b[0m     ignore\u001b[39m=\u001b[39;49m[\n\u001b[1;32m    573\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    574\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mmemory\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    575\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mmemory_level\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    576\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mcopy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    577\u001b[0m     ],\n\u001b[1;32m    578\u001b[0m     shelve\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shelving,\n\u001b[1;32m    579\u001b[0m )(\n\u001b[1;32m    580\u001b[0m     imgs,\n\u001b[1;32m    581\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask_img_,\n\u001b[1;32m    582\u001b[0m     params,\n\u001b[1;32m    583\u001b[0m     memory_level\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory_level,\n\u001b[1;32m    584\u001b[0m     memory\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory,\n\u001b[1;32m    585\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    586\u001b[0m     confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[1;32m    587\u001b[0m     sample_mask\u001b[39m=\u001b[39;49msample_mask,\n\u001b[1;32m    588\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    589\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m    590\u001b[0m )\n\u001b[1;32m    592\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:109\u001b[0m, in \u001b[0;36m_filter_and_mask\u001b[0;34m(imgs, mask_img_, parameters, memory_level, memory, verbose, confounds, sample_mask, copy, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     parameters[\u001b[39m'\u001b[39m\u001b[39mtarget_shape\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m mask_img_\u001b[39m.\u001b[39mshape\n\u001b[1;32m    107\u001b[0m     parameters[\u001b[39m'\u001b[39m\u001b[39mtarget_affine\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m mask_img_\u001b[39m.\u001b[39maffine\n\u001b[0;32m--> 109\u001b[0m data, affine \u001b[39m=\u001b[39m _filter_and_extract(\n\u001b[1;32m    110\u001b[0m     imgs, _ExtractionFunctor(mask_img_),\n\u001b[1;32m    111\u001b[0m     parameters,\n\u001b[1;32m    112\u001b[0m     memory_level\u001b[39m=\u001b[39;49mmemory_level,\n\u001b[1;32m    113\u001b[0m     memory\u001b[39m=\u001b[39;49mmemory,\n\u001b[1;32m    114\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    115\u001b[0m     confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[1;32m    116\u001b[0m     sample_mask\u001b[39m=\u001b[39;49msample_mask,\n\u001b[1;32m    117\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    118\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[39m# For _later_: missing value removal or imputing of missing data\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m# (i.e. we want to get rid of NaNs, if smoothing must be done\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m# earlier)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m# Optionally: 'doctor_nan', remove voxels with NaNs, other option\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# for later: some form of imputation\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/maskers/base_masker.py:112\u001b[0m, in \u001b[0;36m_filter_and_extract\u001b[0;34m(imgs, extraction_function, parameters, memory_level, memory, verbose, confounds, sample_mask, copy, dtype)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    111\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m] Extracting region signals\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m class_name)\n\u001b[0;32m--> 112\u001b[0m region_signals, aux \u001b[39m=\u001b[39m cache(extraction_function, memory,\n\u001b[1;32m    113\u001b[0m                             func_memory_level\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m    114\u001b[0m                             memory_level\u001b[39m=\u001b[39;49mmemory_level)(imgs)\n\u001b[1;32m    116\u001b[0m \u001b[39m# Temporal\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# --------\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# Detrending (optional)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m# Filtering\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# Confounds removing (from csv file or numpy array)\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m# Normalizing\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:25\u001b[0m, in \u001b[0;36m_ExtractionFunctor.__call__\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, imgs):\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m---> 25\u001b[0m         masking\u001b[39m.\u001b[39;49mapply_mask(\n\u001b[1;32m     26\u001b[0m             imgs,\n\u001b[1;32m     27\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask_img_,\n\u001b[1;32m     28\u001b[0m             dtype\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mniimg\u001b[39m.\u001b[39;49mimg_data_dtype(imgs),\n\u001b[1;32m     29\u001b[0m         ),\n\u001b[1;32m     30\u001b[0m         imgs\u001b[39m.\u001b[39maffine,\n\u001b[1;32m     31\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/masking.py:698\u001b[0m, in \u001b[0;36mapply_mask\u001b[0;34m(imgs, mask_img, dtype, smoothing_fwhm, ensure_finite)\u001b[0m\n\u001b[1;32m    696\u001b[0m mask, mask_affine \u001b[39m=\u001b[39m _load_mask_img(mask_img)\n\u001b[1;32m    697\u001b[0m mask_img \u001b[39m=\u001b[39m new_img_like(mask_img, mask, mask_affine)\n\u001b[0;32m--> 698\u001b[0m \u001b[39mreturn\u001b[39;00m _apply_mask_fmri(imgs, mask_img, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    699\u001b[0m                         smoothing_fwhm\u001b[39m=\u001b[39;49msmoothing_fwhm,\n\u001b[1;32m    700\u001b[0m                         ensure_finite\u001b[39m=\u001b[39;49mensure_finite)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/masking.py:742\u001b[0m, in \u001b[0;36m_apply_mask_fmri\u001b[0;34m(imgs, mask_img, dtype, smoothing_fwhm, ensure_finite)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m         dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32\n\u001b[0;32m--> 742\u001b[0m series \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39;49mas_ndarray(series, dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    743\u001b[0m                            copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    744\u001b[0m \u001b[39mdel\u001b[39;00m imgs_img  \u001b[39m# frees a lot of memory\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39m# Delayed import to avoid circular imports\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/_utils/numpy_conversions.py:119\u001b[0m, in \u001b[0;36mas_ndarray\u001b[0;34m(arr, copy, dtype, order)\u001b[0m\n\u001b[1;32m    117\u001b[0m             ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mcopy()\u001b[39m.\u001b[39mT\n\u001b[1;32m    118\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m             ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39;49mcopy()\n\u001b[1;32m    121\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    122\u001b[0m     \u001b[39mif\u001b[39;00m order \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mK\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 32.5 GiB for an array with shape (208, 240, 256, 682) and data type float32"
     ]
    }
   ],
   "source": [
    "# run ppi and fc\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, input_data\n",
    "from nilearn.maskers import NiftiMasker\n",
    "import nibabel as nib\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/hemisphere'\n",
    "sys.path.insert(0, curr_dir)\n",
    "#import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'hemispace'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results/tools/'\n",
    "\n",
    "def extract_roi_timeseries(img, roi_mask, hemisphere='left'):\n",
    "    \"\"\"\n",
    "    Extract mean time series from an anatomical ROI for a specific hemisphere\n",
    "    \"\"\"\n",
    "    # Get the data\n",
    "    roi_data = roi_mask.get_fdata()\n",
    "    \n",
    "    # Create hemisphere mask\n",
    "    mid_x = roi_data.shape[0] // 2\n",
    "    hemi_mask = np.zeros_like(roi_data)\n",
    "    if hemisphere == 'left':\n",
    "        hemi_mask[:mid_x, :, :] = 1\n",
    "    else:  # right hemisphere\n",
    "        hemi_mask[mid_x:, :, :] = 1\n",
    "    \n",
    "    # Combine ROI and hemisphere masks\n",
    "    combined_mask = roi_data * hemi_mask\n",
    "    mask_img = nib.Nifti1Image(combined_mask, roi_mask.affine)\n",
    "    \n",
    "    # Extract time series\n",
    "    roi_masker = NiftiMasker(mask_img, standardize=True)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    phys = np.mean(seed_time_series, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    return phys, roi_masker\n",
    "\n",
    "def make_psy_cov(runs, ss, raw_dir):\n",
    "    \"\"\"\n",
    "    Create psychological regressor for PPI analysis using tool vs non-tool contrast\n",
    "    \"\"\"\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    vols, tr = 341, 1.0\n",
    "    times = np.arange(0, vols * tr, tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for rn in runs:\n",
    "        ss_num = ss.split('-')[1].replace('spaceloc', '')  # Extract just the number\n",
    "        tool_cov_file = f'{cov_dir}/spaceloc_{ss_num}_run-0{rn}_tool.txt'\n",
    "        nontool_cov_file = f'{cov_dir}/spaceloc_{ss_num}_run-0{rn}_non_tool.txt'\n",
    "\n",
    "        if not os.path.exists(tool_cov_file) or not os.path.exists(nontool_cov_file):\n",
    "            print(f'Covariate file not found for run {rn}')\n",
    "            continue\n",
    "\n",
    "        tool_cov = pd.read_csv(tool_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        nontool_cov = pd.read_csv(nontool_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        nontool_cov['value'] *= -1  # Reverse the sign for contrast\n",
    "        full_cov = pd.concat([full_cov, tool_cov, nontool_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    cov = full_cov.to_numpy()\n",
    "    valid_onsets = cov[:, 0] < times[-1]\n",
    "    cov = cov[valid_onsets]\n",
    "\n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    return psy\n",
    "\n",
    "def conduct_analyses(study_dir, raw_dir, subs, rois, run_num=2):\n",
    "    \"\"\"\n",
    "    Main function to conduct FC and PPI analyses\n",
    "    \"\"\"\n",
    "    hemispheres = ['left', 'right']\n",
    "    runs = list(range(1, run_num + 1))\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f\"Processing subject: {ss}\")\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01/'\n",
    "        roi_dir = f'{sub_dir}derivatives/rois'\n",
    "        temp_dir = f'{raw_dir}/{ss}/ses-01/derivatives/fsl/toolloc'\n",
    "        out_dir = f'{study_dir}/{ss}/ses-01/derivatives'\n",
    "        os.makedirs(f'{out_dir}/fc', exist_ok=True)\n",
    "\n",
    "        # Get subject-specific brain mask\n",
    "        mask_path = f'{raw_dir}/{ss}/ses-01/anat/{ss}_ses-01_T1w_brain_mask.nii.gz'\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Brain mask not found for {ss}\")\n",
    "            continue\n",
    "            \n",
    "        whole_brain_mask = nib.load(mask_path)\n",
    "        brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "        for tsk in ['loc']:\n",
    "            for rr in rois:\n",
    "                roi_path = f'{roi_dir}/parcels/{rr}.nii.gz'\n",
    "                if not os.path.exists(roi_path):\n",
    "                    print(f\"ROI file not found: {roi_path}\")\n",
    "                    continue\n",
    "                \n",
    "                roi_img = nib.load(roi_path)\n",
    "                \n",
    "                for hemi in hemispheres:\n",
    "                    roi_start_time = time.time()\n",
    "                    print(f\"Processing ROI: {rr}, Hemisphere: {hemi}\")\n",
    "                    \n",
    "                    fc_file = f'{out_dir}/fc/{ss}_{rr}_{hemi}_{tsk}_fc_native.nii.gz'\n",
    "                    ppi_file = f'{out_dir}/fc/{ss}_{rr}_{hemi}_{tsk}_ppi_native.nii.gz'\n",
    "                    \n",
    "                    do_fc = not os.path.exists(fc_file)\n",
    "                    do_ppi = not os.path.exists(ppi_file)\n",
    "                    \n",
    "                    if not do_fc and not do_ppi:\n",
    "                        print(f'Both FC and PPI files already exist. Skipping...')\n",
    "                        continue\n",
    "\n",
    "                    # Load and concatenate both runs\n",
    "                    run_imgs = []\n",
    "                    for rn in runs:\n",
    "                        run_path = f'{temp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz'\n",
    "                        if os.path.exists(run_path):\n",
    "                            img = image.clean_img(image.load_img(run_path), standardize=True)\n",
    "                            run_imgs.append(img)\n",
    "                    \n",
    "                    if len(run_imgs) != 2:\n",
    "                        print(f\"Did not find both runs for {ss}\")\n",
    "                        continue\n",
    "                        \n",
    "                    img4d = image.concat_imgs(run_imgs)\n",
    "                    \n",
    "                    # Extract ROI time series\n",
    "                    phys, _ = extract_roi_timeseries(img4d, roi_img, hemisphere=hemi)\n",
    "                    brain_time_series = brain_masker.fit_transform(img4d)\n",
    "                    \n",
    "                    if do_fc:\n",
    "                        # FC Analysis\n",
    "                        correlations = np.dot(brain_time_series.T, phys) / phys.shape[0]\n",
    "                        correlation_img = brain_masker.inverse_transform(correlations)\n",
    "                        nib.save(correlation_img, fc_file)\n",
    "                        print(f'Saved FC result for {rr} {hemi}')\n",
    "                    \n",
    "                    if do_ppi:\n",
    "                        # PPI Analysis\n",
    "                        psy = make_psy_cov(runs, ss, raw_dir)\n",
    "                        \n",
    "                        # Ensure psy length matches phys\n",
    "                        min_length = min(psy.shape[0], phys.shape[0], brain_time_series.shape[0])\n",
    "                        psy = psy[:min_length]\n",
    "                        phys = phys[:min_length]\n",
    "                        brain_time_series = brain_time_series[:min_length]\n",
    "                        \n",
    "                        ppi_regressor = phys * psy\n",
    "                        ppi_correlations = np.dot(brain_time_series.T, ppi_regressor) / ppi_regressor.shape[0]\n",
    "                        ppi_img = brain_masker.inverse_transform(ppi_correlations)\n",
    "                        nib.save(ppi_img, ppi_file)\n",
    "                        print(f'Saved PPI result for {rr} {hemi}')\n",
    "                    \n",
    "                    print(f\"Completed {rr} {hemi} in {time.time() - roi_start_time:.2f} seconds\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your paths\n",
    "    study_dir = \"/lab_data/behrmannlab/vlad/hemispace\"\n",
    "    raw_dir = \"/lab_data/behrmannlab/vlad/hemispace\"\n",
    "    \n",
    "    # Create subject list for spaceloc001 through spaceloc018\n",
    "    subs = [f'sub-spaceloc1{str(i).zfill(3)}' for i in range(1, 19)]\n",
    "    rois = ['LO', 'pIPS']\n",
    "    \n",
    "    # Run the analysis\n",
    "    conduct_analyses(study_dir, raw_dir, subs, rois, run_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csimmon2/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/input_data/__init__.py:23: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: --ip=127.0.0.1\n",
      "Brain mask not found for --ip=127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "# run ppi and fc\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, input_data\n",
    "from nilearn.maskers import NiftiMasker\n",
    "import nibabel as nib\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/hemisphere'\n",
    "sys.path.insert(0, curr_dir)\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'hemispace'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results/tools/'\n",
    "\n",
    "def extract_roi_timeseries(img, roi_mask, hemisphere='left'):\n",
    "    \"\"\"\n",
    "    Extract mean time series from an anatomical ROI for a specific hemisphere\n",
    "    \"\"\"\n",
    "    # Get the data\n",
    "    roi_data = roi_mask.get_fdata()\n",
    "    \n",
    "    # Create hemisphere mask\n",
    "    mid_x = roi_data.shape[0] // 2\n",
    "    hemi_mask = np.zeros_like(roi_data)\n",
    "    if hemisphere == 'left':\n",
    "        hemi_mask[:mid_x, :, :] = 1\n",
    "    else:  # right hemisphere\n",
    "        hemi_mask[mid_x:, :, :] = 1\n",
    "    \n",
    "    # Combine ROI and hemisphere masks\n",
    "    combined_mask = roi_data * hemi_mask\n",
    "    mask_img = nib.Nifti1Image(combined_mask, roi_mask.affine)\n",
    "    \n",
    "    # Extract time series\n",
    "    roi_masker = NiftiMasker(mask_img, standardize=True)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    phys = np.mean(seed_time_series, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    return phys, roi_masker\n",
    "\n",
    "def make_psy_cov(runs, ss, raw_dir):\n",
    "    \"\"\"\n",
    "    Create psychological regressor for PPI analysis using tool vs non-tool contrast\n",
    "    \"\"\"\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    vols, tr = 341, 1.0\n",
    "    times = np.arange(0, vols * tr, tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for rn in runs:\n",
    "        ss_num = ss.split('-')[1].replace('spaceloc', '')  # Extract just the number\n",
    "        tool_cov_file = f'{cov_dir}/spaceloc_{ss_num}_run-0{rn}_tool.txt'\n",
    "        nontool_cov_file = f'{cov_dir}/spaceloc_{ss_num}_run-0{rn}_non_tool.txt'\n",
    "\n",
    "        if not os.path.exists(tool_cov_file) or not os.path.exists(nontool_cov_file):\n",
    "            print(f'Covariate file not found for run {rn}')\n",
    "            continue\n",
    "\n",
    "        tool_cov = pd.read_csv(tool_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        nontool_cov = pd.read_csv(nontool_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        nontool_cov['value'] *= -1  # Reverse the sign for contrast\n",
    "        full_cov = pd.concat([full_cov, tool_cov, nontool_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    cov = full_cov.to_numpy()\n",
    "    valid_onsets = cov[:, 0] < times[-1]\n",
    "    cov = cov[valid_onsets]\n",
    "\n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    return psy\n",
    "\n",
    "def conduct_analyses(study_dir, raw_dir, sub, rois, run_num=2):\n",
    "    \"\"\"\n",
    "    Main function to conduct FC and PPI analyses for a single subject\n",
    "    \"\"\"\n",
    "    hemispheres = ['left', 'right']\n",
    "    runs = list(range(1, run_num + 1))\n",
    "\n",
    "    print(f\"Processing subject: {sub}\")\n",
    "    sub_dir = f'{study_dir}/{sub}/ses-01/'\n",
    "    roi_dir = f'{sub_dir}derivatives/rois'\n",
    "    temp_dir = f'{raw_dir}/{sub}/ses-01/derivatives/fsl/toolloc'\n",
    "    out_dir = f'{study_dir}/{sub}/ses-01/derivatives'\n",
    "    os.makedirs(f'{out_dir}/fc', exist_ok=True)\n",
    "\n",
    "    # Get subject-specific brain mask\n",
    "    mask_path = f'{raw_dir}/{sub}/ses-01/anat/{sub}_ses-01_T1w_brain_mask.nii.gz'\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"Brain mask not found for {sub}\")\n",
    "        return\n",
    "        \n",
    "    whole_brain_mask = nib.load(mask_path)\n",
    "    brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "    for tsk in ['loc']:\n",
    "        for rr in rois:\n",
    "            roi_path = f'{roi_dir}/parcels/{rr}.nii.gz'\n",
    "            if not os.path.exists(roi_path):\n",
    "                print(f\"ROI file not found: {roi_path}\")\n",
    "                continue\n",
    "            \n",
    "            roi_img = nib.load(roi_path)\n",
    "            \n",
    "            for hemi in hemispheres:\n",
    "                roi_start_time = time.time()\n",
    "                print(f\"Processing ROI: {rr}, Hemisphere: {hemi}\")\n",
    "                \n",
    "                fc_file = f'{out_dir}/fc/{sub}_{rr}_{hemi}_{tsk}_fc_native.nii.gz'\n",
    "                ppi_file = f'{out_dir}/fc/{sub}_{rr}_{hemi}_{tsk}_ppi_native.nii.gz'\n",
    "                \n",
    "                do_fc = not os.path.exists(fc_file)\n",
    "                do_ppi = not os.path.exists(ppi_file)\n",
    "                \n",
    "                if not do_fc and not do_ppi:\n",
    "                    print(f'Both FC and PPI files already exist. Skipping...')\n",
    "                    continue\n",
    "\n",
    "                # Load and concatenate both runs\n",
    "                run_imgs = []\n",
    "                for rn in runs:\n",
    "                    run_path = f'{temp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz'\n",
    "                    if os.path.exists(run_path):\n",
    "                        img = image.clean_img(image.load_img(run_path), standardize=True)\n",
    "                        run_imgs.append(img)\n",
    "                \n",
    "                if len(run_imgs) != 2:\n",
    "                    print(f\"Did not find both runs for {sub}\")\n",
    "                    continue\n",
    "                    \n",
    "                img4d = image.concat_imgs(run_imgs)\n",
    "                \n",
    "                # Extract ROI time series\n",
    "                phys, _ = extract_roi_timeseries(img4d, roi_img, hemisphere=hemi)\n",
    "                brain_time_series = brain_masker.fit_transform(img4d)\n",
    "                \n",
    "                if do_fc:\n",
    "                    # FC Analysis\n",
    "                    correlations = np.dot(brain_time_series.T, phys) / phys.shape[0]\n",
    "                    correlation_img = brain_masker.inverse_transform(correlations)\n",
    "                    nib.save(correlation_img, fc_file)\n",
    "                    print(f'Saved FC result for {rr} {hemi}')\n",
    "                \n",
    "                if do_ppi:\n",
    "                    # PPI Analysis\n",
    "                    psy = make_psy_cov(runs, sub, raw_dir)\n",
    "                    \n",
    "                    # Ensure psy length matches phys\n",
    "                    min_length = min(psy.shape[0], phys.shape[0], brain_time_series.shape[0])\n",
    "                    psy = psy[:min_length]\n",
    "                    phys = phys[:min_length]\n",
    "                    brain_time_series = brain_time_series[:min_length]\n",
    "                    \n",
    "                    ppi_regressor = phys * psy\n",
    "                    ppi_correlations = np.dot(brain_time_series.T, ppi_regressor) / ppi_regressor.shape[0]\n",
    "                    ppi_img = brain_masker.inverse_transform(ppi_correlations)\n",
    "                    nib.save(ppi_img, ppi_file)\n",
    "                    print(f'Saved PPI result for {rr} {hemi}')\n",
    "                \n",
    "                print(f\"Completed {rr} {hemi} in {time.time() - roi_start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study_dir = \"/lab_data/behrmannlab/vlad/hemispace\"\n",
    "    raw_dir = \"/lab_data/behrmannlab/vlad/hemispace\"\n",
    "    rois = ['LO', 'pIPS']\n",
    "    \n",
    "    if len(sys.argv) > 1:\n",
    "        sub = sys.argv[1]\n",
    "        conduct_analyses(study_dir, raw_dir, sub, rois, run_num=2)\n",
    "    else:\n",
    "        print(\"Please provide subject ID as command line argument\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
