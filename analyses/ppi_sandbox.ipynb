{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,curr_dir)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import statsmodels.api as s\n",
    "from sklearn import metrics\n",
    "\n",
    "import pdb\n",
    "import ptoc_params as params\n",
    "\n",
    "from plotnine import *\n",
    "#from plotnine import ggplot, aes, geom_point\n",
    "\n",
    "\n",
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load additional libraries\n",
    "from nilearn import image, plotting, input_data, glm\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nibabel as nib\n",
    "import statsmodels.api as sm\n",
    "from nilearn.datasets import load_mni152_brain_mask, load_mni152_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = params.data_dir\n",
    "results_dir = params.results_dir\n",
    "fig_dir = params.fig_dir\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "sub_info = params.sub_info\n",
    "task_info = params.task_info\n",
    "\n",
    "suf = params.suf\n",
    "rois = params.rois\n",
    "hemis = params.hemis\n",
    "\n",
    "#load subject info\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "\n",
    "#mni = load_mni152_brain_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''exp info'''\n",
    "#subs = ['sub-064']  # Run for one subject initially\n",
    "#subs = sub_info['sub'].tolist()\n",
    "\n",
    "#Just controls\n",
    "subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "study = 'ptoc'\n",
    "data_dir = 'hemispace'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "out_dir = f'{study_dir}/derivatives/fc'\n",
    "results_dir = '/user_data/csimmon2/GitHub_Repos/ptoc/results'\n",
    "exp = ''\n",
    "rois = ['LO']  # Run for one ROI initially\n",
    "control_tasks = ['loc']\n",
    "file_suf = ''\n",
    "\n",
    "'''scan params'''\n",
    "tr = 1\n",
    "vols = 321\n",
    "\n",
    "whole_brain_mask = load_mni152_brain_mask()\n",
    "mni = load_mni152_template()\n",
    "brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "'''run info'''\n",
    "run_num = 3\n",
    "runs = list(range(1, run_num + 1))\n",
    "run_combos = []\n",
    "\n",
    "for rn1 in range(1, run_num + 1):\n",
    "    for rn2 in range(rn1 + 1, run_num + 1):\n",
    "        run_combos.append([rn1, rn2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract ROI coordinates\n",
    "def extract_roi_coords():\n",
    "    \"\"\"\n",
    "    Define ROIs\n",
    "    \"\"\"\n",
    "    parcels = ['V1', 'aIPS', 'PFS', 'pIPS', 'LO']\n",
    "    subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f'Processing subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        os.makedirs(f'{roi_dir}/spheres', exist_ok=True)\n",
    "        \n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "        parcel_dir = f'{roi_dir}/parcels'\n",
    "        roi_coords = pd.DataFrame(columns=['index', 'task', 'roi', 'x', 'y', 'z'])\n",
    "        \n",
    "        for rcn, rc in enumerate(run_combos):\n",
    "            roi_runs = [ele for ele in runs if ele not in rc]\n",
    "            \n",
    "            #load each run\n",
    "            all_runs = []\n",
    "            for rn in roi_runs:\n",
    "                curr_run_path = f'{exp_dir}/loc/run-0{rn}/1stLevel.feat/stats/zstat3_reg.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "            affine = mean_zstat.affine\n",
    "\n",
    "            for pr in parcels:\n",
    "                roi_path = f'{parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    roi = image.math_img('img > 0', img=roi)\n",
    "\n",
    "                    coords = plotting.find_xyz_cut_coords(mean_zstat, mask_img=roi, activation_threshold=0.99)\n",
    "                    \n",
    "                    masked_stat = image.math_img('img1 * img2', img1=roi, img2=mean_zstat)\n",
    "                    masked_stat = image.get_data(masked_stat)\n",
    "                    np_coords = np.where(masked_stat == np.max(masked_stat))\n",
    "                    \n",
    "                    curr_coords = pd.Series([rcn, 'loc', pr] + coords, index=roi_coords.columns)\n",
    "                    roi_coords = roi_coords.append(curr_coords, ignore_index=True)\n",
    "\n",
    "                    # control task ROI\n",
    "                    control_zstat_path = f'{exp_dir}/loc/HighLevel.gfeat/cope3.feat/stats/zstat1.nii.gz'\n",
    "                    if os.path.exists(control_zstat_path):\n",
    "                        control_zstat = image.load_img(control_zstat_path)\n",
    "                        coords = plotting.find_xyz_cut_coords(control_zstat, mask_img=roi, activation_threshold=0.99)\n",
    "                        \n",
    "                        curr_coords = pd.Series([rcn, 'highlevel', pr] + coords, index=roi_coords.columns)\n",
    "                        roi_coords = roi_coords.append(curr_coords, ignore_index=True)\n",
    "                    else:\n",
    "                        print(f'File does not exist: {control_zstat_path}')\n",
    "                else:\n",
    "                    print(f'File does not exist: {roi_path}')\n",
    "            \n",
    "        roi_coords.to_csv(f'{roi_dir}/spheres/sphere_coords.csv', index=False)\n",
    "\n",
    "# Call the function\n",
    "extract_roi_coords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi_sphere(img, coords):\n",
    "    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius = 6)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    \n",
    "    phys = np.mean(seed_time_series, axis= 1)\n",
    "    #phys = (phys - np.mean(phys)) / np.std(phys) #TRY WITHOUT STANDARDIZING AT SOME POINT\n",
    "    phys = phys.reshape((phys.shape[0],1))\n",
    "    \n",
    "    return phys\n",
    "\n",
    "#these paths are tricky\n",
    "def make_psy_cov(runs,ss):\n",
    "    \n",
    "    sub_dir = f'{study_dir}/sub-{study}{ss}/ses-01/'\n",
    "    cov_dir = f'{sub_dir}/covs'\n",
    "    \n",
    "    times = np.arange(0, vols*len(runs), tr)\n",
    "    full_cov = pd.DataFrame(columns = ['onset','duration', 'value'])\n",
    "    for rn, run in enumerate(runs):    \n",
    "        \n",
    "        curr_cov = pd.read_csv(f'{cov_dir}/SpaceLoc_{study}{ss}_Run{run}_SA.txt', sep = '\\t', header = None, names = ['onset','duration', 'value'])\n",
    "        #contrasting (neg) cov\n",
    "\n",
    "        curr_cont = pd.read_csv(f'{cov_dir}/SpaceLoc_{study}{ss}_Run{run}_FT.txt', sep = '\\t', header =None, names =['onset','duration', 'value'])\n",
    "        curr_cont.iloc[:,2] = curr_cont.iloc[:,2] *-1 #make contrasting cov neg\n",
    "        \n",
    "        curr_cov = curr_cov.append(curr_cont) #append to positive\n",
    "\n",
    "        curr_cov['onset'] = curr_cov['onset'] + (vols*rn)\n",
    "        full_cov = full_cov.append(curr_cov)\n",
    "        #add number of vols to the timing cols based on what run you are on\n",
    "        #e.g., for run 1, add 0, for run 2, add 321\n",
    "        #curr_cov['onset'] = curr_cov['onset'] + ((rn_n)*vols) \n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        #append to concatenated cov\n",
    "    full_cov = full_cov.sort_values(by =['onset'])\n",
    "    cov = full_cov.to_numpy()\n",
    "\n",
    "    #convolve to hrf\n",
    "    psy, name = glm.first_level.compute_regressor(cov.T, 'spm', times)\n",
    "        \n",
    "\n",
    "    return psy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHERE I AM STUCK 7/29/24\n",
    "rois = ['LO']\n",
    "tsk = 'loc'\n",
    "rr = 'LO'\n",
    "ss = 'sub-064'\n",
    "runs = [1,2,3]\n",
    "\n",
    "def conduct_ppi():\n",
    "    for ss in subs:\n",
    "        print(ss)\n",
    "        sub_dir = f'{study_dir}/sub-{study}{ss}/ses-01/'\n",
    "        cov_dir = f'{sub_dir}/covs'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl/{exp}'\n",
    "\n",
    "        roi_coords = pd.read_csv(f'{params.raw_dir}/sub-{study}{ss}/ses-01/spheres/sphere_coords.csv') #load ROI coordinates\n",
    "                                 \n",
    "        for rr in rois:\n",
    "            all_runs = [] #this will get filled with the data from each run\n",
    "            for rcn, rc in enumerate(run_combos): #determine which runs to use for creating ROIs | run combos\n",
    "                curr_coords = roi_coords[(roi_coords['index'] == rcn) & (roi_coords['task'] ==tsk) & (roi_coords['roi'] ==rr)]\n",
    "\n",
    "                filtered_list = []\n",
    "                for rn in rc:\n",
    "                    \n",
    "                    curr_run = image.load_img(f'{exp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz') #load image data\n",
    "                    curr_run = image.clean_img(curr_run,standardize=True)\n",
    "                    filtered_list.append(curr_run)\n",
    "                    \n",
    "                img4d = image.concat_imgs(filtered_list)\n",
    "                phys = extract_roi_sphere(img4d,curr_coords[['x','y','z']].values.tolist()[0]) #extract ROI spehere coordinate, pulls out just the time series from that part of the brain, every voxel of the brain, time series for just the spheres we've pulled out\n",
    "                #load behavioral data\n",
    "                #CONVOLE TO HRF\n",
    "                psy = make_psy_cov(rc, ss) #this is the one that goes to the covariate folder and grabs the covariate we care about and converts the three coloumn into binary data. \n",
    "\n",
    "                #combine phys (seed TS) and psy (task TS) into a regressor ||  TS = time series, CNS\n",
    "                confounds = pd.DataFrame(columns =['psy', 'phys'])\n",
    "                confounds['psy'] = psy[:,0]\n",
    "                confounds['phys'] =phys[:,0]\n",
    "\n",
    "                #create PPI cov by multiply psy * phys #this is createing the interaction term, the is the PPI time course. There are the individual, so we can get a brain time series with sine phys regressed out\n",
    "                ppi = psy*phys\n",
    "                ppi = ppi.reshape((ppi.shape[0],1))\n",
    "\n",
    "                brain_time_series = brain_masker.fit_transform(img4d, confounds=[confounds]) #change this line to remove confounds \n",
    "                #brain_time_series_4FC = brain_masker.fit_transform(img4d) #change this line to remove confounds\n",
    "\n",
    "                #Correlate interaction term to TS for vox in the brain\n",
    "                seed_to_voxel_correlations = (np.dot(brain_time_series.T, ppi) /\n",
    "                                ppi.shape[0])\n",
    "                print(ss, rr, tsk, seed_to_voxel_correlations.max())\n",
    "                \n",
    "                #Correlate interaction term to TS for vox in the brain\n",
    "                #seed_to_voxel_correlations = (np.dot(brain_time_series_4FC.T, psy) /\n",
    "                                #psy.shape[0])\n",
    "                \n",
    "                seed_to_voxel_correlations = np.arctanh(seed_to_voxel_correlations) # transform back to brain space\n",
    "                #transform correlation map back to brain\n",
    "                seed_to_voxel_correlations_img = brain_masker.inverse_transform(seed_to_voxel_correlations.T)\n",
    "                \n",
    "                all_runs.append(seed_to_voxel_correlations_img)\n",
    "\n",
    "            mean_fc = image.mean_img(all_runs)\n",
    "                \n",
    "            nib.save(mean_fc, f'{out_dir}/sub-{study}{ss}_{rr}_{tsk}_ppi.nii.gz') #creates the summary file for the PPI analysis (stop here each seed region and the rest of the brain)\n",
    "            #nib.save(mean_fc, f'{out_dir}/sub-{study}{ss}_{rr}_{tsk}_fc_4FC.nii.gz') #creates the summary file for the PSY analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pause before this section to review output with Vlad\n",
    "def create_summary():\n",
    "    ventral_rois = ['LO_toolloc']\n",
    "    rois = [\"PPC_spaceloc\"]\n",
    "    print(subs)\n",
    "    \n",
    "    for lrv in ['l', 'r']:\n",
    "        for vr in ventral_rois:\n",
    "            summary_df = pd.DataFrame(columns=['sub'] + ['l' + rr for rr in rois] + ['r' + rr for rr in rois])\n",
    "            ventral = f'{lrv}{vr}'\n",
    "            print(ventral)\n",
    "            \n",
    "            for ss in subs:\n",
    "                sub_dir = f'{study_dir}/sub-{study}{ss}/ses-01/'\n",
    "                roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "                \n",
    "                ventral_mask = image.load_img(f'{roi_dir}/{ventral}.nii.gz')\n",
    "                ventral_mask = NiftiMasker(ventral_mask)\n",
    "                \n",
    "                roi_mean = []\n",
    "                roi_mean.append(ss)\n",
    "                \n",
    "                for lr in ['l', 'r']:\n",
    "                    for rr in rois:\n",
    "                        roi = f'{roi_dir}/{lr}{rr}.nii.gz'\n",
    "                        fc_img = image.load_img(f'{out_dir}/sub-{study}{ss}_{lr}{rr}_ppi.nii.gz')\n",
    "                        \n",
    "                        mask_img = ventral_mask.fit_transform(fc_img)\n",
    "                        mean_val = mask_img.mean()\n",
    "                        roi_mean.append(mean_val)\n",
    "                \n",
    "                summary_df.loc[len(summary_df)] = roi_mean\n",
    "            \n",
    "            summary_df.to_csv(f'{results_dir}/ppi_summary_{ventral}.csv', index=False)\n",
    "            \n",
    "create_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original with comments\n",
    "#pause after this to check the output || run brain_time_series without confounds, and instead of ppi you would use phys || change the two lines to be the same, and then you can see the correlation between the two time series. || change the name of the output and the two lines \n",
    "def conduct_ppi():\n",
    "    for ss in subs:\n",
    "        print(ss)\n",
    "        sub_dir = f'{study_dir}/sub-{study}{ss}/ses-01/'\n",
    "        cov_dir = f'{sub_dir}/covs'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl/{exp}'\n",
    "\n",
    "        roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords.csv')\n",
    "\n",
    "        for tsk in ['spaceloc','distloc']: #just include one task for now get rid of the loop and extract current coords\n",
    "            for rr in rois:\n",
    "                all_runs = [] #this will get filled with the data from each run\n",
    "                for rcn, rc in enumerate(run_combos): #determine which runs to use for creating ROIs | run combos\n",
    "                    curr_coords = roi_coords[(roi_coords['index'] == rcn) & (roi_coords['task'] ==tsk) & (roi_coords['roi'] ==rr)]\n",
    "\n",
    "                    filtered_list = []\n",
    "                    for rn in rc:\n",
    "                        \n",
    "                        curr_run = image.load_img(f'{exp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz') #filtered_func data - cope and zstat is a mean image, while the filtered is preprocessed data - standardized\n",
    "                        #double check the above exists.\n",
    "                        curr_run = image.clean_img(curr_run,standardize=True)\n",
    "                        filtered_list.append(curr_run)\n",
    "                        \n",
    "                    img4d = image.concat_imgs(filtered_list)\n",
    "                    phys = extract_roi_sphere(img4d,curr_coords[['x','y','z']].values.tolist()[0]) #extract ROI spehere coordinate, pulls out just the time series from that part of the brain, every voxel of the brain, time series for just the spheres we've pulled out\n",
    "                    #load behavioral data\n",
    "                    #CONVOLE TO HRF\n",
    "                    psy = make_psy_cov(rc, ss) #this is the one that goes to the covariate folder and grabs the covariate we care about and converts the three coloumn into binary data. \n",
    "\n",
    "                    #combine phys (seed TS) and psy (task TS) into a regressor ||  TS = time series, CNS\n",
    "                    confounds = pd.DataFrame(columns =['psy', 'phys'])\n",
    "                    confounds['psy'] = psy[:,0]\n",
    "                    confounds['phys'] =phys[:,0]\n",
    "\n",
    "                    #create PPI cov by multiply psy * phys #this is createing the interaction term, the is the PPI time course. There are the individual, so we can get a brain time series with sine phys regressed out\n",
    "                    ppi = psy*phys\n",
    "                    ppi = ppi.reshape((ppi.shape[0],1))\n",
    "\n",
    "                    brain_time_series = brain_masker.fit_transform(img4d, confounds=[confounds]) #change this line to remove confounds \n",
    "                    #brain_time_series_4FC = brain_masker.fit_transform(img4d) #change this line to remove confounds\n",
    "\n",
    "                    #Correlate interaction term to TS for vox in the brain\n",
    "                    seed_to_voxel_correlations = (np.dot(brain_time_series.T, ppi) /\n",
    "                                    ppi.shape[0])\n",
    "                    print(ss, rr, tsk, seed_to_voxel_correlations.max())\n",
    "                    \n",
    "                    #Correlate interaction term to TS for vox in the brain\n",
    "                    #seed_to_voxel_correlations = (np.dot(brain_time_series_4FC.T, psy) /\n",
    "                                    #psy.shape[0])\n",
    "                    \n",
    "                    seed_to_voxel_correlations = np.arctanh(seed_to_voxel_correlations) # transform back to brain space\n",
    "                    #transform correlation map back to brain\n",
    "                    seed_to_voxel_correlations_img = brain_masker.inverse_transform(seed_to_voxel_correlations.T)\n",
    "                    \n",
    "                    all_runs.append(seed_to_voxel_correlations_img)\n",
    "\n",
    "                mean_fc = image.mean_img(all_runs)\n",
    "                    \n",
    "                nib.save(mean_fc, f'{out_dir}/sub-{study}{ss}_{rr}_{tsk}_ppi.nii.gz') #creates the summary file for the PPI analysis (stop here each seed region and the rest of the brain)\n",
    "                #nib.save(mean_fc, f'{out_dir}/sub-{study}{ss}_{rr}_{tsk}_fc_4FC.nii.gz') #creates the summary file for the PSY analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85d6a1f04e70c5556da1eb33c5679a806be4c5365a0d8ae0b55875cb552fe2b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
