{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run to start\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,curr_dir)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import statsmodels.api as s\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, maskers, plotting, datasets\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import time\n",
    "import itertools \n",
    "import warnings\n",
    "\n",
    "\n",
    "import pdb\n",
    "import ptoc_params as params\n",
    "\n",
    "from plotnine import *\n",
    "#from plotnine import ggplot, aes, geom_point\n",
    "\n",
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load additional libraries\n",
    "from nilearn import image, plotting, input_data, glm\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nibabel as nib\n",
    "import statsmodels.api as sm\n",
    "from nilearn.datasets import load_mni152_brain_mask, load_mni152_template\n",
    "from nilearn.glm.first_level import compute_regressor ##?????\n",
    "\n",
    "data_dir = params.data_dir\n",
    "results_dir = params.results_dir\n",
    "fig_dir = params.fig_dir\n",
    "raw_dir = params.raw_dir\n",
    "sub_info = params.sub_info\n",
    "task_info = params.task_info\n",
    "\n",
    "suf = params.suf\n",
    "#mni = load_mni152_brain_mask()\n",
    "\n",
    "'''exp info'''\n",
    "#load subject info\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "\n",
    "\n",
    "##Just controls\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/GitHub_Repos/ptoc/results'\n",
    "exp = ''\n",
    "#rois = ['LO']  # Run for one ROI initially\n",
    "#rois = ['LO', 'PFS', 'pIPS','aIPS', 'V1']\n",
    "control_tasks = ['loc']\n",
    "file_suf = ''\n",
    "\n",
    "'''scan params'''\n",
    "tr = 2 #ptoc_params\n",
    "vols = 184 #ptoc_params\n",
    "\n",
    "whole_brain_mask = load_mni152_brain_mask()\n",
    "mni = load_mni152_template()\n",
    "brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: sub-025\n",
      "Run combination: (1, 2)\n",
      "ROI: pIPS, Run combination: (1, 2)\n",
      "Peak coordinates: (-44.22365046851337, -59.75756710395217, 27.444749713875353)\n",
      "Peak voxel (rounded): [-44 -60  27]\n",
      "ROI: LO, Run combination: (1, 2)\n",
      "Peak coordinates: (39.86771406978369, -51.45941890403628, -0.6402177913114429)\n",
      "Peak voxel (rounded): [ 40 -51  -1]\n",
      "Run combination: (1, 3)\n",
      "ROI: pIPS, Run combination: (1, 3)\n",
      "Peak coordinates: (-19.34424934722483, -58.18833639472723, 37.66978480108082)\n",
      "Peak voxel (rounded): [-19 -58  38]\n",
      "ROI: LO, Run combination: (1, 3)\n",
      "Peak coordinates: (42.94056975096464, -53.16523325443268, -4.334501564502716)\n",
      "Peak voxel (rounded): [ 43 -53  -4]\n",
      "Run combination: (2, 3)\n",
      "ROI: pIPS, Run combination: (2, 3)\n",
      "Peak coordinates: (-36.29278386384249, -58.5846809707582, 32.41722715739161)\n",
      "Peak voxel (rounded): [-36 -59  32]\n",
      "ROI: LO, Run combination: (2, 3)\n",
      "Peak coordinates: (39.86771406978369, -51.45941890403628, -0.6402177913114429)\n",
      "Peak voxel (rounded): [ 40 -51  -1]\n",
      "ROI coordinates saved to /lab_data/behrmannlab/vlad/ptoc/sub-025/ses-01/derivatives/rois/spheres/sphere_coords.csv\n",
      "ROI coordinate extraction completed.\n"
     ]
    }
   ],
   "source": [
    "#8.8.24 extract_roi_coords for subject specific rois\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_roi_coords():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(os.path.join(curr_dir, 'sub_info.csv'))\n",
    "    #subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    subs = ['sub-025']\n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = [(r1, r2) for r1 in runs for r2 in runs if r1 < r2]\n",
    "    \n",
    "    for ss in subs:\n",
    "        print(f'Processing subject: {ss}')\n",
    "        sub_dir = os.path.join(study_dir, ss, 'ses-01')\n",
    "        roi_dir = os.path.join(sub_dir, 'derivatives', 'rois')\n",
    "        parcel_dir = os.path.join(roi_dir, 'parcels')\n",
    "        temp_dir = os.path.join(RAW_DIR, ss, 'ses-01', 'derivatives', 'fsl', 'loc')\n",
    "        os.makedirs(os.path.join(roi_dir, 'spheres'), exist_ok=True)\n",
    "        roi_coords = []\n",
    "        \n",
    "        for idx, rc in enumerate(run_combos):\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = os.path.join(temp_dir, f'run-0{rn}', '1stLevel.feat', 'stats', 'zstat3_anat.nii.gz')\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "            \n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "            \n",
    "            # Load a single volume for visualization\n",
    "            sub_anat_path = os.path.join(temp_dir, f'run-0{rc[0]}', '1stLevel.feat', 'example_func.nii.gz')\n",
    "            if not os.path.exists(sub_anat_path):\n",
    "                print(f\"Anatomical image not found: {sub_anat_path}\")\n",
    "                continue\n",
    "            sub_anat = image.load_img(sub_anat_path)\n",
    "            \n",
    "            for pr in parcels:\n",
    "                roi_path = os.path.join(parcel_dir, f'{pr}.nii.gz')\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi_img = image.load_img(roi_path)\n",
    "                    masked_data = image.math_img('img1 * img2', img1=mean_zstat, img2=roi_img).get_fdata()\n",
    "                    peak_idx = np.unravel_index(np.argmax(masked_data), masked_data.shape)\n",
    "                    peak_coords = image.coord_transform(*peak_idx, mean_zstat.affine)\n",
    "                    \n",
    "                    roi_coords.append({\n",
    "                        'index': idx,  # Add index corresponding to run combination\n",
    "                        'task': 'loc',\n",
    "                        'roi': pr,\n",
    "                        'x': peak_coords[0],\n",
    "                        'y': peak_coords[1],\n",
    "                        'z': peak_coords[2]\n",
    "                    })\n",
    "                    \n",
    "                    # After finding peak_coords\n",
    "                    peak_voxel = np.round(peak_coords).astype(int)\n",
    "\n",
    "                    print(f\"ROI: {pr}, Run combination: {rc}\")\n",
    "                    print(f\"Peak coordinates: {peak_coords}\")\n",
    "                    print(f\"Peak voxel (rounded): {peak_voxel}\")\n",
    "\n",
    "                    # Visualization code remains the same\n",
    "                    ...\n",
    "                    \n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "        \n",
    "        roi_coords_df = pd.DataFrame(roi_coords)\n",
    "        roi_coords_df.to_csv(os.path.join(roi_dir, 'spheres', 'sphere_coords.csv'), index=False)\n",
    "        print(f\"ROI coordinates saved to {os.path.join(roi_dir, 'spheres', 'sphere_coords.csv')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_roi_coords()\n",
    "    print(\"ROI coordinate extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: sub-025\n",
      "Run combination: (1, 2)\n",
      "ROI: pIPS, Peak coordinates: (-42.0, -76.0, 30.0)\n",
      "ROI: LO, Peak coordinates: (44.0, -74.0, -10.0)\n",
      "Run combination: (1, 3)\n",
      "ROI: pIPS, Peak coordinates: (-22.0, -74.0, 32.0)\n",
      "ROI: LO, Peak coordinates: (44.0, -74.0, -10.0)\n",
      "Run combination: (2, 3)\n",
      "ROI: pIPS, Peak coordinates: (-22.0, -76.0, 34.0)\n",
      "ROI: LO, Peak coordinates: (44.0, -74.0, -10.0)\n",
      "ROI coordinates saved to /lab_data/behrmannlab/vlad/ptoc/sub-025/ses-01/derivatives/rois/spheres/sphere_coords_std.csv\n",
      "Processing subject: sub-038\n",
      "Run combination: (1, 2)\n",
      "ROI: pIPS, Peak coordinates: (-24.0, -70.0, 38.0)\n",
      "ROI: LO, Peak coordinates: (46.0, -70.0, -8.0)\n",
      "Run combination: (1, 3)\n",
      "ROI: pIPS, Peak coordinates: (-24.0, -74.0, 46.0)\n",
      "ROI: LO, Peak coordinates: (46.0, -68.0, -8.0)\n",
      "Run combination: (2, 3)\n",
      "ROI: pIPS, Peak coordinates: (-24.0, -72.0, 44.0)\n",
      "ROI: LO, Peak coordinates: (48.0, -70.0, -10.0)\n",
      "ROI coordinates saved to /lab_data/behrmannlab/vlad/ptoc/sub-038/ses-01/derivatives/rois/spheres/sphere_coords_std.csv\n",
      "Processing subject: sub-057\n",
      "Run combination: (1, 2)\n",
      "ROI: pIPS, Peak coordinates: (-26.0, -68.0, 40.0)\n",
      "ROI: LO, Peak coordinates: (42.0, -62.0, 2.0)\n",
      "Run combination: (1, 3)\n",
      "ROI: pIPS, Peak coordinates: (-24.0, -76.0, 52.0)\n",
      "ROI: LO, Peak coordinates: (-52.0, -68.0, -8.0)\n",
      "Run combination: (2, 3)\n",
      "ROI: pIPS, Peak coordinates: (-26.0, -70.0, 44.0)\n",
      "ROI: LO, Peak coordinates: (44.0, -64.0, 2.0)\n",
      "ROI coordinates saved to /lab_data/behrmannlab/vlad/ptoc/sub-057/ses-01/derivatives/rois/spheres/sphere_coords_std.csv\n",
      "Processing subject: sub-059\n",
      "Run combination: (1, 2)\n",
      "ROI: pIPS, Peak coordinates: (28.0, -78.0, 26.0)\n",
      "ROI: LO, Peak coordinates: (-32.0, -76.0, -2.0)\n",
      "Run combination: (1, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 90\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROI coordinates saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/spheres/sphere_coords_std.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mextract_roi_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROI coordinate extraction completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m, in \u001b[0;36mextract_roi_coords\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m roi_coords \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([roi_coords, pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m: [index],\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m: [peak_coords[\u001b[38;5;241m2\u001b[39m]]\n\u001b[1;32m     71\u001b[0m })], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Visualize ROI and peak voxel on MNI template\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m display \u001b[38;5;241m=\u001b[39m \u001b[43mplotting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_roi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbg_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmni_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mss\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m - \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpr\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m - Runs \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m display\u001b[38;5;241m.\u001b[39madd_markers([peak_coords], marker_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, marker_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#plt.savefig(f'{roi_dir}/{ss}_{pr}_runs{rc[0]}{rc[1]}_peak_mni.png')\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/plotting/img_plotting.py:665\u001b[0m, in \u001b[0;36mplot_roi\u001b[0;34m(roi_img, bg_img, cut_coords, output_file, display_mode, figure, axes, title, annotate, draw_cross, black_bg, threshold, alpha, cmap, dim, colorbar, cbar_tick_format, vmin, vmax, resampling_interpolation, view_type, linewidths, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m     roi_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    662\u001b[0m bg_img, black_bg, bg_vmin, bg_vmax \u001b[38;5;241m=\u001b[39m _load_anat(bg_img, dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[1;32m    663\u001b[0m                                                 black_bg\u001b[38;5;241m=\u001b[39mblack_bg)\n\u001b[0;32m--> 665\u001b[0m display \u001b[38;5;241m=\u001b[39m \u001b[43m_plot_img_with_bg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroi_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbg_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbg_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcut_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcut_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw_cross\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_cross\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblack_bg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblack_bg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbg_vmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbg_vmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbg_vmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbg_vmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresampling_interpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresampling_interpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolorbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_tick_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbar_tick_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m view_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontours\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    676\u001b[0m     display \u001b[38;5;241m=\u001b[39m _plot_roi_contours(display, img, cmap\u001b[38;5;241m=\u001b[39mcmap, alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    677\u001b[0m                                  linewidths\u001b[38;5;241m=\u001b[39mlinewidths)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/plotting/img_plotting.py:196\u001b[0m, in \u001b[0;36m_plot_img_with_bg\u001b[0;34m(img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, vmin, vmax, bg_vmin, bg_vmax, interpolation, display_factory, cbar_vmin, cbar_vmax, cbar_tick_format, brain_color, decimals, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bg_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     bg_img \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mcheck_niimg_3d(bg_img)\n\u001b[0;32m--> 196\u001b[0m     \u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_overlay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbg_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbg_vmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbg_vmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     display\u001b[38;5;241m.\u001b[39madd_overlay(new_img_like(img, data, affine),\n\u001b[1;32m    202\u001b[0m                         threshold\u001b[38;5;241m=\u001b[39mthreshold, interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[1;32m    203\u001b[0m                         colorbar\u001b[38;5;241m=\u001b[39mcolorbar, vmin\u001b[38;5;241m=\u001b[39mvmin, vmax\u001b[38;5;241m=\u001b[39mvmax,\n\u001b[1;32m    204\u001b[0m                         cbar_vmin\u001b[38;5;241m=\u001b[39mcbar_vmin, cbar_vmax\u001b[38;5;241m=\u001b[39mcbar_vmax,\n\u001b[1;32m    205\u001b[0m                         cbar_tick_format\u001b[38;5;241m=\u001b[39mcbar_tick_format,\n\u001b[1;32m    206\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/plotting/displays/_slicers.py:273\u001b[0m, in \u001b[0;36mBaseSlicer.add_overlay\u001b[0;34m(self, img, threshold, colorbar, cbar_tick_format, cbar_vmin, cbar_vmax, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Make sure that add_overlay shows consistent default behavior\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# with plot_stat_map\u001b[39;00m\n\u001b[1;32m    272\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterpolation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 273\u001b[0m ims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_show\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimshow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# `ims` can be empty in some corner cases, look at test_img_plotting.test_outlier_cut_coords.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m colorbar \u001b[38;5;129;01mand\u001b[39;00m ims:\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/plotting/displays/_slicers.py:353\u001b[0m, in \u001b[0;36mBaseSlicer._map_show\u001b[0;34m(self, img, type, resampling_interpolation, threshold, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(threshold) \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_safe_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    355\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_equal(data, \u001b[38;5;241m0\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/_utils/niimg.py:57\u001b[0m, in \u001b[0;36m_safe_get_data\u001b[0;34m(img, ensure_finite, copy_data)\u001b[0m\n\u001b[1;32m     53\u001b[0m     img \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(img)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# typically the line below can double memory usage\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# that's why we invoke a forced call to the garbage collector\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mgc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m data \u001b[38;5;241m=\u001b[39m _get_data(img)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_finite:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 660x260 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#8/7/24 at 1:30 pm reviewed and confirmed # 8/6/24 at 10:30 pm Extract_roi_coords\n",
    "# it runs well and looks good but some of the coordinate are too similar i.e. identical for different runs, this wasn't a problem and confirmed in the below cell. \n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "mni_parcel_dir = f'{curr_dir}/roiParcels'\n",
    "\n",
    "def extract_roi_coords():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "    subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    #subs = ['sub-025']\n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = list(itertools.combinations(runs, 2))\n",
    "    \n",
    "    # Load MNI152 template for visualization\n",
    "    mni_template = image.load_img('/opt/fsl/6.0.3/data/standard/MNI152_T1_2mm_brain.nii.gz')\n",
    "    \n",
    "    for ss in subs:\n",
    "        print(f'Processing subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        os.makedirs(f'{roi_dir}/spheres', exist_ok=True)\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "        roi_coords = pd.DataFrame(columns=['index', 'task', 'roi', 'x', 'y', 'z'])\n",
    "        \n",
    "        index = 0\n",
    "        for rc in run_combos:\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = f'/lab_data/behrmannlab/vlad/hemispace/{ss}/ses-01/derivatives/fsl/loc/run-0{rn}/1stLevel.feat/stats/zstat3_mni.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "            \n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "            \n",
    "            for pr in parcels:\n",
    "                roi_path = f'{mni_parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    # Find peak voxel within ROI\n",
    "                    masked_data = image.math_img('img1 * img2', img1=mean_zstat, img2=roi).get_fdata()\n",
    "                    peak_idx = np.unravel_index(np.argmax(masked_data), masked_data.shape)\n",
    "                    peak_coords = image.coord_transform(*peak_idx, mean_zstat.affine)\n",
    "                    \n",
    "                    roi_coords = pd.concat([roi_coords, pd.DataFrame({\n",
    "                        'index': [index],\n",
    "                        'task': ['loc'],\n",
    "                        'roi': [pr],\n",
    "                        'x': [peak_coords[0]],\n",
    "                        'y': [peak_coords[1]],\n",
    "                        'z': [peak_coords[2]]\n",
    "                    })], ignore_index=True)\n",
    "                    \n",
    "                    # Visualize ROI and peak voxel on MNI template\n",
    "                    display = plotting.plot_roi(roi, bg_img=mni_template,\n",
    "                                                title=f'{ss} - {pr} - Runs {rc[0]}{rc[1]}')\n",
    "                    display.add_markers([peak_coords], marker_color='r', marker_size=100)\n",
    "                    #plt.savefig(f'{roi_dir}/{ss}_{pr}_runs{rc[0]}{rc[1]}_peak_mni.png')\n",
    "                    plt.close()\n",
    "                    \n",
    "                    print(f\"ROI: {pr}, Peak coordinates: {peak_coords}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "            \n",
    "            index += 1\n",
    "        \n",
    "        roi_coords.to_csv(f'{roi_dir}/spheres/sphere_coords_std.csv', index=False)\n",
    "        print(f\"ROI coordinates saved to {roi_dir}/spheres/sphere_coords_std.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_roi_coords()\n",
    "    print(\"ROI coordinate extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8/7/24 1 pm confirming the extraction of the coordinates process - it works well\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "mni_parcel_dir = f'{curr_dir}/roiParcels'\n",
    "\n",
    "def is_unique(coords, existing_coords, tolerance=1.0):\n",
    "    for existing in existing_coords:\n",
    "        if np.all(np.abs(np.array(coords) - np.array(existing)) < tolerance):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def extract_roi_coords():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "    subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    #subs = ['sub-025']\n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = list(itertools.combinations(runs, 2))\n",
    "\n",
    "    # Load MNI152 template for visualization\n",
    "    mni_template = image.load_img('/opt/fsl/6.0.3/data/standard/MNI152_T1_2mm_brain.nii.gz')\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f'Processing subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        os.makedirs(f'{roi_dir}/spheres', exist_ok=True)\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "\n",
    "        roi_coords = pd.DataFrame(columns=['run_combo', 'roi', 'x', 'y', 'z', 'peak_value'])\n",
    "\n",
    "        for rc in run_combos:\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = f'/lab_data/behrmannlab/vlad/hemispace/{ss}/ses-01/derivatives/fsl/loc/run-0{rn}/1stLevel.feat/stats/zstat3_mni.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                    print(f\"Run {rn} stats: mean={np.mean(curr_run.get_fdata()):.4f}, max={np.max(curr_run.get_fdata()):.4f}\")\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "\n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "\n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "\n",
    "            for pr in parcels:\n",
    "                roi_path = f'{mni_parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    \n",
    "                    # Find peak voxel within ROI\n",
    "                    masked_data = image.math_img('img1 * img2', img1=mean_zstat, img2=roi).get_fdata()\n",
    "                    \n",
    "                    print(f\"ROI: {pr}\")\n",
    "                    print(f\"Number of voxels in ROI: {np.sum(masked_data != 0)}\")\n",
    "                    print(f\"Max value in masked data: {np.max(masked_data)}\")\n",
    "                    print(f\"Number of voxels with max value: {np.sum(masked_data == np.max(masked_data))}\")\n",
    "                    \n",
    "                    flat_indices = np.argsort(masked_data.ravel())[::-1][:5]\n",
    "                    peak_indices = np.unravel_index(flat_indices, masked_data.shape)\n",
    "                    print(\"Top 5 peak voxels:\")\n",
    "                    for i in range(5):\n",
    "                        peak_coords = image.coord_transform(peak_indices[0][i], peak_indices[1][i], peak_indices[2][i], mean_zstat.affine)\n",
    "                        peak_value = masked_data[peak_indices[0][i], peak_indices[1][i], peak_indices[2][i]]\n",
    "                        print(f\"  Voxel {i+1}: coordinates {peak_coords}, value {peak_value}\")\n",
    "                    \n",
    "                    peak_idx = np.unravel_index(np.argmax(masked_data), masked_data.shape)\n",
    "                    print(f\"Selected peak voxel indices: {peak_idx}\")\n",
    "                    \n",
    "                    peak_coords = image.coord_transform(*peak_idx, mean_zstat.affine)\n",
    "                    print(f\"Peak coordinates before rounding: {peak_coords}\")\n",
    "                    \n",
    "                    # Round coordinates\n",
    "                    peak_coords = tuple(round(coord, 2) for coord in peak_coords)\n",
    "                    peak_value = masked_data[peak_idx]\n",
    "                    \n",
    "                    # Check for uniqueness\n",
    "                    existing_coords = roi_coords[roi_coords['roi'] == pr][['x', 'y', 'z']].values.tolist()\n",
    "                    if is_unique(peak_coords, existing_coords):\n",
    "                        roi_coords = pd.concat([roi_coords, pd.DataFrame({\n",
    "                            'run_combo': [f'{rc[0]}{rc[1]}'],\n",
    "                            'roi': [pr],\n",
    "                            'x': [peak_coords[0]],\n",
    "                            'y': [peak_coords[1]],\n",
    "                            'z': [peak_coords[2]],\n",
    "                            'peak_value': [peak_value]\n",
    "                        })], ignore_index=True)\n",
    "                    else:\n",
    "                        print(f\"Warning: Similar coordinates already exist for {pr}\")\n",
    "\n",
    "                    # Visualize ROI and peak voxel on MNI template\n",
    "                    display = plotting.plot_roi(roi, bg_img=mni_template,\n",
    "                                                title=f'{ss} - {pr} - Runs {rc[0]}{rc[1]}')\n",
    "                    display.add_markers([peak_coords], marker_color='r', marker_size=100)\n",
    "                    plt.savefig(f'{roi_dir}/{ss}_{pr}_runs{rc[0]}{rc[1]}_peak_mni.png')\n",
    "                    plt.close()\n",
    "\n",
    "                    print(f\"ROI: {pr}, Peak coordinates: {peak_coords}, Peak value: {peak_value}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "\n",
    "        print(f\"\\nExtracted ROI coordinates for subject {ss}:\")\n",
    "        print(roi_coords.to_string(index=False))\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_roi_coords()\n",
    "    print(\"ROI coordinate extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.7.24 1 pm, plots heat map of averaged and raw individual run's ROIs\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'hemispace'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "mni_parcel_dir = f'{curr_dir}/roiParcels'\n",
    "\n",
    "def visualize_roi_activation_raw():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "    #subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    subs = ['sub-025', 'sub-057', 'sub-059'] # Update this list as needed\n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = list(itertools.combinations(runs, 2))\n",
    "\n",
    "    # Load MNI152 template for visualization\n",
    "    mni_template = image.load_img('/opt/fsl/6.0.3/data/standard/MNI152_T1_2mm_brain.nii.gz')\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f'Visualizing activation for subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "\n",
    "        for rc in run_combos:\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = f'{exp_dir}/loc/run-0{rn}/1stLevel.feat/stats/zstat3_mni.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                    # Print summary statistics\n",
    "                    data = curr_run.get_fdata()\n",
    "                    print(f\"Run {rn} stats: mean={np.mean(data):.4f}, max={np.max(data):.4f}, min={np.min(data):.4f}, std={np.std(data):.4f}\")\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "            \n",
    "            # Manual averaging\n",
    "            mean_data = np.mean([run.get_fdata() for run in all_runs], axis=0)\n",
    "            mean_zstat = image.new_img_like(all_runs[0], mean_data)\n",
    "            \n",
    "            # Print summary statistics of the averaged data\n",
    "            print(f\"Averaged data stats: mean={np.mean(mean_data):.4f}, max={np.max(mean_data):.4f}, min={np.min(mean_data):.4f}, std={np.std(mean_data):.4f}\")\n",
    "\n",
    "            for pr in parcels:\n",
    "                roi_path = f'{mni_parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    # Create a masked version of the mean_zstat image\n",
    "                    masked_zstat = image.math_img('img1 * img2', img1=mean_zstat, img2=roi)\n",
    "\n",
    "                    # Visualize the activation within the ROI\n",
    "                    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                    fig.suptitle(f'{ss} - {pr} - Runs {rc[0]}{rc[1]} Activation')\n",
    "\n",
    "                    # Sagittal view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template,\n",
    "                                           display_mode='x', cut_coords=1,\n",
    "                                           threshold=0, colorbar=True, axes=ax1)\n",
    "                    ax1.set_title('Sagittal')\n",
    "\n",
    "                    # Coronal view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template,\n",
    "                                           display_mode='y', cut_coords=1,\n",
    "                                           threshold=0, colorbar=True, axes=ax2)\n",
    "                    ax2.set_title('Coronal')\n",
    "\n",
    "                    # Axial view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template,\n",
    "                                           display_mode='z', cut_coords=1,\n",
    "                                           threshold=0, colorbar=True, axes=ax3)\n",
    "                    ax3.set_title('Axial')\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    #plt.savefig(f'{roi_dir}/{ss}_{pr}_runs{rc[0]}{rc[1]}_activation.png')\n",
    "                    #plt.close()\n",
    "                    print(f\"Activation map saved for ROI: {pr}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "\n",
    "    print(\"ROI activation visualization completed.\")\n",
    "\n",
    "def visualize_roi_activation_combos():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "    #subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    subs = ['sub-025', 'sub-057', 'sub-059']  # Update this list as needed\n",
    "    \n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = list(itertools.combinations(runs, 2))\n",
    "\n",
    "    # Load MNI152 template for visualization\n",
    "    mni_template = image.load_img('/opt/fsl/6.0.3/data/standard/MNI152_T1_2mm_brain.nii.gz')\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f'Visualizing activation for subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "\n",
    "        for rc in run_combos:\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = f'{exp_dir}/loc/run-0{rn}/1stLevel.feat/stats/zstat3_mni.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "\n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "\n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "\n",
    "            for pr in parcels:\n",
    "                roi_path = f'{mni_parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    \n",
    "                    # Create a masked version of the mean_zstat image\n",
    "                    masked_zstat = image.math_img('img1 * img2', img1=mean_zstat, img2=roi)\n",
    "                    \n",
    "                    # Visualize the activation within the ROI\n",
    "                    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                    fig.suptitle(f'{ss} - {pr} - Runs {rc[0]}{rc[1]} Activation')\n",
    "                    \n",
    "                    # Sagittal view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template, \n",
    "                                        display_mode='x', cut_coords=1, \n",
    "                                        threshold=0, colorbar=True, axes=ax1)\n",
    "                    ax1.set_title('Sagittal')\n",
    "\n",
    "                    # Coronal view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template, \n",
    "                                        display_mode='y', cut_coords=1, \n",
    "                                        threshold=0, colorbar=True, axes=ax2)\n",
    "                    ax2.set_title('Coronal')\n",
    "\n",
    "                    # Axial view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template, \n",
    "                                        display_mode='z', cut_coords=1, \n",
    "                                        threshold=0, colorbar=True, axes=ax3)\n",
    "                    ax3.set_title('Axial')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    #plt.savefig(f'{roi_dir}/{ss}_{pr}_runs{rc[0]}{rc[1]}_activation.png')\n",
    "                    #plt.close()\n",
    "\n",
    "                    print(f\"Activation map saved for ROI: {pr}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "\n",
    "    print(\"ROI activation visualization completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #visualize_roi_activation_combos()\n",
    "    #visualize_roi_activation_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print psy and phys correctly \n",
    "\n",
    "# Define constants\n",
    "ss = '064'  # Subject ID\n",
    "tsk = 'loc'  # Task name\n",
    "tr = 2  # Repetition time\n",
    "vols = 184  # Number of volumes\n",
    "rc = [1, 2]  # Run combinations (unchangeable)\n",
    "roi_name = 'LO'  # ROI name\n",
    "exp = 'loc'  # Experiment name\n",
    "raw_dir = params.raw_dir  # Path to raw data\n",
    "n_time_points = 184  # Number of time points per run\n",
    "n_runs = 1  # Number of runs (adjust as needed)\n",
    "\n",
    "# Directories\n",
    "sub_dir = f'{study_dir}/sub-{ss}/ses-01/'\n",
    "roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "temp_dir = f'{raw_dir}/sub-{ss}/ses-01'\n",
    "cov_dir = f'{temp_dir}/covs'\n",
    "\n",
    "# Load and print psy data\n",
    "psy = make_psy_cov(rc, ss)  # Load psy covariates\n",
    "print(f'Psy data shape: {psy.shape}')\n",
    "\n",
    "# Plot psy data\n",
    "plt.figure(figsize=(30, 5))\n",
    "for run in range(n_runs):\n",
    "    plt.subplot(2, 1, run + 1)\n",
    "    plt.plot(np.arange(n_time_points), psy[:, run], label=f'Psy Run {run + 1}', color='blue')\n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('Psy Value')\n",
    "    plt.title(f'Psychophysiological Time Series - Run {run + 1}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Load ROI coordinates and process phys data\n",
    "roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords.csv')\n",
    "curr_coords = roi_coords[(roi_coords['task'] == tsk) & (roi_coords['roi'] == roi_name)]\n",
    "\n",
    "for rn in rc:\n",
    "    run_path = f'{temp_dir}/derivatives/fsl/loc/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz'\n",
    "    if os.path.exists(run_path):\n",
    "        curr_run = image.load_img(run_path)  # Load image data\n",
    "        curr_run = image.clean_img(curr_run, standardize=True)\n",
    "        if not curr_coords.empty:\n",
    "            coords = curr_coords[['x', 'y', 'z']].values[0].tolist()\n",
    "            phys = extract_roi_sphere(curr_run, coords)\n",
    "            print(f'Extracted phys data shape: {phys.shape} for ROI {roi_name} with coordinates {coords}')\n",
    "        else:\n",
    "            print(f'No coordinates found for ROI {roi_name} and task {tsk}')\n",
    "    else:\n",
    "        print(f\"File {run_path} does not exist.\")\n",
    "\n",
    "# Plot phys data\n",
    "plt.figure(figsize=(30, 5))\n",
    "for run in range(n_runs):\n",
    "    plt.subplot(2, 1, run + 1)\n",
    "    plt.plot(np.arange(n_time_points), phys[:, run], label=f'Phys Run {run + 1}', color='green')\n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('Phys Value')\n",
    "    plt.title(f'Physiological Time Series - Run {run + 1}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.7.24 fc_ppi - 8:00 pm || back to basics, corrected sphere_coords.csv and registered to standard space. \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, input_data\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.datasets import load_mni152_brain_mask, load_mni152_template\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/GitHub_Repos/ptoc/results'\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "whole_brain_mask = load_mni152_brain_mask()\n",
    "mni = load_mni152_template()\n",
    "brain_masker = input_data.NiftiMasker(whole_brain_mask,\n",
    "    smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "#sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "subs = ['sub-025']\n",
    "rois = ['LO']\n",
    "tsk = 'loc'\n",
    "\n",
    "run_num = 3\n",
    "run_combos = list(itertools.combinations(range(1, run_num + 1), 2))\n",
    "\n",
    "'''also Vlads code\n",
    "#this may have been a common point of issue\n",
    "for rn1 in range(1,run_num+1):\n",
    "    for rn2 in range(rn1+1,run_num+1):\n",
    "        run_combos.append([rn1,rn2])\n",
    "'''\n",
    "\n",
    "def extract_roi_sphere(img, coords):\n",
    "    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius = 6)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    phys = np.mean(seed_time_series, axis= 1)\n",
    "    #phys = (phys - np.mean(phys)) / np.std(phys) #TRY WITHOUT STANDARDIZING AT SOME POINT\n",
    "    phys = phys.reshape((phys.shape[0],1))\n",
    "    return phys\n",
    "\n",
    "def make_psy_cov(runs, ss):\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    vols, tr = 184, 2.0\n",
    "    times = np.arange(0, vols * len(runs) * tr, tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "    \n",
    "    for rn, run in enumerate(runs):\n",
    "        ss_num = ss.split('-')[1]\n",
    "        obj_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{run}_Object.txt'\n",
    "        scr_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{run}_Scramble.txt'\n",
    "        \n",
    "        if not os.path.exists(obj_cov_file) or not os.path.exists(scr_cov_file):\n",
    "            print(f'Covariate file not found for run {run}')\n",
    "            raise FileNotFoundError(f\"Missing covariate file for run {run}\")\n",
    "        \n",
    "        obj_cov = pd.read_csv(obj_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov = pd.read_csv(scr_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov['value'] *= -1\n",
    "        \n",
    "        curr_cov = pd.concat([obj_cov, scr_cov])\n",
    "        curr_cov['onset'] += rn * vols * tr\n",
    "        full_cov = pd.concat([full_cov, curr_cov])\n",
    "    \n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    \n",
    "    if full_cov['onset'].max() >= times[-1] or full_cov['onset'].min() < 0:\n",
    "        raise ValueError(\"Event onsets are outside the expected time range\")\n",
    "    \n",
    "    cov = full_cov.to_numpy()\n",
    "    \n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    \n",
    "    if len(psy) != vols * len(runs):\n",
    "        raise ValueError(f\"Generated psy does not match expected length. Expected {vols * len(runs)}, got {len(psy)}\")\n",
    "    \n",
    "    return psy\n",
    "\n",
    "'''most similar to vlad's code\n",
    "def make_psy_cov(runs, ss):\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    vols, tr = 184, 2.0\n",
    "    times = np.arange(0, vols * tr, tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for rn, run in enumerate(runs):\n",
    "        \n",
    "        ss_num = ss.split('-')[1]\n",
    "        obj_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_Object.txt'\n",
    "        scr_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_Scramble.txt'\n",
    "\n",
    "        if not os.path.exists(obj_cov_file) or not os.path.exists(scr_cov_file):\n",
    "            print(f'Covariate file not found for run {run}')\n",
    "            continue\n",
    "\n",
    "        obj_cov = pd.read_csv(obj_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov = pd.read_csv(scr_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov['value'] *= -1\n",
    "        \n",
    "        full_cov = pd.concat([full_cov, obj_cov, scr_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    cov = full_cov.to_numpy()\n",
    "    \n",
    "    #convolve to hrf\n",
    "    psy, name = glm.first_level.compute_regressor(cov.T, 'spm', times)\n",
    "    \n",
    "    return psy\n",
    "'''\n",
    "\n",
    "def conduct_analyses():\n",
    "    for ss in subs:\n",
    "        subject_start_time = time.time()\n",
    "        print(f\"Processing subject: {ss}\")\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01/'\n",
    "        roi_dir = f'{sub_dir}derivatives/rois'\n",
    "        temp_dir = f'{raw_dir}/{ss}/ses-01/derivatives/fsl/loc'\n",
    "        exp = 'loc'\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl/{exp}'\n",
    "        out_dir = f'{study_dir}/{ss}/ses-01/derivatives'\n",
    "        os.makedirs(f'{out_dir}/fc', exist_ok=True) #os.makedirs(f'{out_dir}/fc_ppi', exist_ok=True)\n",
    "        \n",
    "        roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords.csv')\n",
    "\n",
    "        for rr in rois:\n",
    "            all_runs_fc = []\n",
    "            all_runs_ppi = []\n",
    "            \n",
    "            print(f\"Processing ROI: {rr}\")\n",
    "            fc_file = f'{out_dir}/fc/{ss}_{rr}_{tsk}_fc.nii.gz'\n",
    "            ppi_file = f'{out_dir}/fc/{ss}_{rr}_{tsk}_ppi.nii.gz'\n",
    "            \n",
    "            do_fc = not os.path.exists(fc_file)\n",
    "            do_ppi = not os.path.exists(ppi_file)\n",
    "            \n",
    "            if not do_fc and not do_ppi:\n",
    "                print(f'Both FC and PPI files for {rr} already exist. Skipping...')\n",
    "                continue\n",
    "            \n",
    "            for rcn, rc in enumerate(run_combos):\n",
    "                curr_coords = roi_coords[(roi_coords['index'] == rcn) & \n",
    "                                            (roi_coords['task'] == tsk) & \n",
    "                                            (roi_coords['roi'] == rr)]\n",
    "                \n",
    "                peak_coords = curr_coords[['x', 'y', 'z']].values[0]\n",
    "                held_out_run = list(set(range(1, 4)) - set(rc))[0]\n",
    "                img4d = image.load_img(f'{exp_dir}/run-0{held_out_run}/1stLevel.feat/filtered_func_data_reg.nii.gz')\n",
    "                img4d = image.clean_img(img4d, standardize=True)\n",
    "                \n",
    "                phys = extract_roi_sphere(img4d, peak_coords)\n",
    "                psy = make_psy_cov([held_out_run], ss)  # Generate psy for the current run combination\n",
    "                #here is where it gets weird\n",
    "                \n",
    "                #combine phys (seed time series) and psy (task time series) into a regressor\n",
    "                confounds = pd.DataFrame({'psy': psy[:,0], 'phys': phys[:,0]})\n",
    "                \n",
    "                brain_time_series_ppi = brain_masker.fit_transform(img4d, confounds=[confounds])\n",
    "                brain_time_series_fc = brain_masker.fit_transform(img4d)\n",
    "                \n",
    "                if do_fc: # need to confirm analysis, is it psy or phys?\n",
    "                    # FC Analysis\n",
    "                    correlations_fc = np.dot(brain_time_series_fc.T, phys) / phys.shape[0]\n",
    "                    correlations_fc = np.arctanh(correlations_fc)\n",
    "                    correlation_fc_img = brain_masker.inverse_transform(correlations_fc.T)\n",
    "                    all_runs_fc.append(correlation_fc_img)\n",
    "                \n",
    "                if do_ppi:\n",
    "                    # PPI Analysis\n",
    "                    ppi = phys * psy\n",
    "                    ppi = ppi.reshape((ppi.shape[0],1))\n",
    "                    correlations_ppi = np.dot(brain_time_series_ppi.T, ppi) / ppi.shape[0]\n",
    "                    print(ss, rr, tsk, correlations_ppi.max())\n",
    "                    correlations_ppi = np.arctanh(correlations_ppi)\n",
    "                    correlations_ppi_img = brain_masker.inverse_transform(correlations_ppi.T)\n",
    "                    all_runs_ppi.append(correlations_ppi_img)\n",
    "\n",
    "            if do_fc:\n",
    "                mean_fc = image.mean_img(all_runs_fc)\n",
    "                nib.save(mean_fc, fc_file)\n",
    "                print(f'Saved FC result for {rr}')\n",
    "            \n",
    "            if do_ppi:\n",
    "                mean_ppi = image.mean_img(all_runs_ppi)\n",
    "                nib.save(mean_ppi, ppi_file)\n",
    "                print(f'Saved PPI result for {rr}')\n",
    "\n",
    "# Call the function\n",
    "conduct_analyses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Summary\n",
    "#pause before this section to review output with Vlad\n",
    "\n",
    "def create_summary():\n",
    "    \"\"\"\n",
    "    extract avg PPI in LO  and PFS\n",
    "    \"\"\"\n",
    "    ventral_rois = ['LO_toolloc']\n",
    "    #rois = [\"PPC_spaceloc\", \"PPC_distloc\", \"PPC_toolloc\"]\n",
    "    rois = [\"PPC_spaceloc\", \"APC_spaceloc\", \"APC_distloc\", \"APC_toolloc\"]\n",
    "    print(subs)\n",
    "    #For each ventral ROI\n",
    "    for lrv in ['l','r']:\n",
    "        \n",
    "        for vr in ventral_rois:\n",
    "            \n",
    "            summary_df = pd.DataFrame(columns = ['sub'] + ['l' + rr for rr in rois] + ['r' + rr for rr in rois])\n",
    "            #summary_df = pd.DataFrame(columns = ['sub'] + ['r' + rr for rr in rois])\n",
    "            ventral = f'{lrv}{vr}'\n",
    "            print(ventral)\n",
    "            \n",
    "            for ss in subs:\n",
    "                \n",
    "                sub_dir = f'{study_dir}/sub-{study}{ss}/ses-01/'\n",
    "                roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "                \n",
    "                #if os.path.exists(f'{roi_dir}/{ventral}_peak.nii.gz'):\n",
    "                ventral_mask = image.load_img(f'{roi_dir}/{ventral}.nii.gz')\n",
    "                ventral_mask = input_data.NiftiMasker(ventral_mask)\n",
    "                \n",
    "                \n",
    "                roi_mean = []\n",
    "                roi_mean.append(ss)\n",
    "                \n",
    "                #For each dorsal ROI\n",
    "                for lr in ['l','r']:\n",
    "                    for rr in rois:\n",
    "                        \n",
    "                        roi = f'{lr}{rr}'\n",
    "                        if os.path.exists(f'{out_dir}/sub-{study}{ss}_{roi}_fc.nii.gz'):\n",
    "                            ppi_img = image.load_img(f'{out_dir}/sub-{study}{ss}_{roi}_fc.nii.gz')\n",
    "                            #ppi_img  = image.smooth_img(ppi_img, 6)\n",
    "                            acts = ventral_mask.fit_transform(ppi_img)\n",
    "\n",
    "                            \n",
    "                            roi_mean.append(acts.mean())\n",
    "                        else:\n",
    "                            roi_mean.append(np.nan)\n",
    "            #pdb.set_trace()\n",
    "                summary_df = summary_df.append(pd.Series(roi_mean, index = summary_df.columns), ignore_index = True)\n",
    "        #print(ventral)\n",
    "            summary_df.to_csv(f'{results_dir}/ppi/{ventral}_fc{file_suf}.csv', index=False)\n",
    "        #summary_df.iloc[:, 1:].mean().plot.bar()\n",
    "        #plt.pause(0.0001)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                    print(ss, roi)\n",
    "\n",
    "#subs = list(range(2018,2015,-1))\n",
    "#print(subs)\n",
    "#extract_roi_coords()\n",
    "#conduct_ppi()\n",
    "subs = list(range(1001,1013)) + list(range(2013,2019))\n",
    "create_summary()\n",
    "#make_psy_cov(1001,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: sub-107\n",
      "Processing ROI: LO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csimmon2/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/image/image.py:211: UserWarning: The parameter 'fwhm' for smoothing is specified as 0. Setting it to None (no smoothing will be performed)\n",
      "  warnings.warn(\"The parameter 'fwhm' for smoothing is specified \"\n",
      "/home/csimmon2/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/image/image.py:211: UserWarning: The parameter 'fwhm' for smoothing is specified as 0. Setting it to None (no smoothing will be performed)\n",
      "  warnings.warn(\"The parameter 'fwhm' for smoothing is specified \"\n",
      "/home/csimmon2/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/image/image.py:211: UserWarning: The parameter 'fwhm' for smoothing is specified as 0. Setting it to None (no smoothing will be performed)\n",
      "  warnings.warn(\"The parameter 'fwhm' for smoothing is specified \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FC result for LO\n",
      "Saved PPI result for LO\n",
      "Processing ROI: pIPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csimmon2/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/image/image.py:211: UserWarning: The parameter 'fwhm' for smoothing is specified as 0. Setting it to None (no smoothing will be performed)\n",
      "  warnings.warn(\"The parameter 'fwhm' for smoothing is specified \"\n",
      "/home/csimmon2/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/image/image.py:211: UserWarning: The parameter 'fwhm' for smoothing is specified as 0. Setting it to None (no smoothing will be performed)\n",
      "  warnings.warn(\"The parameter 'fwhm' for smoothing is specified \"\n",
      "/home/csimmon2/anaconda3/envs/fmri/lib/python3.9/site-packages/nilearn/image/image.py:211: UserWarning: The parameter 'fwhm' for smoothing is specified as 0. Setting it to None (no smoothing will be performed)\n",
      "  warnings.warn(\"The parameter 'fwhm' for smoothing is specified \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FC result for pIPS\n",
      "Saved PPI result for pIPS\n"
     ]
    }
   ],
   "source": [
    "#fc_ppi all in subject space\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, input_data\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import nibabel as nib\n",
    "import sys\n",
    "\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "subs = ['sub-107']\n",
    "rois = ['LO', 'pIPS']\n",
    "run_num = 3\n",
    "runs = list(range(1, run_num + 1))\n",
    "run_combos = [[rn1, rn2] for rn1 in range(1, run_num + 1) for rn2 in range(rn1 + 1, run_num + 1)]\n",
    "\n",
    "def extract_roi_sphere(img, coords):\n",
    "    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius=6)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    phys = np.mean(seed_time_series, axis=1).reshape(-1, 1)\n",
    "    return phys\n",
    "\n",
    "def make_psy_cov(runs, ss):\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    vols, tr = 184, 2.0\n",
    "    times = np.arange(0, vols * tr, tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for rn in runs:\n",
    "        ss_num = ss.split('-')[1]\n",
    "        obj_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_Object.txt'\n",
    "        scr_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_Scramble.txt'\n",
    "\n",
    "        if not os.path.exists(obj_cov_file) or not os.path.exists(scr_cov_file):\n",
    "            print(f'Covariate file not found for run {rn}')\n",
    "            continue\n",
    "\n",
    "        obj_cov = pd.read_csv(obj_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov = pd.read_csv(scr_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov['value'] *= -1\n",
    "        full_cov = pd.concat([full_cov, obj_cov, scr_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    cov = full_cov.to_numpy()\n",
    "    valid_onsets = cov[:, 0] < times[-1]\n",
    "    cov = cov[valid_onsets]\n",
    "\n",
    "    if cov.shape[0] == 0:\n",
    "        print('No valid covariate data after filtering. Returning zeros array.')\n",
    "        return np.zeros((vols, 1))\n",
    "\n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    return psy\n",
    "\n",
    "def conduct_analyses():\n",
    "    for ss in subs:\n",
    "        print(f\"Processing subject: {ss}\")\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01/'\n",
    "        roi_dir = f'{sub_dir}derivatives/rois'\n",
    "        temp_dir = f'{raw_dir}/{ss}/ses-01/derivatives/fsl/loc'\n",
    "        \n",
    "        roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords.csv')\n",
    "        \n",
    "        out_dir = f'{study_dir}/{ss}/ses-01/derivatives'\n",
    "        os.makedirs(f'{out_dir}/fc', exist_ok=True)\n",
    "        os.makedirs(f'{out_dir}/fc', exist_ok=True)\n",
    "        \n",
    "        # subject-specific brain mask\n",
    "        def get_subject_mask(ss):\n",
    "            mask_path  = f'{raw_dir}/{ss}/ses-01/anat/{ss}_ses-01_T1w_brain_mask.nii.gz'\n",
    "            return nib.load(mask_path)\n",
    "        \n",
    "        # Load subject-specific mask\n",
    "        whole_brain_mask = get_subject_mask(ss)\n",
    "        brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "        for tsk in ['loc']:\n",
    "            for rr in rois:\n",
    "                print(f\"Processing ROI: {rr}\")\n",
    "                \n",
    "                fc_file = f'{out_dir}/fc/{ss}_{rr}_{tsk}_fc.nii.gz'\n",
    "                ppi_file = f'{out_dir}/fc/{ss}_{rr}_{tsk}_ppi.nii.gz'\n",
    "                \n",
    "                do_fc = not os.path.exists(fc_file)\n",
    "                do_ppi = not os.path.exists(ppi_file)\n",
    "                \n",
    "                if not do_fc and not do_ppi:\n",
    "                    print(f'Both FC and PPI files for {rr} already exist. Skipping...')\n",
    "                    continue\n",
    "                \n",
    "                all_runs_fc = []\n",
    "                all_runs_ppi = []\n",
    "                \n",
    "                for rcn, rc in enumerate(run_combos):\n",
    "                    curr_coords = roi_coords[(roi_coords['index'] == rcn) & (roi_coords['task'] == tsk) & (roi_coords['roi'] == rr)]\n",
    "                    coords = curr_coords[['x', 'y', 'z']].values.tolist()[0]\n",
    "                    \n",
    "                    filtered_list = [image.clean_img(image.load_img(f'{temp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz'), standardize=True) for rn in rc]\n",
    "                    img4d = image.concat_imgs(filtered_list)\n",
    "                    \n",
    "                    phys = extract_roi_sphere(img4d, coords)\n",
    "                    \n",
    "                    # Ensure phys length matches the number of volumes\n",
    "                    if phys.shape[0] > 184 * len(rc):\n",
    "                        phys = phys[:184 * len(rc)]\n",
    "                    \n",
    "                    brain_time_series = brain_masker.fit_transform(img4d)\n",
    "                    \n",
    "                    if do_fc:\n",
    "                        # FC Analysis\n",
    "                        correlations = np.dot(brain_time_series.T, phys) / phys.shape[0]\n",
    "                        correlations = np.arctanh(correlations.ravel())\n",
    "                        correlation_img = brain_masker.inverse_transform(correlations)\n",
    "                        all_runs_fc.append(correlation_img)\n",
    "                    \n",
    "                    if do_ppi:\n",
    "                        # PPI Analysis\n",
    "                        psy = make_psy_cov(rc, ss)  # Generate psy for the current run combination\n",
    "                        \n",
    "                        # Ensure psy length matches phys\n",
    "                        if psy.shape[0] > phys.shape[0]:\n",
    "                            psy = psy[:phys.shape[0]]\n",
    "                        elif psy.shape[0] < phys.shape[0]:\n",
    "                            phys = phys[:psy.shape[0]]\n",
    "                            brain_time_series = brain_time_series[:psy.shape[0]]\n",
    "                        \n",
    "                        ppi_regressor = phys * psy\n",
    "                        ppi_correlations = np.dot(brain_time_series.T, ppi_regressor) / ppi_regressor.shape[0]\n",
    "                        ppi_correlations = np.arctanh(ppi_correlations.ravel())\n",
    "                        ppi_img = brain_masker.inverse_transform(ppi_correlations)\n",
    "                        all_runs_ppi.append(ppi_img)\n",
    "                \n",
    "                if do_fc:\n",
    "                    mean_fc = image.mean_img(all_runs_fc)\n",
    "                    nib.save(mean_fc, fc_file)\n",
    "                    print(f'Saved FC result for {rr}')e\n",
    "                \n",
    "                if do_ppi:\n",
    "                    mean_ppi = image.mean_img(all_runs_ppi)\n",
    "                    nib.save(mean_ppi, ppi_file)\n",
    "                    print(f'Saved PPI result for {rr}')\n",
    "\n",
    "# Call the function\n",
    "conduct_analyses()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85d6a1f04e70c5556da1eb33c5679a806be4c5365a0d8ae0b55875cb552fe2b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
