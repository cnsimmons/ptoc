{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,curr_dir)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import statsmodels.api as s\n",
    "from sklearn import metrics\n",
    "\n",
    "import pdb\n",
    "import ptoc_params as params\n",
    "\n",
    "from plotnine import *\n",
    "#from plotnine import ggplot, aes, geom_point\n",
    "\n",
    "\n",
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load additional libraries\n",
    "from nilearn import image, plotting, input_data, glm\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nibabel as nib\n",
    "import statsmodels.api as sm\n",
    "from nilearn.datasets import load_mni152_brain_mask, load_mni152_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = params.data_dir\n",
    "results_dir = params.results_dir\n",
    "fig_dir = params.fig_dir\n",
    "\n",
    "sub_info = params.sub_info\n",
    "task_info = params.task_info\n",
    "\n",
    "suf = params.suf\n",
    "rois = params.rois\n",
    "hemis = params.hemis\n",
    "\n",
    "#load subject info\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "\n",
    "#mni = load_mni152_brain_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''exp info'''\n",
    "#subs = ['sub-064']  # Run for one subject initially\n",
    "#subs = sub_info['sub'].tolist()\n",
    "\n",
    "#Just controls\n",
    "subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "study = 'ptoc'\n",
    "data_dir = 'hemispace'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "out_dir = f'{study_dir}/derivatives/fc'\n",
    "results_dir = '/user_data/csimmon2/GitHub_Repos/ptoc/results'\n",
    "exp = ''\n",
    "rois = ['LO']  # Run for one ROI initially\n",
    "control_tasks = ['loc']\n",
    "file_suf = ''\n",
    "\n",
    "'''scan params'''\n",
    "tr = 1\n",
    "vols = 321\n",
    "\n",
    "whole_brain_mask = load_mni152_brain_mask()\n",
    "mni = load_mni152_template()\n",
    "brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "'''run info'''\n",
    "run_num = 3\n",
    "runs = list(range(1, run_num + 1))\n",
    "run_combos = []\n",
    "\n",
    "for rn1 in range(1, run_num + 1):\n",
    "    for rn2 in range(rn1 + 1, run_num + 1):\n",
    "        run_combos.append([rn1, rn2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define seed region in each roi \n",
    "# peak activation in ROI in first run, second run, etc. \n",
    "# Saved in sphere coords, this one creates a loop for runs, so update to include the list runs. \n",
    "# Creates a list to loop thorugh all possible combinations of runs\n",
    "\n",
    "def extract_roi_coords(sub_info):\n",
    "    \"\"\"\n",
    "    Define ROIs\n",
    "    \"\"\"\n",
    "    parcels = ['V1', 'aIPS', 'PFS', 'pIPS', 'LO']\n",
    "    subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f'Processing subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        os.makedirs(f'{roi_dir}/spheres', exist_ok=True)\n",
    "        \n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "        parcel_dir = f'{roi_dir}/parcels'\n",
    "        roi_coords = pd.DataFrame(columns=['index', 'task', 'roi', 'x', 'y', 'z'])\n",
    "\n",
    "        # Process mean runs\n",
    "        for rcn, rc in enumerate(run_combos):\n",
    "            roi_runs = [ele for ele in runs if ele not in rc]\n",
    "            \n",
    "            all_runs = []\n",
    "            for rn in roi_runs:\n",
    "                curr_run_path = f'{exp_dir}/loc/run-0{rn}/1stLevel.feat/stats/zstat3_reg.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            if all_runs:\n",
    "                mean_zstat = image.mean_img(all_runs)\n",
    "                affine = mean_zstat.affine\n",
    "\n",
    "                for pr in parcels:\n",
    "                    roi_path = f'{parcel_dir}/{pr}.nii.gz'\n",
    "                    if os.path.exists(roi_path):\n",
    "                        roi = image.load_img(roi_path)\n",
    "                        roi = image.math_img('img > 0', img=roi)\n",
    "\n",
    "                        coords = plotting.find_xyz_cut_coords(mean_zstat, mask_img=roi, activation_threshold=0.99)\n",
    "                        \n",
    "                        masked_stat = image.math_img('img1 * img2', img1=roi, img2=mean_zstat)\n",
    "                        masked_stat = image.get_data(masked_stat)\n",
    "                        np_coords = np.where(masked_stat == np.max(masked_stat))\n",
    "                        \n",
    "                        curr_coords = pd.Series([rcn, 'loc', pr] + coords, index=roi_coords.columns)\n",
    "                        roi_coords = roi_coords.append(curr_coords, ignore_index=True)\n",
    "\n",
    "        # Process control highlevel once per ROI\n",
    "        control_zstat_path = f'{exp_dir}/loc/HighLevel.gfeat/cope3.feat/stats/zstat1.nii.gz'\n",
    "        if os.path.exists(control_zstat_path):\n",
    "            control_zstat = image.load_img(control_zstat_path)\n",
    "            \n",
    "            for pr in parcels:\n",
    "                roi_path = f'{parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    roi = image.math_img('img > 0', img=roi)\n",
    "                    \n",
    "                    coords = plotting.find_xyz_cut_coords(control_zstat, mask_img=roi, activation_threshold=0.99)\n",
    "                    \n",
    "                    curr_coords = pd.Series([len(run_combos), 'highlevel', pr] + coords, index=roi_coords.columns)\n",
    "                    roi_coords = roi_coords.append(curr_coords, ignore_index=True)\n",
    "                else:\n",
    "                    print(f'File does not exist: {roi_path}')\n",
    "        else:\n",
    "            print(f'File does not exist: {control_zstat_path}')\n",
    "            \n",
    "        roi_coords.to_csv(f'{roi_dir}/spheres/sphere_coords.csv', index=False)\n",
    "\n",
    "# Call the function\n",
    "#extract_roi_coords(sub_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi_sphere(img, coords):\n",
    "    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius=6)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    \n",
    "    phys = np.mean(seed_time_series, axis=1)\n",
    "    phys = phys.reshape((phys.shape[0], 1))\n",
    "    \n",
    "    return phys\n",
    "\n",
    "\n",
    "def make_psy_cov(runs, sub):\n",
    "    sub_dir = f'{study_dir}/sub-{study}{sub}/ses-01/'\n",
    "    cov_dir = f'{sub_dir}/covs'\n",
    "    times = np.arange(0, vols * len(runs), tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "    for rn, run in enumerate(runs):    \n",
    "        curr_cov = pd.read_csv(f'{cov_dir}/ptoc_{study}{sub}_Run{run}_SA.txt', sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        curr_cont = pd.read_csv(f'{cov_dir}/ptoc_{study}{sub}_Run{run}_FT.txt', sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        curr_cont.iloc[:, 2] = curr_cont.iloc[:, 2] * -1\n",
    "        \n",
    "        curr_cov = curr_cov.append(curr_cont)\n",
    "        curr_cov['onset'] = curr_cov['onset'] + (vols * rn)\n",
    "        full_cov = full_cov.append(curr_cov)\n",
    "        \n",
    "    full_cov = full_cov.sort_values(by=['onset'])\n",
    "    cov = full_cov.to_numpy()\n",
    "\n",
    "    psy, name = glm.first_level.compute_regressor(cov.T, 'spm', times)\n",
    "\n",
    "    return psy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_ppi():\n",
    "    for ss in subs:\n",
    "        print(ss)\n",
    "        sub_dir = f'{study_dir}/sub-{study}{ss}/ses-01/'\n",
    "        cov_dir = f'{sub_dir}/covs'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl/{exp}'\n",
    "\n",
    "        roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords.csv')\n",
    "\n",
    "        for tsk in ['loc']:\n",
    "            for rr in dorsal_rois:\n",
    "                all_runs = []\n",
    "                for rcn, rc in enumerate(run_combos):\n",
    "                    curr_coords = roi_coords[(roi_coords['index'] == rcn) & (roi_coords['task'] == tsk) & (roi_coords['roi'] == rr)]\n",
    "\n",
    "                    filtered_list = []\n",
    "                    for rn in rc:\n",
    "                        curr_run = image.load_img(f'{exp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz')\n",
    "                        curr_run = image.clean_img(curr_run, standardize=True)\n",
    "                        filtered_list.append(curr_run)\n",
    "                        \n",
    "                    img4d = image.concat_imgs(filtered_list)\n",
    "                    phys = extract_roi_sphere(img4d, curr_coords[['x', 'y', 'z']].values.tolist()[0])\n",
    "                    psy = make_psy_cov(rc, ss)\n",
    "\n",
    "                    confounds = pd.DataFrame(columns=['psy', 'phys'])\n",
    "                    confounds['psy'] = psy[:, 0]\n",
    "                    confounds['phys'] = phys[:, 0]\n",
    "\n",
    "                    ppi = psy * phys\n",
    "                    ppi = ppi.reshape((ppi.shape[0], 1))\n",
    "\n",
    "                    brain_time_series = brain_masker.fit_transform(img4d, confounds=[confounds])\n",
    "                    \n",
    "                    seed_to_voxel_correlations = (np.dot(brain_time_series.T, ppi) / ppi.shape[0])\n",
    "                    print(ss, rr, tsk, seed_to_voxel_correlations.max())\n",
    "                    \n",
    "                    seed_to_voxel_correlations = np.arctanh(seed_to_voxel_correlations)\n",
    "                    seed_to_voxel_correlations_img = brain_masker.inverse_transform(seed_to_voxel_correlations.T)\n",
    "                    \n",
    "                    all_runs.append(seed_to_voxel_correlations_img)\n",
    "\n",
    "                mean_fc = image.mean_img(all_runs)\n",
    "                    \n",
    "                nib.save(mean_fc, f'{out_dir}/sub-{study}{ss}_{rr}_{tsk}_ppi.nii.gz')\n",
    "\n",
    "conduct_ppi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary():\n",
    "    ventral_rois = ['LO_toolloc']\n",
    "    rois = [\"PPC_spaceloc\"]\n",
    "    print(subs)\n",
    "    \n",
    "    for lrv in ['l', 'r']:\n",
    "        for vr in ventral_rois:\n",
    "            summary_df = pd.DataFrame(columns=['sub'] + ['l' + rr for rr in rois] + ['r' + rr for rr in rois])\n",
    "            ventral = f'{lrv}{vr}'\n",
    "            print(ventral)\n",
    "            \n",
    "            for ss in subs:\n",
    "                sub_dir = f'{study_dir}/sub-{study}{ss}/ses-01/'\n",
    "                roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "                \n",
    "                ventral_mask = image.load_img(f'{roi_dir}/{ventral}.nii.gz')\n",
    "                ventral_mask = NiftiMasker(ventral_mask)\n",
    "                \n",
    "                roi_mean = []\n",
    "                roi_mean.append(ss)\n",
    "                \n",
    "                for lr in ['l', 'r']:\n",
    "                    for rr in rois:\n",
    "                        roi = f'{roi_dir}/{lr}{rr}.nii.gz'\n",
    "                        fc_img = image.load_img(f'{out_dir}/sub-{study}{ss}_{lr}{rr}_ppi.nii.gz')\n",
    "                        \n",
    "                        mask_img = ventral_mask.fit_transform(fc_img)\n",
    "                        mean_val = mask_img.mean()\n",
    "                        roi_mean.append(mean_val)\n",
    "                \n",
    "                summary_df.loc[len(summary_df)] = roi_mean\n",
    "            \n",
    "            summary_df.to_csv(f'{results_dir}/ppi_summary_{ventral}.csv', index=False)\n",
    "            \n",
    "create_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these functions to run them\n",
    "# extract_roi_coords()\n",
    "# conduct_ppi()\n",
    "# create_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85d6a1f04e70c5556da1eb33c5679a806be4c5365a0d8ae0b55875cb552fe2b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
