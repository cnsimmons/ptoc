{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n.p check input at native or standard, check mask as native or standard, check time series, check parameters too of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 12:26:25,416 - INFO - Running GCA with searchlight for Object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 12:26:25,464 - INFO - Processing run combination [1, 2] for subject sub-025\n",
      "2024-10-08 12:33:56,145 - INFO - Concatenated image shape: (176, 256, 256, 368)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Data given cannot be loaded because it is not compatible with nibabel format:\n0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48585/2247890664.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mconduct_gca_searchlight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;31m#summarize_gca_searchlight()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48585/2247890664.py\u001b[0m in \u001b[0;36mconduct_gca_searchlight\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msphere_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_searchlight_sphere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0msphere_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_searchlight_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg4d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msphere_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msphere_ts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpsy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48585/2247890664.py\u001b[0m in \u001b[0;36mextract_searchlight_timeseries\u001b[0;34m(img, sphere_mask)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_searchlight_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msphere_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmasked_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msphere_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36mapply_mask\u001b[0;34m(imgs, mask_img, dtype, smoothing_fwhm, ensure_finite)\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mspread\u001b[0m \u001b[0macross\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \"\"\"\n\u001b[0;32m--> 800\u001b[0;31m     \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_affine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_mask_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_img_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_affine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \"\"\"\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             )\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot concatenate empty objects\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             )\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot concatenate empty objects\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             )\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot concatenate empty objects\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;34m\"Data given cannot be loaded because it is\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m\" not compatible with nibabel format:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;34m+\u001b[0m \u001b[0m_repr_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshorten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         )\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Data given cannot be loaded because it is not compatible with nibabel format:\n0.0"
     ]
    }
   ],
   "source": [
    "##keep for now I feel like it is close to working\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, input_data\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import sys\n",
    "import nibabel as nib\n",
    "import logging\n",
    "from nilearn.image import new_img_like\n",
    "from nilearn.masking import apply_mask, unmask\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "localizer = 'Object'  # scramble or object. This is the localizer task.\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "# Load subject information\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "sub_info = sub_info[sub_info['group'] == 'control']\n",
    "subs = sub_info['sub'].tolist()\n",
    "# subs = ['sub-068']  # Uncomment for testing\n",
    "\n",
    "rois = ['pIPS', 'LO']\n",
    "hemispheres = ['left', 'right']\n",
    "run_num = 3\n",
    "runs = list(range(1, run_num + 1))\n",
    "run_combos = [[rn1, rn2] for rn1 in range(1, run_num + 1) for rn2 in range(rn1 + 1, run_num + 1)]\n",
    "\n",
    "def create_searchlight_sphere(center, radius, mask):\n",
    "    sphere = np.zeros(mask.shape)\n",
    "    x, y, z = np.ogrid[:mask.shape[0], :mask.shape[1], :mask.shape[2]]\n",
    "    mask_x, mask_y, mask_z = center\n",
    "    dist_from_center = np.sqrt((x - mask_x)**2 + (y - mask_y)**2 + (z - mask_z)**2)\n",
    "    sphere[dist_from_center <= radius] = 1\n",
    "    return sphere\n",
    "\n",
    "def extract_searchlight_timeseries(img, sphere_mask):\n",
    "    masked_data = apply_mask(img, sphere_mask)\n",
    "    return np.mean(masked_data, axis=1).reshape(-1, 1)\n",
    "\n",
    "def extract_roi_sphere(img, coords):\n",
    "    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius=6)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    phys = np.mean(seed_time_series, axis=1).reshape(-1, 1)\n",
    "    return phys  # Return non-standardized time series\n",
    "\n",
    "def make_psy_cov(runs, ss):\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    vols_per_run, tr = 184, 2.0\n",
    "    total_vols = vols_per_run * len(runs)\n",
    "    times = np.arange(0, total_vols * tr, tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for i, rn in enumerate(runs):\n",
    "        ss_num = ss.split('-')[1]\n",
    "        obj_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_{localizer}.txt'\n",
    "\n",
    "        if not os.path.exists(obj_cov_file):\n",
    "            logging.warning(f'Covariate file not found for run {rn}')\n",
    "            continue\n",
    "\n",
    "        obj_cov = pd.read_csv(obj_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        \n",
    "        if i > 0:\n",
    "            obj_cov['onset'] += i * vols_per_run * tr\n",
    "        \n",
    "        full_cov = pd.concat([full_cov, obj_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    cov = full_cov.to_numpy()\n",
    "    valid_onsets = cov[:, 0] < times[-1]\n",
    "    cov = cov[valid_onsets]\n",
    "\n",
    "    if cov.shape[0] == 0:\n",
    "        logging.warning('No valid covariate data after filtering. Returning zeros array.')\n",
    "        return np.zeros((total_vols, 1))\n",
    "\n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    psy[psy > 0] = 1\n",
    "    psy[psy <= 0] = 0\n",
    "    return psy\n",
    "\n",
    "def extract_cond_ts(ts, cov):\n",
    "    block_ind = (cov==1)\n",
    "    block_ind = np.insert(block_ind, 0, True)\n",
    "    block_ind = np.delete(block_ind, len(block_ind)-1)\n",
    "    block_ind = (cov == 1).reshape((len(cov))) | block_ind\n",
    "    return ts[block_ind]\n",
    "\n",
    "def conduct_gca_searchlight():\n",
    "    logging.info(f'Running GCA with searchlight for {localizer}...')\n",
    "    tasks = ['loc']\n",
    "    \n",
    "    # Load whole-brain mask\n",
    "    whole_brain_mask = nib.load(f'{curr_dir}/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz')\n",
    "    mask_data = whole_brain_mask.get_fdata().astype(bool)\n",
    "    \n",
    "    for ss in subs:\n",
    "        sub_summary = pd.DataFrame(columns=['sub', 'fold', 'task', 'center_x', 'center_y', 'center_z', 'f_diff'])\n",
    "        \n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01/'\n",
    "        temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "        exp_dir = f'{temp_dir}/derivatives/fsl/loc'\n",
    "        output_dir = f'{sub_dir}/derivatives/gca_searchlight'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        roi_coords = pd.read_csv(f'{sub_dir}/derivatives/rois/spheres/sphere_coords_hemisphere.csv')\n",
    "\n",
    "        for rcn, rc in enumerate(run_combos):\n",
    "            logging.info(f\"Processing run combination {rc} for subject {ss}\")\n",
    "            \n",
    "            filtered_list = []\n",
    "            for rn in rc:\n",
    "                curr_run = nib.load(f'{exp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz')\n",
    "                curr_run_data = curr_run.get_fdata()\n",
    "                curr_run_cleaned = image.clean_img(curr_run)\n",
    "                filtered_list.append(curr_run_cleaned)\n",
    "\n",
    "            img4d = image.concat_imgs(filtered_list)\n",
    "            affine = curr_run.affine\n",
    "            logging.info(f\"Concatenated image shape: {img4d.shape}\")\n",
    "\n",
    "            psy = make_psy_cov(rc, ss)\n",
    "            \n",
    "            f_diff_3d = np.zeros(mask_data.shape)\n",
    "            \n",
    "            # Iterate over all voxels in the brain mask\n",
    "            for x, y, z in zip(*np.where(mask_data)):\n",
    "                sphere_mask = create_searchlight_sphere((x, y, z), radius=6, mask=mask_data)\n",
    "                sphere_ts = extract_searchlight_timeseries(img4d, sphere_mask)\n",
    "                \n",
    "                if sphere_ts.shape[0] != psy.shape[0]:\n",
    "                    logging.warning(f\"Mismatch in volumes: sphere_ts has {sphere_ts.shape[0]}, psy has {psy.shape[0]}\")\n",
    "                    continue\n",
    "                \n",
    "                sphere_phys = extract_cond_ts(sphere_ts, psy)\n",
    "                \n",
    "                # Perform GCA between the sphere and a reference region (e.g., pIPS)\n",
    "                pips_coords = roi_coords[(roi_coords['index'] == rcn) & \n",
    "                                         (roi_coords['task'] == 'loc') & \n",
    "                                         (roi_coords['roi'] == 'pIPS') &\n",
    "                                         (roi_coords['hemisphere'] == 'right')]\n",
    "                \n",
    "                if pips_coords.empty:\n",
    "                    logging.warning(f\"No coordinates found for pIPS, run combo {rc}\")\n",
    "                    continue\n",
    "                \n",
    "                pips_ts = extract_roi_sphere(img4d, pips_coords[['x', 'y', 'z']].values.tolist()[0])\n",
    "                pips_phys = extract_cond_ts(pips_ts, psy)\n",
    "                \n",
    "                neural_ts = pd.DataFrame({\n",
    "                    'sphere': sphere_phys.ravel(),\n",
    "                    'pips': pips_phys.ravel()\n",
    "                })\n",
    "                \n",
    "                gc_res_sphere = grangercausalitytests(neural_ts[['pips', 'sphere']], 1, verbose=False)\n",
    "                gc_res_pips = grangercausalitytests(neural_ts[['sphere', 'pips']], 1, verbose=False)\n",
    "                \n",
    "                f_diff = gc_res_sphere[1][0]['ssr_ftest'][0] - gc_res_pips[1][0]['ssr_ftest'][0]\n",
    "                \n",
    "                f_diff_3d[x, y, z] = f_diff\n",
    "                \n",
    "                curr_data = pd.Series([ss, rcn, 'loc', x, y, z, f_diff], index=sub_summary.columns)\n",
    "                sub_summary = sub_summary.append(curr_data, ignore_index=True)\n",
    "        \n",
    "        logging.info(f'Completed GCA searchlight for subject {ss}')\n",
    "        sub_summary.to_csv(f'{output_dir}/gca_searchlight_summary_{localizer.lower()}.csv', index=False)\n",
    "        \n",
    "        # Save the 3D nifti image of f_diff values\n",
    "        f_diff_3d = f_diff_3d.astype('float64')  # Convert to double precision\n",
    "        f_diff_3d[np.isnan(f_diff_3d)] = 0  # Replace NaNs with zeros\n",
    "        f_diff_img = nib.Nifti1Image(f_diff_3d, affine)\n",
    "        nib.save(f_diff_img, f'{output_dir}/gca_searchlight_f_diff_{localizer.lower()}.nii.gz')\n",
    "\n",
    "def summarize_gca_searchlight():\n",
    "    logging.info('Creating summary across subjects for searchlight GCA...')\n",
    "    \n",
    "    all_subjects_data = []\n",
    "    \n",
    "    for ss in subs:\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01/'\n",
    "        data_dir = f'{sub_dir}/derivatives/gca_searchlight'\n",
    "        \n",
    "        curr_df = pd.read_csv(f'{data_dir}/gca_searchlight_summary_{localizer.lower()}.csv')\n",
    "        curr_df['sub'] = ss\n",
    "        all_subjects_data.append(curr_df)\n",
    "    \n",
    "    df_all = pd.concat(all_subjects_data, ignore_index=True)\n",
    "    \n",
    "    # Calculate mean and std of f_diff across subjects for each voxel\n",
    "    df_summary = df_all.groupby(['center_x', 'center_y', 'center_z'])['f_diff'].agg(['mean', 'std']).reset_index()\n",
    "    df_summary.columns = ['x', 'y', 'z', 'mean_f_diff', 'std_f_diff']\n",
    "    \n",
    "    output_dir = f\"{results_dir}/gca_searchlight\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    summary_file = f\"{output_dir}/all_subjects_gca_searchlight_summary_{localizer.lower()}.csv\"\n",
    "    df_summary.to_csv(summary_file, index=False)\n",
    "    \n",
    "    logging.info(f'Summary across subjects completed and saved to {summary_file}')\n",
    "    print(df_summary.head())\n",
    "    \n",
    "    # Create and save a 3D nifti image of mean f_diff values\n",
    "    whole_brain_mask = nib.load(f'{curr_dir}/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz')\n",
    "    mean_f_diff_3d = np.zeros(whole_brain_mask.shape)\n",
    "    for _, row in df_summary.iterrows():\n",
    "        mean_f_diff_3d[int(row['x']), int(row['y']), int(row['z'])] = row['mean_f_diff']\n",
    "    \n",
    "    mean_f_diff_img = new_img_like(whole_brain_mask, mean_f_diff_3d)\n",
    "    nib.save(mean_f_diff_img, f'{output_dir}/gca_searchlight_mean_f_diff_{localizer.lower()}.nii.gz')\n",
    "    \n",
    "    return df_summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    conduct_gca_searchlight()\n",
    "    #summarize_gca_searchlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries loaded...\n",
      "['sub-025'] ['pIPS']\n",
      "Searchlight setup ...\n",
      "Loading data...\n",
      "Loading run 1\n",
      "Run 1 shape: (176, 256, 256, 184)\n",
      "Memory usage after run 1: 34.21418762207031 MB\n",
      "Loading run 2\n",
      "Run 2 shape: (176, 256, 256, 184)\n",
      "Memory usage after run 2: 50.026695251464844 MB\n",
      "Data loaded. Concatenating...\n",
      "Concatenated data shape: (176, 256, 256, 368)\n",
      "Final memory usage: 81.65162658691406 MB\n",
      "Data concatenated...\n",
      "bold_vol type: <class 'numpy.ndarray'>\n",
      "bold_vol shape: (176, 256, 256, 368)\n",
      "bold_vol dtype: float64\n",
      "Extracting seed time series...\n",
      "Loading seed ROI from: /lab_data/behrmannlab/vlad/ptoc/sub-025/ses-01/derivatives/rois/spheres_nifti/sub-025_pIPS_left_loc_sphere_r6mm.nii.gz\n",
      "Loaded seed ROI shape: (176, 256, 256)\n",
      "Bold volume shape: (176, 256, 256, 368)\n",
      "Extracted seed time series shape: (368, 114)\n",
      "Seed data extracted successfully.\n",
      "108.18761444091797\n",
      "Begin Searchlight None\n",
      "Distribute 108.18761444091797\n",
      "Broadcast 108.18761444091797\n",
      "Run 108.18761444091797\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4830/2029266692.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_ts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#send the relevant analysis vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrusage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUSAGE_SELF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mru_maxrss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m \u001b[0msl_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_searchlight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvpd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End Searchlight\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/brainiak/searchlight/searchlight.py\u001b[0m in \u001b[0;36mrun_searchlight\u001b[0;34m(self, voxel_fn, pool_size)\u001b[0m\n\u001b[1;32m    519\u001b[0m         block_fn_result = self.run_block_function(_singlenode_searchlight,\n\u001b[1;32m    520\u001b[0m                                                   \u001b[0mextra_block_fn_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                                                   pool_size)\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblock_fn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/brainiak/searchlight/searchlight.py\u001b[0m in \u001b[0;36mrun_block_function\u001b[0;34m(self, block_fn, extra_block_fn_params, pool_size)\u001b[0m\n\u001b[1;32m    455\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msl_rad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbcast_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                             extra_block_fn_params)\n\u001b[0m\u001b[1;32m    458\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mlocal_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/brainiak/searchlight/searchlight.py\u001b[0m in \u001b[0;36m_singlenode_searchlight\u001b[0;34m(data, msk, mysl_rad, bcast_var, extra_params)\u001b[0m\n\u001b[1;32m    558\u001b[0m                             \u001b[0mmsk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msearchlight_slice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshape_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                             \u001b[0mmysl_rad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                             bcast_var)\n\u001b[0m\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4830/2029266692.py\u001b[0m in \u001b[0;36mmvpd\u001b[0;34m(data, sl_mask, myrad, seed_ts)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mtarget_test_pcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#transform test data into PCs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mmvc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_mvc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_train_pcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_test_pcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train_pcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test_pcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4830/2029266692.py\u001b[0m in \u001b[0;36mcalc_mvc\u001b[0;34m(seed_train, seed_test, target_train, target_test, target_pc)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_pc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpcn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit seed PCs to target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mpred_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#use dorsal test data to predict left out runs of ventral test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mweighted_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_ts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpcn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_pc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpcn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         X, y = self._validate_data(\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         )\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m\"\"\"Return number of samples in array-like x.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Expected sequence or array-like, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Don't get num_samples from an ensembles length!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#directly converting vlad mvpd to my paths\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import resource\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from nilearn import image, datasets\n",
    "import nibabel as nib\n",
    "from brainiak.searchlight.searchlight import Searchlight, Ball\n",
    "\n",
    "\n",
    "def transform_mask_to_native(subject_func, standard_mask, output_dir):\n",
    "    \"\"\"\n",
    "    Transform the standard space whole brain mask to the subject's native space.\n",
    "    \n",
    "    Parameters:\n",
    "    subject_func : str\n",
    "        Path to a functional image in the subject's native space\n",
    "    standard_mask : str\n",
    "        Path to the whole brain mask in standard space\n",
    "    output_dir : str\n",
    "        Directory to save the transformed mask\n",
    "    \n",
    "    Returns:\n",
    "    str : Path to the transformed mask\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load images\n",
    "    func_img = image.load_img(subject_func)\n",
    "    mask_img = image.load_img(standard_mask)\n",
    "    \n",
    "    # Resample mask to functional space\n",
    "    native_mask = image.resample_to_img(mask_img, func_img, interpolation='nearest')\n",
    "    \n",
    "    # Save the transformed mask\n",
    "    output_path = os.path.join(output_dir, f'whole_brain_mask_native.nii.gz')\n",
    "    native_mask.to_filename(output_path)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "print('libraries loaded...')\n",
    "\n",
    "#load subj number and seed\n",
    "#subj\n",
    "# Load subject information\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "sub_info = sub_info[sub_info['group'] == 'control']\n",
    "#subs = sub_info['sub'].tolist()\n",
    "subs = ['sub-025']  # Uncomment for testing\n",
    "#seed region\n",
    "#dorsal = str(sys.argv[2])\n",
    "dorsal = ['pIPS'] # Run for one ROI initially\n",
    "\n",
    "print(subs, dorsal)\n",
    "\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "localizer = 'Object'  # scramble or object. This is the localizer task.\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = \"/lab_data/behrmannlab/vlad/hemispace\"\n",
    "exp = 'loc' \n",
    "\n",
    "\n",
    "#setup directories\n",
    "out_dir = f'{study_dir}/derivatives/fc'\n",
    "sub_dir = f'{study_dir}/sub-025/ses-01/'\n",
    "cov_dir = f'{raw_dir}/covs'\n",
    "roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "exp_dir = f'{sub_dir}/derivatives/fsl/{exp}'\n",
    "\n",
    "runs = list(range(1,4)) #this should have been 1,4 not 1,3 for 3 runs\n",
    "\n",
    "standard_mask_path = '/user_data/csimmon2/git_repos/ptoc/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz'\n",
    "native_mask_path = transform_mask_to_native(\n",
    "    f'{exp_dir}/run-01/1stLevel.feat/filtered_func_data_reg.nii.gz',\n",
    "    standard_mask_path,\n",
    "    f'{sub_dir}/derivatives/masks'\n",
    ")\n",
    "whole_brain_mask = image.load_img(native_mask_path)\n",
    "\n",
    "affine = whole_brain_mask.affine\n",
    "dimsize = whole_brain_mask.header.get_zooms()  #get dimensions\n",
    "\n",
    "# scan parameters\n",
    "vols = 184\n",
    "first_fix = 0\n",
    "\n",
    "# threshold for PCA\n",
    "pc_thresh = .9\n",
    "\n",
    "clf = LinearRegression()\n",
    "# train/test split with 3 runs || no idea if this will work\n",
    "rs = ShuffleSplit(n_splits=5, test_size=1/3, random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "Setup searchlight\n",
    "\"\"\"\n",
    "print('Searchlight setup ...')\n",
    "#set search light params\n",
    "\n",
    "mask = image.get_data(whole_brain_mask) #the mask to search within\n",
    "\n",
    "\n",
    "sl_rad = 2 #radius of searchlight sphere (in voxels)\n",
    "max_blk_edge = 10 #how many blocks to send on each parallelized search\n",
    "pool_size = 1 #number of cores to work on each search\n",
    "\n",
    "voxels_proportion=1\n",
    "shape = Ball\n",
    "\n",
    "def extract_pc(data, n_components=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Extract principal components\n",
    "    if n_components isn't set, it will extract all it can\n",
    "    \"\"\"\n",
    "    \n",
    "    pca = PCA(n_components = n_components)\n",
    "    pca.fit(data)\n",
    "    \n",
    "    return pca\n",
    "\n",
    "def calc_pc_n(pca, thresh):\n",
    "    '''\n",
    "    Calculate how many PCs are needed to explain X% of data\n",
    "    \n",
    "    pca - result of pca analysis\n",
    "    thresh- threshold for how many components to keep\n",
    "    '''\n",
    "    \n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    \n",
    "    var = 0\n",
    "    for n_comp, ev in enumerate(explained_variance):\n",
    "        var += ev #add each PC's variance to current variance\n",
    "        #print(n_comp, ev, var)\n",
    "\n",
    "        if var >=thresh: #once variance > than thresh, stop\n",
    "            break\n",
    "    \n",
    "    '''\n",
    "    plt.bar(range(len(explained_variance[0:n_comp+1])), explained_variance[0:n_comp+1], alpha=0.5, align='center')\n",
    "    plt.ylabel('Variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.show()\n",
    "    '''\n",
    "    return n_comp+1\n",
    "\n",
    "def calc_mvc(seed_train,seed_test, target_train, target_test, target_pc):\n",
    "    \"\"\"\n",
    "    Conduct regression by iteratively fitting all seed PCs to target PCs\n",
    "\n",
    "    seed_train,seed_test, target_train, target_test, target_pc\n",
    "    \"\"\"\n",
    "\n",
    "    all_corrs = []\n",
    "    for pcn in range(0,len(target_pc.explained_variance_ratio_)):\n",
    "        \n",
    "        clf.fit(seed_train, target_train[:,pcn]) #fit seed PCs to target\n",
    "        pred_ts = clf.predict(seed_test) #use dorsal test data to predict left out runs of ventral test data\n",
    "        weighted_corr = np.corrcoef(pred_ts,target_test[:,pcn])[0,1] * target_pc.explained_variance_ratio_[pcn]\n",
    "        all_corrs.append(weighted_corr)\n",
    "\n",
    "    final_corr = np.sum(all_corrs)/(np.sum(target_pc.explained_variance_ratio_))\n",
    "\n",
    "    return final_corr\n",
    "\n",
    "def create_ts_mask(train, test):\n",
    "    \"\"\"\n",
    "    Create timeseries mask (i.e., a list of value)  that correspond to training and test runs\n",
    "    \"\"\"\n",
    "\n",
    "    train_index = []\n",
    "    test_index = []\n",
    "\n",
    "    for tr in train:\n",
    "        train_index = train_index + list(range((tr-1) * (vols-first_fix),((tr-1) * (vols-first_fix)) + (vols-first_fix)))\n",
    "\n",
    "    for te in test:\n",
    "        test_index = test_index + list(range((te-1) * (vols-first_fix),((te-1) * (vols-first_fix)) + (vols-first_fix)))\n",
    "\n",
    "    return train_index, test_index\n",
    "\n",
    "\n",
    "def mvpd(data, sl_mask, myrad, seed_ts):\n",
    "    \"\"\"\n",
    "    Run multivaraite pattern dependance analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pull out the data\n",
    "    data4D = data[0]\n",
    "    data4D = np.transpose(data4D.reshape(-1, data[0].shape[3]))\n",
    "    #print('mvpd', (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024)\n",
    "\n",
    "    mvc_list = []\n",
    "    \n",
    "    #set up train/test split\n",
    "    for train_runs, test_runs in rs.split(runs): \n",
    "        \n",
    "        #determine train time points and test time points\n",
    "        train_index, test_index = create_ts_mask(train_runs, test_runs)\n",
    "        \n",
    "        #split seed ts in train and test\n",
    "        seed_train = seed_ts[train_index,:]\n",
    "        seed_test = seed_ts[test_index,:]\n",
    "        \n",
    "        #split target region timeseries into train and test\n",
    "        target_train = data4D[train_index, :]\n",
    "        target_test = data4D[test_index, :]\n",
    "        \n",
    "        #extract PCs from seed and target\n",
    "        n_comp = calc_pc_n(extract_pc(seed_train),pc_thresh) #determine number of PCs in train_data using threshold\n",
    "        \n",
    "        seed_pca = extract_pc(seed_train, n_comp) #conduct PCA one more time with that number of PCs\n",
    "        #print(seed_pca.shape)\n",
    "\n",
    "        seed_train_pcs = seed_pca.transform(seed_train) #transform train data in PCs\n",
    "        seed_test_pcs = seed_pca.transform(seed_test) #transform test data into PCs \n",
    "        \n",
    "        #extract PCs from seed and target\n",
    "        n_comp = calc_pc_n(extract_pc(target_train),pc_thresh) #determine number of PCs in train_data using threshold\n",
    "        target_pca = extract_pc(target_train, n_comp) #conduct PCA one more time with that number of PCs\n",
    "        \n",
    "\n",
    "        target_train_pcs = target_pca.transform(target_train) #transform train data in PCs\n",
    "        target_test_pcs = target_pca.transform(target_test) #transform test data into PCs\n",
    "\n",
    "        mvc_list.append(calc_mvc(seed_train_pcs, seed_test_pcs, target_train_pcs, target_test_pcs, target_pca))\n",
    "\n",
    "\n",
    "    return np.mean(mvc_list)   \n",
    "\n",
    "def load_data(sub):\n",
    "    print('Loading data...')\n",
    "\n",
    "    all_runs = []\n",
    "    for run in runs:\n",
    "        print(f\"Loading run {run}\")\n",
    "\n",
    "        try:\n",
    "            # Load the image\n",
    "            curr_run = nib.load(f\"{raw_dir}/{sub}/ses-01/derivatives/fsl/loc/run-0{run}/1stLevel.feat/filtered_func_data_reg.nii.gz\")\n",
    "            \n",
    "            # Apply the brain mask and standardize\n",
    "            curr_run_data = brain_masker.fit_transform(curr_run)\n",
    "            \n",
    "            # Reshape the data back to 4D\n",
    "            curr_run_data = curr_run_data.T.reshape(whole_brain_mask.shape + (-1,))\n",
    "            \n",
    "            # Remove first few fixation volumes if needed\n",
    "            # curr_run_data = curr_run_data[:,:,:,first_fix:]\n",
    "            \n",
    "            print(f\"Run {run} shape: {curr_run_data.shape}\")\n",
    "            all_runs.append(curr_run_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading run {run}: {str(e)}\")\n",
    "\n",
    "        print(f\"Memory usage after run {run}: {(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024} MB\")\n",
    "\n",
    "    print('Data loaded. Concatenating...')\n",
    "\n",
    "    if not all_runs:\n",
    "        raise ValueError(\"No valid run data was loaded. Check your input files and paths.\")\n",
    "\n",
    "    bold_vol = np.concatenate(all_runs, axis=3)  # Compile into 4D\n",
    "    del all_runs\n",
    "    print(f\"Concatenated data shape: {bold_vol.shape}\")\n",
    "    print(f\"Final memory usage: {(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024} MB\")\n",
    "    print('Data concatenated...')\n",
    "    gc.collect()\n",
    "\n",
    "    return bold_vol\n",
    "\n",
    "\n",
    "def extract_seed_ts(bold_vol, sub, roi, hemisphere, task='loc', radius=6):\n",
    "    \"\"\"\n",
    "    Extract all data from seed region using the spherical ROI created by the second script.\n",
    "    \"\"\"\n",
    "    print(\"Extracting seed time series...\")\n",
    "    \n",
    "    # Construct the path to the spherical ROI\n",
    "    seed_roi_path = f'{study_dir}/{sub}/ses-01/derivatives/rois/spheres_nifti/{sub}_{roi}_{hemisphere}_{task}_sphere_r{radius}mm.nii.gz'\n",
    "    print(f\"Loading seed ROI from: {seed_roi_path}\")\n",
    "    \n",
    "    try:\n",
    "        seed_roi_img = image.load_img(seed_roi_path)\n",
    "        seed_roi = image.get_data(seed_roi_img)\n",
    "        print(f\"Loaded seed ROI shape: {seed_roi.shape}\")\n",
    "        print(f\"Bold volume shape: {bold_vol.shape}\")\n",
    "        \n",
    "        # Check if reshaping is necessary\n",
    "        if seed_roi.shape[:3] != bold_vol.shape[:3]:\n",
    "            print(\"Warning: Seed ROI shape does not match bold volume shape. Attempting to reshape...\")\n",
    "            seed_roi = image.resample_to_img(seed_roi_img, nib.Nifti1Image(bold_vol, affine), interpolation='nearest').get_fdata()\n",
    "            print(f\"Reshaped seed ROI to: {seed_roi.shape}\")\n",
    "        \n",
    "        # Ensure seed_roi is 4D\n",
    "        if len(seed_roi.shape) == 3:\n",
    "            seed_roi = seed_roi[..., np.newaxis]\n",
    "        \n",
    "        # Perform masking\n",
    "        masked_img = seed_roi * bold_vol\n",
    "        \n",
    "        # Extract voxel responses from within mask\n",
    "        seed_ts = masked_img.reshape(-1, bold_vol.shape[3])  # reshape into rows (voxels) x columns (time)\n",
    "        seed_ts = seed_ts[~np.all(seed_ts == 0, axis=1)]  # remove voxels that are 0 (masked out)\n",
    "        seed_ts = np.transpose(seed_ts)\n",
    "        \n",
    "        print(f\"Extracted seed time series shape: {seed_ts.shape}\")\n",
    "        print('Seed data extracted successfully.')\n",
    "        \n",
    "        return seed_ts\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_seed_ts: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "bold_vol = load_data(sub)\n",
    "\n",
    "print(f\"bold_vol type: {type(bold_vol)}\") #troubleshooting\n",
    "print(f\"bold_vol shape: {bold_vol.shape}\") #troubleshooting\n",
    "print(f\"bold_vol dtype: {bold_vol.dtype}\") #troubleshooting\n",
    "seed_ts = extract_seed_ts(bold_vol, sub='sub-025', roi='pIPS', hemisphere='left') #adjust for each subject and ROI\n",
    "\n",
    "#run searchlight\n",
    "t1 = time.time()\n",
    "print(\"Begin Searchlight\", print((resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024))\n",
    "sl = Searchlight(sl_rad=sl_rad,max_blk_edge=max_blk_edge, shape = shape) #setup the searchlight\n",
    "print('Distribute', (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024)\n",
    "sl.distribute([bold_vol], mask) #send the 4dimg and mask\n",
    "\n",
    "print('Broadcast', (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024)\n",
    "sl.broadcast(seed_ts) #send the relevant analysis vars\n",
    "print('Run', (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024, flush= True)\n",
    "sl_result = sl.run_searchlight(mvpd, pool_size=pool_size)\n",
    "print(\"End Searchlight\\n\", (time.time()-t1)/60)\n",
    "\n",
    "# At the end of your script\n",
    "sl_result = sl_result.astype('double')  # Convert the output into a precision format that can be used by other applications\n",
    "sl_result[np.isnan(sl_result)] = 0  # Exchange nans with zero to ensure compatibility with other applications\n",
    "sl_nii = nib.Nifti1Image(sl_result, affine)  # create the volume image\n",
    "nib.save(sl_nii, f'{out_dir}/{study}_sub-025_pIPS_left_mvpd.nii.gz')  # Save the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directly converting vlad mvpd to GCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import resource\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from nilearn import image, datasets\n",
    "import nibabel as nib\n",
    "from brainiak.searchlight.searchlight import Searchlight, Ball\n",
    "\n",
    "\n",
    "def transform_mask_to_native(subject_func, standard_mask, output_dir):\n",
    "    \"\"\"\n",
    "    Transform the standard space whole brain mask to the subject's native space.\n",
    "    \n",
    "    Parameters:\n",
    "    subject_func : str\n",
    "        Path to a functional image in the subject's native space\n",
    "    standard_mask : str\n",
    "        Path to the whole brain mask in standard space\n",
    "    output_dir : str\n",
    "        Directory to save the transformed mask\n",
    "    \n",
    "    Returns:\n",
    "    str : Path to the transformed mask\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load images\n",
    "    func_img = image.load_img(subject_func)\n",
    "    mask_img = image.load_img(standard_mask)\n",
    "    \n",
    "    # Resample mask to functional space\n",
    "    native_mask = image.resample_to_img(mask_img, func_img, interpolation='nearest')\n",
    "    \n",
    "    # Save the transformed mask\n",
    "    output_path = os.path.join(output_dir, f'whole_brain_mask_native.nii.gz')\n",
    "    native_mask.to_filename(output_path)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "print('libraries loaded...')\n",
    "\n",
    "#load subj number and seed\n",
    "#subj\n",
    "# Load subject information\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "sub_info = sub_info[sub_info['group'] == 'control']\n",
    "#subs = sub_info['sub'].tolist()\n",
    "subs = ['sub-025']  # Uncomment for testing\n",
    "#seed region\n",
    "#dorsal = str(sys.argv[2])\n",
    "dorsal = ['pIPS'] # Run for one ROI initially\n",
    "\n",
    "print(subs, dorsal)\n",
    "\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "localizer = 'Object'  # scramble or object. This is the localizer task.\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = \"/lab_data/behrmannlab/vlad/hemispace\"\n",
    "exp = 'loc' \n",
    "\n",
    "\n",
    "#setup directories\n",
    "out_dir = f'{study_dir}/derivatives/fc'\n",
    "sub_dir = f'{study_dir}/sub-025/ses-01/'\n",
    "cov_dir = f'{raw_dir}/covs'\n",
    "roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "exp_dir = f'{sub_dir}/derivatives/fsl/{exp}'\n",
    "\n",
    "runs = list(range(1,3))\n",
    "\n",
    "standard_mask_path = '/user_data/csimmon2/git_repos/ptoc/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz'\n",
    "native_mask_path = transform_mask_to_native(\n",
    "    f'{exp_dir}/run-01/1stLevel.feat/filtered_func_data_reg.nii.gz',\n",
    "    standard_mask_path,\n",
    "    f'{sub_dir}/derivatives/masks'\n",
    ")\n",
    "whole_brain_mask = image.load_img(native_mask_path)\n",
    "\n",
    "affine = whole_brain_mask.affine\n",
    "dimsize = whole_brain_mask.header.get_zooms()  #get dimensions\n",
    "\n",
    "# scan parameters\n",
    "vols = 184\n",
    "first_fix = 0\n",
    "\n",
    "# threshold for PCA\n",
    "pc_thresh = .9\n",
    "\n",
    "clf = LinearRegression()\n",
    "#train/test split in 6 and 2 runs\n",
    "rs = ShuffleSplit(n_splits=5, test_size=1/3, random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "Setup searchlight\n",
    "\"\"\"\n",
    "print('Searchlight setup ...')\n",
    "#set search light params\n",
    "\n",
    "mask = image.get_data(whole_brain_mask) #the mask to search within\n",
    "\n",
    "\n",
    "sl_rad = 2 #radius of searchlight sphere (in voxels)\n",
    "max_blk_edge = 10 #how many blocks to send on each parallelized search\n",
    "pool_size = 1 #number of cores to work on each search\n",
    "\n",
    "voxels_proportion=1\n",
    "shape = Ball\n",
    "\n",
    "def extract_pc(data, n_components=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Extract principal components\n",
    "    if n_components isn't set, it will extract all it can\n",
    "    \"\"\"\n",
    "    \n",
    "    pca = PCA(n_components = n_components)\n",
    "    pca.fit(data)\n",
    "    \n",
    "    return pca\n",
    "\n",
    "def calc_pc_n(pca, thresh):\n",
    "    '''\n",
    "    Calculate how many PCs are needed to explain X% of data\n",
    "    \n",
    "    pca - result of pca analysis\n",
    "    thresh- threshold for how many components to keep\n",
    "    '''\n",
    "    \n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    \n",
    "    var = 0\n",
    "    for n_comp, ev in enumerate(explained_variance):\n",
    "        var += ev #add each PC's variance to current variance\n",
    "        #print(n_comp, ev, var)\n",
    "\n",
    "        if var >=thresh: #once variance > than thresh, stop\n",
    "            break\n",
    "    \n",
    "    '''\n",
    "    plt.bar(range(len(explained_variance[0:n_comp+1])), explained_variance[0:n_comp+1], alpha=0.5, align='center')\n",
    "    plt.ylabel('Variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.show()\n",
    "    '''\n",
    "    return n_comp+1\n",
    "\n",
    "def calc_mvc(seed_train,seed_test, target_train, target_test, target_pc):\n",
    "    \"\"\"\n",
    "    Conduct regression by iteratively fitting all seed PCs to target PCs\n",
    "\n",
    "    seed_train,seed_test, target_train, target_test, target_pc\n",
    "    \"\"\"\n",
    "\n",
    "    all_corrs = []\n",
    "    for pcn in range(0,len(target_pc.explained_variance_ratio_)):\n",
    "        \n",
    "        clf.fit(seed_train, target_train[:,pcn]) #fit seed PCs to target\n",
    "        pred_ts = clf.predict(seed_test) #use dorsal test data to predict left out runs of ventral test data\n",
    "        weighted_corr = np.corrcoef(pred_ts,target_test[:,pcn])[0,1] * target_pc.explained_variance_ratio_[pcn]\n",
    "        all_corrs.append(weighted_corr)\n",
    "\n",
    "    final_corr = np.sum(all_corrs)/(np.sum(target_pc.explained_variance_ratio_))\n",
    "\n",
    "    return final_corr\n",
    "\n",
    "def create_ts_mask(train, test):\n",
    "    \"\"\"\n",
    "    Create timeseries mask (i.e., a list of value)  that correspond to training and test runs\n",
    "    \"\"\"\n",
    "\n",
    "    train_index = []\n",
    "    test_index = []\n",
    "\n",
    "    for tr in train:\n",
    "        train_index = train_index + list(range((tr-1) * (vols-first_fix),((tr-1) * (vols-first_fix)) + (vols-first_fix)))\n",
    "\n",
    "    for te in test:\n",
    "        test_index = test_index + list(range((te-1) * (vols-first_fix),((te-1) * (vols-first_fix)) + (vols-first_fix)))\n",
    "\n",
    "    return train_index, test_index\n",
    "\n",
    "\n",
    "def mvpd(data, sl_mask, myrad, seed_ts):\n",
    "    \"\"\"\n",
    "    Run multivaraite pattern dependance analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pull out the data\n",
    "    data4D = data[0]\n",
    "    data4D = np.transpose(data4D.reshape(-1, data[0].shape[3]))\n",
    "    #print('mvpd', (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024)\n",
    "\n",
    "    mvc_list = []\n",
    "    \n",
    "    #set up train/test split\n",
    "    for train_runs, test_runs in rs.split(runs): \n",
    "        \n",
    "        #determine train time points and test time points\n",
    "        train_index, test_index = create_ts_mask(train_runs, test_runs)\n",
    "        \n",
    "        #split seed ts in train and test\n",
    "        seed_train = seed_ts[train_index,:]\n",
    "        seed_test = seed_ts[test_index,:]\n",
    "        \n",
    "        #split target region timeseries into train and test\n",
    "        target_train = data4D[train_index, :]\n",
    "        target_test = data4D[test_index, :]\n",
    "        \n",
    "        #extract PCs from seed and target\n",
    "        n_comp = calc_pc_n(extract_pc(seed_train),pc_thresh) #determine number of PCs in train_data using threshold\n",
    "        \n",
    "        seed_pca = extract_pc(seed_train, n_comp) #conduct PCA one more time with that number of PCs\n",
    "        #print(seed_pca.shape)\n",
    "\n",
    "        seed_train_pcs = seed_pca.transform(seed_train) #transform train data in PCs\n",
    "        seed_test_pcs = seed_pca.transform(seed_test) #transform test data into PCs \n",
    "        \n",
    "        #extract PCs from seed and target\n",
    "        n_comp = calc_pc_n(extract_pc(target_train),pc_thresh) #determine number of PCs in train_data using threshold\n",
    "        target_pca = extract_pc(target_train, n_comp) #conduct PCA one more time with that number of PCs\n",
    "        \n",
    "\n",
    "        target_train_pcs = target_pca.transform(target_train) #transform train data in PCs\n",
    "        target_test_pcs = target_pca.transform(target_test) #transform test data into PCs\n",
    "\n",
    "        mvc_list.append(calc_mvc(seed_train_pcs, seed_test_pcs, target_train_pcs, target_test_pcs, target_pca))\n",
    "\n",
    "\n",
    "    return np.mean(mvc_list)   \n",
    "\n",
    "def load_data(sub):\n",
    "    print('Loading data...')\n",
    "\n",
    "    all_runs = []\n",
    "    for run in runs:\n",
    "        print(f\"Loading run {run}\")\n",
    "\n",
    "        try:\n",
    "            # Load the image\n",
    "            curr_run = nib.load(f\"{raw_dir}/{sub}/ses-01/derivatives/fsl/loc/run-0{run}/1stLevel.feat/filtered_func_data_reg.nii.gz\")\n",
    "            \n",
    "            # Apply the brain mask and standardize\n",
    "            curr_run_data = brain_masker.fit_transform(curr_run)\n",
    "            \n",
    "            # Reshape the data back to 4D\n",
    "            curr_run_data = curr_run_data.T.reshape(whole_brain_mask.shape + (-1,))\n",
    "            \n",
    "            # Remove first few fixation volumes if needed\n",
    "            # curr_run_data = curr_run_data[:,:,:,first_fix:]\n",
    "            \n",
    "            print(f\"Run {run} shape: {curr_run_data.shape}\")\n",
    "            all_runs.append(curr_run_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading run {run}: {str(e)}\")\n",
    "\n",
    "        print(f\"Memory usage after run {run}: {(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024} MB\")\n",
    "\n",
    "    print('Data loaded. Concatenating...')\n",
    "\n",
    "    if not all_runs:\n",
    "        raise ValueError(\"No valid run data was loaded. Check your input files and paths.\")\n",
    "\n",
    "    bold_vol = np.concatenate(all_runs, axis=3)  # Compile into 4D\n",
    "    del all_runs\n",
    "    print(f\"Concatenated data shape: {bold_vol.shape}\")\n",
    "    print(f\"Final memory usage: {(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024} MB\")\n",
    "    print('Data concatenated...')\n",
    "    gc.collect()\n",
    "\n",
    "    return bold_vol\n",
    "\n",
    "\n",
    "def extract_seed_ts(bold_vol, sub, roi, hemisphere, task='loc', radius=6):\n",
    "    \"\"\"\n",
    "    Extract all data from seed region using the spherical ROI created by the second script.\n",
    "    \"\"\"\n",
    "    print(\"Extracting seed time series...\")\n",
    "    \n",
    "    # Construct the path to the spherical ROI\n",
    "    seed_roi_path = f'{study_dir}/{sub}/ses-01/derivatives/rois/spheres_nifti/{sub}_{roi}_{hemisphere}_{task}_sphere_r{radius}mm.nii.gz'\n",
    "    print(f\"Loading seed ROI from: {seed_roi_path}\")\n",
    "    \n",
    "    try:\n",
    "        seed_roi_img = image.load_img(seed_roi_path)\n",
    "        seed_roi = image.get_data(seed_roi_img)\n",
    "        print(f\"Loaded seed ROI shape: {seed_roi.shape}\")\n",
    "        print(f\"Bold volume shape: {bold_vol.shape}\")\n",
    "        \n",
    "        # Check if reshaping is necessary\n",
    "        if seed_roi.shape[:3] != bold_vol.shape[:3]:\n",
    "            print(\"Warning: Seed ROI shape does not match bold volume shape. Attempting to reshape...\")\n",
    "            seed_roi = image.resample_to_img(seed_roi_img, nib.Nifti1Image(bold_vol, affine), interpolation='nearest').get_fdata()\n",
    "            print(f\"Reshaped seed ROI to: {seed_roi.shape}\")\n",
    "        \n",
    "        # Ensure seed_roi is 4D\n",
    "        if len(seed_roi.shape) == 3:\n",
    "            seed_roi = seed_roi[..., np.newaxis]\n",
    "        \n",
    "        # Perform masking\n",
    "        masked_img = seed_roi * bold_vol\n",
    "        \n",
    "        # Extract voxel responses from within mask\n",
    "        seed_ts = masked_img.reshape(-1, bold_vol.shape[3])  # reshape into rows (voxels) x columns (time)\n",
    "        seed_ts = seed_ts[~np.all(seed_ts == 0, axis=1)]  # remove voxels that are 0 (masked out)\n",
    "        seed_ts = np.transpose(seed_ts)\n",
    "        \n",
    "        print(f\"Extracted seed time series shape: {seed_ts.shape}\")\n",
    "        print('Seed data extracted successfully.')\n",
    "        \n",
    "        return seed_ts\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_seed_ts: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "bold_vol = load_data(sub)\n",
    "\n",
    "print(f\"bold_vol type: {type(bold_vol)}\") #troubleshooting\n",
    "print(f\"bold_vol shape: {bold_vol.shape}\") #troubleshooting\n",
    "print(f\"bold_vol dtype: {bold_vol.dtype}\") #troubleshooting\n",
    "seed_ts = extract_seed_ts(bold_vol, sub='sub-025', roi='pIPS', hemisphere='left') #adjust for each subject and ROI\n",
    "\n",
    "#run searchlight\n",
    "t1 = time.time()\n",
    "print(\"Begin Searchlight\", print((resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024))\n",
    "sl = Searchlight(sl_rad=sl_rad,max_blk_edge=max_blk_edge, shape = shape) #setup the searchlight\n",
    "print('Distribute', (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024)\n",
    "sl.distribute([bold_vol], mask) #send the 4dimg and mask\n",
    "\n",
    "print('Broadcast', (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024)\n",
    "sl.broadcast(seed_ts) #send the relevant analysis vars\n",
    "print('Run', (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)/1024, flush= True)\n",
    "sl_result = sl.run_searchlight(mvpd, pool_size=pool_size)\n",
    "print(\"End Searchlight\\n\", (time.time()-t1)/60)\n",
    "\n",
    "# At the end of your script\n",
    "sl_result = sl_result.astype('double')  # Convert the output into a precision format that can be used by other applications\n",
    "sl_result[np.isnan(sl_result)] = 0  # Exchange nans with zero to ensure compatibility with other applications\n",
    "sl_nii = nib.Nifti1Image(sl_result, affine)  # create the volume image\n",
    "nib.save(sl_nii, f'{out_dir}/{study}_sub-025_pIPS_left_mvpd.nii.gz')  # Save the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates spherical rois in registered native space\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from nilearn import image\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "localizer = 'Object'  # scramble or object. This is the localizer task.\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "# Load subject information\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "sub_info = sub_info[sub_info['group'] == 'control']\n",
    "subs = sub_info['sub'].tolist()\n",
    "#subs = ['sub-025']  # You can change this to sub_info['sub'].tolist() if needed\n",
    "\n",
    "# ROI parameters\n",
    "rois = ['pIPS', 'LO']\n",
    "hemispheres = ['left', 'right']\n",
    "radius = 6\n",
    "\n",
    "def create_spherical_roi(coords, radius, affine, shape):\n",
    "    \"\"\"Create a spherical ROI mask.\"\"\"\n",
    "    coords = np.array(coords)\n",
    "    mask = np.zeros(shape, dtype=bool)\n",
    "    \n",
    "    # Get voxel coordinates\n",
    "    xx, yy, zz = np.meshgrid(np.arange(shape[0]),\n",
    "                             np.arange(shape[1]),\n",
    "                             np.arange(shape[2]),\n",
    "                             indexing='ij')\n",
    "    vox_coords = np.column_stack((xx.ravel(), yy.ravel(), zz.ravel()))\n",
    "    \n",
    "    # Transform voxel coordinates to world coordinates\n",
    "    world_coords = nib.affines.apply_affine(affine, vox_coords)\n",
    "    \n",
    "    # Calculate distances\n",
    "    distances = np.sqrt(np.sum((world_coords - coords)**2, axis=1))\n",
    "    \n",
    "    # Create mask\n",
    "    mask = distances <= radius\n",
    "    return mask.reshape(shape)\n",
    "\n",
    "def save_spherical_rois(ss, tsk='loc'):\n",
    "    \"\"\"\n",
    "    Save spherical ROIs as NIfTI files based on coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    - ss: str, subject ID\n",
    "    - tsk: str, task name (default: 'loc')\n",
    "    \"\"\"\n",
    "    logging.info(f\"Processing subject: {ss}\")\n",
    "    \n",
    "    # Define paths\n",
    "    sub_dir = f'{study_dir}/{ss}/ses-01/'\n",
    "    roi_dir = f'{sub_dir}derivatives/rois'\n",
    "    out_dir = f'{sub_dir}derivatives/rois/spheres_nifti'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Read ROI coordinates\n",
    "    roi_coords_file = f'{roi_dir}/spheres/sphere_coords_hemisphere.csv'\n",
    "    roi_coords = pd.read_csv(roi_coords_file)\n",
    "    \n",
    "    # Get subject-specific brain mask to use as a template\n",
    "    mask_path = f'{raw_dir}/{ss}/ses-01/anat/{ss}_ses-01_T1w_brain_mask.nii.gz'\n",
    "    template = nib.load(mask_path)\n",
    "    \n",
    "    # Iterate through each ROI and hemisphere\n",
    "    for rr in rois:\n",
    "        for hemi in hemispheres:\n",
    "            curr_coords = roi_coords[(roi_coords['task'] == tsk) & \n",
    "                                     (roi_coords['roi'] == rr) &\n",
    "                                     (roi_coords['hemisphere'] == hemi)]\n",
    "            \n",
    "            if curr_coords.empty:\n",
    "                logging.warning(f\"No coordinates found for {rr}, {hemi}\")\n",
    "                continue\n",
    "            \n",
    "            coords = curr_coords[['x', 'y', 'z']].values.tolist()[0]\n",
    "            \n",
    "            # Create spherical ROI\n",
    "            roi_mask = create_spherical_roi(coords, radius, template.affine, template.shape)\n",
    "            roi_img = nib.Nifti1Image(roi_mask.astype(np.int16), template.affine, template.header)\n",
    "            \n",
    "            # Save ROI as NIfTI file\n",
    "            output_file = os.path.join(out_dir, f\"{ss}_{rr}_{hemi}_{tsk}_sphere_r{radius}mm.nii.gz\")\n",
    "            nib.save(roi_img, output_file)\n",
    "            logging.info(f\"Saved ROI: {output_file}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    for ss in subs:\n",
    "        save_spherical_rois(ss)\n",
    "\n",
    "logging.info(\"ROI saving process completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiak_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
