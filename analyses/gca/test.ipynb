{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n.p check input at native or standard, check mask as native or standard, check time series, check parameters too of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csimmon2/anaconda3/envs/brainiak_env/lib/python3.7/site-packages/nilearn/__init__.py:67: FutureWarning: Python 3.7 support is deprecated and will be removed in release 0.12 of Nilearn. Consider switching to Python 3.9 or 3.10.\n",
      "  _python_deprecation_warnings()\n",
      "2024-10-07 23:36:07,023 - INFO - Loading data for subject sub-025, runs [1, 2]\n",
      "2024-10-07 23:42:10,936 - ERROR - Error processing subject sub-025, runs [1, 2]: No such file or no access: '/user_data/csimmon2/git_repos/analyses/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz'\n",
      "2024-10-07 23:42:13,727 - INFO - Loading data for subject sub-025, runs [1, 3]\n",
      "2024-10-07 23:48:12,783 - ERROR - Error processing subject sub-025, runs [1, 3]: No such file or no access: '/user_data/csimmon2/git_repos/analyses/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz'\n",
      "2024-10-07 23:48:14,976 - INFO - Loading data for subject sub-025, runs [2, 3]\n",
      "2024-10-07 23:54:13,910 - ERROR - Error processing subject sub-025, runs [2, 3]: No such file or no access: '/user_data/csimmon2/git_repos/analyses/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz'\n",
      "2024-10-07 23:54:16,087 - INFO - Loading data for subject sub-038, runs [1, 2]\n",
      "2024-10-08 00:00:15,682 - ERROR - Error processing subject sub-038, runs [1, 2]: No such file or no access: '/user_data/csimmon2/git_repos/analyses/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz'\n",
      "2024-10-08 00:00:17,850 - INFO - Loading data for subject sub-038, runs [1, 3]\n",
      "2024-10-08 00:06:16,325 - ERROR - Error processing subject sub-038, runs [1, 3]: No such file or no access: '/user_data/csimmon2/git_repos/analyses/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz'\n",
      "2024-10-08 00:06:18,550 - INFO - Loading data for subject sub-038, runs [2, 3]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import image\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import logging\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = '/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "localizer = 'Scramble'  # scramble or object. This is the localizer task.\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "# Load subject information\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "sub_info = sub_info[sub_info['group'] == 'control']\n",
    "subs = sub_info['sub'].tolist()\n",
    "# For testing, you can uncomment the line below to include specific subjects\n",
    "# subs = ['sub-025']\n",
    "\n",
    "run_num = 3\n",
    "runs = list(range(1, run_num + 1))\n",
    "run_combos = [[rn1, rn2] for rn1 in range(1, run_num + 1) for rn2 in range(rn1 + 1, run_num + 1)]\n",
    "\n",
    "# Searchlight parameters\n",
    "searchlight_radius = 2  # in voxels, adjust as needed\n",
    "max_blk_edge = 10\n",
    "pool_size = 1\n",
    "\n",
    "# Constants\n",
    "VOL_PER_RUN = 184\n",
    "TR = 2.0\n",
    "\n",
    "def load_and_prepare_data(sub, run_combo):\n",
    "    logging.info(f\"Loading data for subject {sub}, runs {run_combo}\")\n",
    "\n",
    "    # Load and combine run data\n",
    "    run_data_list = []\n",
    "    for run in run_combo:\n",
    "        run_file = f'{raw_dir}/{sub}/ses-01/derivatives/fsl/loc/run-0{run}/1stLevel.feat/filtered_func_data_reg.nii.gz'\n",
    "        run_img = image.load_img(run_file)\n",
    "        run_data = image.clean_img(run_img, standardize='zscore_sample')\n",
    "        run_data_list.append(run_data)\n",
    "    \n",
    "    # Concatenate run data\n",
    "    fmri_data = image.concat_imgs(run_data_list)\n",
    "    \n",
    "    # Load new whole brain mask\n",
    "    mask_file = f'/user_data/csimmon2/git_repos/analyses/roiParcels/mruczek_parcels/binary/all_visual_areas.nii.gz'\n",
    "    whole_brain_mask = nib.load(mask_file).get_fdata().astype(bool)\n",
    "\n",
    "    # Load pIPS mask\n",
    "    pips_mask_file = f'/user_data/csimmon2/git_repos/ptoc/roiParcels/pIPS.nii.gz' #not sure if this is sufficient to direct to file\n",
    "    \n",
    "    pips_mask = nib.load(pips_mask_file).get_fdata().astype(bool)\n",
    "\n",
    "    # Generate psychological covariate\n",
    "    psy = make_psy_cov(run_combo, sub)\n",
    "\n",
    "    # Ensure fMRI data and psy covariate have the same number of time points\n",
    "    if fmri_data.shape[-1] != len(psy):\n",
    "        raise ValueError(f\"Mismatch in volumes: fMRI data has {fmri_data.shape[-1]}, psy has {len(psy)}\")\n",
    "    \n",
    "    # Convert fmri_data to 4D numpy array if it's not already\n",
    "    if isinstance(fmri_data, nib.Nifti1Image):\n",
    "        fmri_data = fmri_data.get_fdata()\n",
    "    \n",
    "    # Ensure fmri_data is 4D\n",
    "    if fmri_data.ndim != 4:\n",
    "        raise ValueError(f\"fMRI data must be 4D, but got shape {fmri_data.shape}\")\n",
    "    \n",
    "    logging.info(f\"Data shapes - fMRI: {fmri_data.shape}, Whole Brain Mask: {whole_brain_mask.shape}, pIPS Mask: {pips_mask.shape}, PSY: {psy.shape}\")\n",
    "    \n",
    "    # Check if dimensions match\n",
    "    if fmri_data.shape[:3] != whole_brain_mask.shape:\n",
    "        raise ValueError(f\"Whole brain mask dimensions {whole_brain_mask.shape} do not match fMRI data dimensions {fmri_data.shape[:3]}\")\n",
    "    \n",
    "    return fmri_data, whole_brain_mask, pips_mask, psy\n",
    "\n",
    "def make_psy_cov(runs, ss):\n",
    "    \"\"\"\n",
    "    Create psychological covariate data for the specified runs and subject.\n",
    "    \"\"\"\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    total_vols = VOL_PER_RUN * len(runs)\n",
    "    times = np.arange(0, total_vols * TR, TR)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for i, rn in enumerate(runs):\n",
    "        ss_num = ss.split('-')[1]\n",
    "        obj_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_{localizer}.txt'\n",
    "\n",
    "        if not os.path.exists(obj_cov_file):\n",
    "            logging.warning(f'Covariate file not found for run {rn}')\n",
    "            return np.zeros((total_vols, 1))  # Return a zeros array if file not found\n",
    "\n",
    "        obj_cov = pd.read_csv(obj_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        \n",
    "        if i > 0:\n",
    "            obj_cov['onset'] += i * VOL_PER_RUN * TR\n",
    "        \n",
    "        full_cov = pd.concat([full_cov, obj_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    cov = full_cov.to_numpy()\n",
    "    valid_onsets = cov[:, 0] < times[-1]\n",
    "    cov = cov[valid_onsets]\n",
    "\n",
    "    if cov.shape[0] == 0:\n",
    "        logging.warning('No valid covariate data after filtering. Returning zeros array.')\n",
    "        return np.zeros((total_vols, 1))\n",
    "\n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    psy[psy > 0] = 1\n",
    "    psy[psy <= 0] = 0\n",
    "    return psy\n",
    "\n",
    "def extract_pips_timeseries(fmri_data, pips_mask):\n",
    "    \"\"\"\n",
    "    Extract the mean time series from the pIPS region.\n",
    "    \"\"\"\n",
    "    fmri_2d = fmri_data.reshape(fmri_data.shape[3], -1)\n",
    "    pips_ts = fmri_2d[:, pips_mask.flatten()]\n",
    "    return np.mean(pips_ts, axis=1)\n",
    "\n",
    "def gca_measure(data, mask, myrad, bcvar):\n",
    "    \"\"\"\n",
    "    Perform Granger Causality Analysis on the searchlight sphere.\n",
    "    \"\"\"\n",
    "    pips_ts, psy = bcvar\n",
    "    \n",
    "    # Reshape data to 2D: (125, time_points)\n",
    "    data_2d = data[0].reshape(-1, data[0].shape[-1])\n",
    "    \n",
    "    # Apply mask to get the searchlight sphere time series\n",
    "    sphere_ts = data_2d[mask.flatten()].mean(axis=0)\n",
    "    \n",
    "    # Ensure all time series have the same length\n",
    "    min_length = min(sphere_ts.shape[0], pips_ts.shape[0], psy.shape[0])\n",
    "    sphere_ts = sphere_ts[:min_length]\n",
    "    pips_ts = pips_ts[:min_length]\n",
    "    psy = psy[:min_length]\n",
    "    \n",
    "    # Perform Granger Causality tests\n",
    "    gc_pips_to_sphere = grangercausalitytests(np.column_stack((sphere_ts, pips_ts, psy.flatten())), maxlag=1, verbose=False)\n",
    "    gc_sphere_to_pips = grangercausalitytests(np.column_stack((pips_ts, sphere_ts, psy.flatten())), maxlag=1, verbose=False)\n",
    "    \n",
    "    # Calculate the difference in F-statistics\n",
    "    f_diff = gc_pips_to_sphere[1][0]['ssr_ftest'][0] - gc_sphere_to_pips[1][0]['ssr_ftest'][0]\n",
    "    \n",
    "    return f_diff\n",
    "\n",
    "def run_searchlight(fmri_data, whole_brain_mask, pips_mask, psy):\n",
    "    \"\"\"\n",
    "    Run searchlight analysis on the fMRI data.\n",
    "    \"\"\"\n",
    "    assert whole_brain_mask.ndim == 3 and whole_brain_mask.dtype == bool, \"Invalid whole_brain_mask\"\n",
    "    assert fmri_data.shape[0:3] == whole_brain_mask.shape, \"Whole brain mask dimensions do not match fMRI data.\"\n",
    "\n",
    "    # Extract pIPS time series before searchlight\n",
    "    pips_ts = extract_pips_timeseries(fmri_data, pips_mask)\n",
    "\n",
    "    sl = Searchlight(sl_rad=searchlight_radius, max_blk_edge=max_blk_edge)\n",
    "    fmri_data_4d = fmri_data.transpose(3, 0, 1, 2)\n",
    "    \n",
    "    sl.distribute([fmri_data_4d], whole_brain_mask)\n",
    "    \n",
    "    # Broadcast pips_ts and psy as a tuple\n",
    "    sl.broadcast((pips_ts, psy))\n",
    "\n",
    "    sl_result = sl.run_searchlight(gca_measure, pool_size=pool_size)\n",
    "    \n",
    "    return sl_result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for sub in subs:\n",
    "        for run_combo in run_combos:\n",
    "            try:\n",
    "                fmri_data, whole_brain_mask, pips_mask, psy = load_and_prepare_data(sub, run_combo)\n",
    "                logging.info(f\"Processing subject {sub}, runs {run_combo}\")\n",
    "                logging.info(f\"Data shapes - fMRI: {fmri_data.shape}, Whole Brain Mask: {whole_brain_mask.shape}, pIPS Mask: {pips_mask.shape}, PSY: {psy.shape}\")\n",
    "                \n",
    "                sl_result = run_searchlight(fmri_data, whole_brain_mask, pips_mask, psy)\n",
    "                \n",
    "                result_file = f'{results_dir}/searchlight_gca_{sub}_runs{\"_\".join(map(str, run_combo))}.nii.gz'\n",
    "                affine = nib.load(f'{raw_dir}/{sub}/ses-01/derivatives/fsl/loc/run-01/1stLevel.feat/filtered_func_data_reg.nii.gz').affine\n",
    "                nib.save(nib.Nifti1Image(sl_result, affine), result_file)\n",
    "                \n",
    "                logging.info(f\"Completed analysis for subject {sub}, runs {run_combo}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing subject {sub}, runs {run_combo}: {str(e)}\")\n",
    "            finally:\n",
    "                gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiak_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
