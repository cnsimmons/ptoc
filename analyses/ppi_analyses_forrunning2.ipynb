{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run to start\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,curr_dir)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import statsmodels.api as s\n",
    "from sklearn import metrics\n",
    "\n",
    "import pdb\n",
    "import ptoc_params as params\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load additional libraries\n",
    "from nilearn import image, plotting, input_data, glm\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nibabel as nib\n",
    "import statsmodels.api as sm\n",
    "from nilearn.datasets import load_mni152_brain_mask, load_mni152_template\n",
    "from nilearn.glm.first_level import compute_regressor \n",
    "\n",
    "data_dir = params.data_dir\n",
    "results_dir = params.results_dir\n",
    "fig_dir = params.fig_dir\n",
    "raw_dir = params.raw_dir\n",
    "sub_info = params.sub_info\n",
    "task_info = params.task_info\n",
    "\n",
    "suf = params.suf\n",
    "#mni = load_mni152_brain_mask()\n",
    "\n",
    "'''exp info'''\n",
    "#load subject info\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/GitHub_Repos/ptoc/results'\n",
    "exp = ''\n",
    "control_tasks = ['loc']\n",
    "file_suf = ''\n",
    "\n",
    "'''scan params'''\n",
    "tr = 2 #ptoc_params\n",
    "vols = 184 #ptoc_params\n",
    "\n",
    "whole_brain_mask = load_mni152_brain_mask()\n",
    "mni = load_mni152_template()\n",
    "brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "#PPI and FC\n",
    "'''run info'''\n",
    "run_num =3\n",
    "runs = list(range(1,run_num+1))\n",
    "run_combos = []\n",
    "#determine the number of left out run combos\n",
    "\n",
    "for rn1 in range(1,run_num+1):\n",
    "    for rn2 in range(rn1+1,run_num+1):\n",
    "        run_combos.append([rn1,rn2])\n",
    "        \n",
    "\n",
    "#PPI and FC\n",
    "#rois = ['LO', 'PFS', 'pIPS', 'aIPS', 'V1']\n",
    "#sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "\n",
    "#set2\n",
    "rois = ['LO', 'aIPS', 'V1']\n",
    "subs = ['sub-067','sub-068','sub-071']\n",
    "\n",
    "'''run info'''\n",
    "run_num =3\n",
    "runs = list(range(1,run_num+1))\n",
    "run_combos = []\n",
    "#determine the number of left out run combos\n",
    "\n",
    "for rn1 in range(1,run_num+1):\n",
    "    for rn2 in range(rn1+1,run_num+1):\n",
    "        run_combos.append([rn1,rn2])\n",
    "\n",
    "#phys\n",
    "def extract_roi_sphere(img, coords):\n",
    "    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius = 6)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    \n",
    "    phys = np.mean(seed_time_series, axis= 1)\n",
    "    phys = phys.reshape((phys.shape[0],1))\n",
    "    print (f'phys just ran')\n",
    "    return phys\n",
    "\n",
    "#psy\n",
    "def make_psy_cov(runs, ss):\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    \n",
    "    # Only for a single run\n",
    "    times = np.arange(0, vols * tr, tr)  # Create time array covering the whole run duration\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "    \n",
    "    for rn, run in enumerate(runs):\n",
    "        ss_num = ss.split('-')[1]  # Strips the \"sub-\" from the subject number\n",
    "        curr_cov = pd.read_csv(f'{cov_dir}/catloc_{ss_num}_run-0{run}_Object.txt', sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        \n",
    "        # Contrasting (negative) covariate\n",
    "        curr_cont = pd.read_csv(f'{cov_dir}/catloc_{ss_num}_run-0{run}_Scramble.txt', sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        curr_cont.iloc[:, 2] = curr_cont.iloc[:, 2] * -1  # Make contrasting cov negative\n",
    "        \n",
    "        curr_cov = curr_cov.append(curr_cont)  # Append to positive\n",
    "        \n",
    "        # Append to concatenated cov\n",
    "        full_cov = full_cov.append(curr_cov)\n",
    "    \n",
    "    full_cov = full_cov.sort_values(by=['onset'])\n",
    "    cov = full_cov.to_numpy()\n",
    "\n",
    "    # Convolve to HRF\n",
    "    psy, name = compute_regressor(cov.T, 'spm', times)\n",
    "    \n",
    "    # Debug: Print the shape of the created psy array\n",
    "    print(f'Full covariate matrix shape: {cov.shape}')\n",
    "    print(f'Created psy array shape: {psy.shape}')\n",
    "    print (f'psy just ran')\n",
    "    return psy\n",
    "\n",
    "#ppi\n",
    "def conduct_ppi():\n",
    "    for ss in subs:\n",
    "        print(ss)\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01/'  #study is PTOC\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'  #rois in PTOC\n",
    "        raw_dir = params.raw_dir  #hemispace\n",
    "        temp_dir = f'{raw_dir}/{ss}/ses-01/derivatives/fsl/loc' #hemispace\n",
    "        \n",
    "        roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords.csv')  # load ROI coordinates\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        out_dir = f'{study_dir}/{ss}/ses-01/derivatives/fc'\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        print(f'Output directory ensured at {out_dir}')\n",
    "\n",
    "        for tsk in ['loc']:\n",
    "            for rr in rois:\n",
    "                all_runs_ppi = []\n",
    "                all_runs_fc = []\n",
    "                for rcn, rc in enumerate(run_combos):  # run combos\n",
    "                    curr_coords = roi_coords[(roi_coords['index'] == rcn) & (roi_coords['task'] == tsk) & (roi_coords['roi'] == rr)]\n",
    "                    for rn in rc:\n",
    "                        filtered_list = []\n",
    "                        curr_run = image.load_img(f'{temp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz') \n",
    "                        curr_run = image.clean_img(curr_run, standardize=True)\n",
    "                        filtered_list.append(curr_run)    \n",
    "                    print('Loaded filtered data')\n",
    "                    \n",
    "                    img4d = image.concat_imgs(filtered_list)\n",
    "                    print('Loaded 4D image') \n",
    "                    \n",
    "                    phys = extract_roi_sphere(img4d, curr_coords[['x', 'y', 'z']].values.tolist()[0])  # extract ROI sphere coordinate\n",
    "                    print('Extracted sphere') \n",
    "                    \n",
    "                    # Load behavioral data\n",
    "                    psy = make_psy_cov([rn], ss)  # grabs the covariate and converts the three-column into binary data\n",
    "                    print('Loaded psy cov')\n",
    "                    \n",
    "                    # Debug: Print shapes of img4d and the concatenated phys and psy arrays\n",
    "                    print(f'Shape of img4d: {img4d.shape}')\n",
    "                    print(f'Length of phys: {phys.shape[0]}')\n",
    "                    print(f'Length of psy: {psy.shape[0]}')\n",
    "                    \n",
    "                    # Ensure phys and psy lengths match\n",
    "                    assert phys.shape[0] == psy.shape[0], f\"Length mismatch: phys={phys.shape[0]}, psy={psy.shape[0]}\"\n",
    "                    \n",
    "                    # Combine phys (seed TS) and psy (task TS) into a regressor\n",
    "                    confounds = pd.DataFrame(columns=['psy', 'phys'])\n",
    "                    confounds['psy'] = psy[:, 0]\n",
    "                    confounds['phys'] = phys[:, 0]\n",
    "                    print('Combined psy and phys')\n",
    "\n",
    "                    # Create PPI cov by multiplying psy * phys\n",
    "                    ppi = psy * phys\n",
    "                    ppi = ppi.reshape((ppi.shape[0], 1))\n",
    "                    print('Created PPI')\n",
    "                    \n",
    "                    # Extract brain time series using PPI confounds\n",
    "                    brain_time_series_ppi = brain_masker.fit_transform(img4d, confounds=[confounds])\n",
    "                    print('Extracted brain TS for PPI')\n",
    "\n",
    "                    # Correlate interaction term to TS for voxels in the brain for PPI\n",
    "                    seed_to_voxel_correlations_ppi = (np.dot(brain_time_series_ppi.T, ppi) / ppi.shape[0])\n",
    "                    print(ss, rr, tsk, seed_to_voxel_correlations_ppi.max())\n",
    "                    print('Correlated interaction term for PPI')\n",
    "\n",
    "                    # Transform PPI correlation back to brain space\n",
    "                    seed_to_voxel_correlations_ppi = np.arctanh(seed_to_voxel_correlations_ppi)\n",
    "                    print('Transformed PPI correlation')\n",
    "\n",
    "                    # Transform PPI correlation map back to brain\n",
    "                    seed_to_voxel_correlations_img_ppi = brain_masker.inverse_transform(seed_to_voxel_correlations_ppi.T)\n",
    "                    print('Transformed PPI correlation map')\n",
    "\n",
    "                    all_runs_ppi.append(seed_to_voxel_correlations_img_ppi)\n",
    "                    \n",
    "                    ##FC SECTION\n",
    "                    # Extract brain time series using only psy confound for FC\n",
    "                    brain_time_series_fc = brain_masker.fit_transform(img4d)\n",
    "                    print('Extracted brain TS for FC')\n",
    "\n",
    "                    # Correlate psy term for FC\n",
    "                    seed_to_voxel_correlations_fc = (np.dot(brain_time_series_fc.T, psy) / psy.shape[0])\n",
    "                    print('Correlated psy term for FC')\n",
    "\n",
    "                    # Transform FC correlation back to brain space\n",
    "                    seed_to_voxel_correlations_fc = np.arctanh(seed_to_voxel_correlations_fc)\n",
    "                    print('Transformed FC correlation')\n",
    "\n",
    "                    # Transform FC correlation map back to brain\n",
    "                    seed_to_voxel_correlations_img_fc = brain_masker.inverse_transform(seed_to_voxel_correlations_fc.T)\n",
    "                    print('Transformed FC correlation map')\n",
    "\n",
    "                    all_runs_fc.append(seed_to_voxel_correlations_img_fc)\n",
    "\n",
    "                mean_ppi = image.mean_img(all_runs_ppi)\n",
    "                mean_fc = image.mean_img(all_runs_fc)\n",
    "                \n",
    "                # Save PPI results\n",
    "                nib.save(mean_ppi, f'{out_dir}/{ss}_{rr}_{tsk}_ppi.nii.gz')\n",
    "                print(f'Saved PPI result: {out_dir}/{ss}_{rr}_{tsk}_ppi.nii.gz')\n",
    "                \n",
    "                # Save FC results\n",
    "                nib.save(mean_fc, f'{out_dir}/{ss}_{rr}_{tsk}_fc.nii.gz')\n",
    "                print(f'Saved FC result: {out_dir}/{ss}_{rr}_{tsk}_fc.nii.gz')\n",
    "\n",
    "conduct_ppi()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85d6a1f04e70c5556da1eb33c5679a806be4c5365a0d8ae0b55875cb552fe2b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
