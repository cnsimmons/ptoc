{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run to start\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,curr_dir)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import statsmodels.api as s\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, maskers, plotting, datasets\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import time\n",
    "import itertools \n",
    "import warnings\n",
    "\n",
    "\n",
    "import pdb\n",
    "import ptoc_params as params\n",
    "\n",
    "from plotnine import *\n",
    "#from plotnine import ggplot, aes, geom_point\n",
    "\n",
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load additional libraries\n",
    "from nilearn import image, plotting, input_data, glm\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nibabel as nib\n",
    "import statsmodels.api as sm\n",
    "from nilearn.datasets import load_mni152_brain_mask, load_mni152_template\n",
    "from nilearn.glm.first_level import compute_regressor ##?????\n",
    "\n",
    "data_dir = params.data_dir\n",
    "results_dir = params.results_dir\n",
    "fig_dir = params.fig_dir\n",
    "raw_dir = params.raw_dir\n",
    "sub_info = params.sub_info\n",
    "task_info = params.task_info\n",
    "\n",
    "suf = params.suf\n",
    "#mni = load_mni152_brain_mask()\n",
    "\n",
    "'''exp info'''\n",
    "#load subject info\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "\n",
    "\n",
    "##Just controls\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/GitHub_Repos/ptoc/results'\n",
    "exp = ''\n",
    "#rois = ['LO']  # Run for one ROI initially\n",
    "#rois = ['LO', 'PFS', 'pIPS','aIPS', 'V1']\n",
    "control_tasks = ['loc']\n",
    "file_suf = ''\n",
    "\n",
    "'''scan params'''\n",
    "tr = 2 #ptoc_params\n",
    "vols = 184 #ptoc_params\n",
    "\n",
    "whole_brain_mask = load_mni152_brain_mask()\n",
    "mni = load_mni152_template()\n",
    "brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract_roi_coords by hemi\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_roi_coords():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    hemispheres = ['left', 'right']\n",
    "    sub_info = pd.read_csv(os.path.join(curr_dir, 'sub_info.csv'))\n",
    "    subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    #subs = ['sub-025']\n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = [(r1, r2) for r1 in runs for r2 in runs if r1 < r2]\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f'Processing subject: {ss}')\n",
    "        sub_dir = os.path.join(study_dir, ss, 'ses-01')\n",
    "        roi_dir = os.path.join(sub_dir, 'derivatives', 'rois')\n",
    "        parcel_dir = os.path.join(roi_dir, 'parcels')\n",
    "        temp_dir = os.path.join(raw_dir, ss, 'ses-01', 'derivatives', 'fsl', 'loc')\n",
    "        os.makedirs(os.path.join(roi_dir, 'spheres'), exist_ok=True)\n",
    "\n",
    "        roi_coords = []\n",
    "        for idx, rc in enumerate(run_combos):\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = os.path.join(temp_dir, f'run-0{rn}', '1stLevel.feat', 'stats', 'zstat3_anat.nii.gz')\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "\n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "\n",
    "            sub_anat_path = os.path.join(temp_dir, f'run-0{rc[0]}', '1stLevel.feat', 'example_func.nii.gz')\n",
    "            if not os.path.exists(sub_anat_path):\n",
    "                print(f\"Anatomical image not found: {sub_anat_path}\")\n",
    "                continue\n",
    "            sub_anat = image.load_img(sub_anat_path)\n",
    "\n",
    "            for pr in parcels:\n",
    "                roi_path = os.path.join(parcel_dir, f'{pr}.nii.gz')\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi_img = image.load_img(roi_path)\n",
    "                    roi_data = roi_img.get_fdata()\n",
    "                    zstat_data = mean_zstat.get_fdata()\n",
    "\n",
    "                    # Get the middle x-coordinate\n",
    "                    mid_x = roi_data.shape[0] // 2\n",
    "\n",
    "                    for hemi in hemispheres:\n",
    "                        # Create hemisphere mask\n",
    "                        if hemi == 'left':\n",
    "                            hemi_mask = np.zeros_like(roi_data)\n",
    "                            hemi_mask[:mid_x, :, :] = 1\n",
    "                        else:  # right hemisphere\n",
    "                            hemi_mask = np.zeros_like(roi_data)\n",
    "                            hemi_mask[mid_x:, :, :] = 1\n",
    "\n",
    "                        # Apply masks\n",
    "                        masked_roi = roi_data * hemi_mask\n",
    "                        masked_zstat = zstat_data * masked_roi\n",
    "\n",
    "                        # Find peak coordinates\n",
    "                        peak_idx = np.unravel_index(np.argmax(masked_zstat), masked_zstat.shape)\n",
    "                        peak_coords = image.coord_transform(*peak_idx, mean_zstat.affine)\n",
    "\n",
    "                        roi_coords.append({\n",
    "                            'index': idx,\n",
    "                            'task': 'loc',\n",
    "                            'roi': pr,\n",
    "                            'hemisphere': hemi,\n",
    "                            'x': peak_coords[0],\n",
    "                            'y': peak_coords[1],\n",
    "                            'z': peak_coords[2]\n",
    "                        })\n",
    "                        peak_voxel = np.round(peak_coords).astype(int)\n",
    "                        print(f\"ROI: {pr}, Hemisphere: {hemi}, Run combination: {rc}\")\n",
    "                        print(f\"Peak coordinates: {peak_coords}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "\n",
    "        roi_coords_df = pd.DataFrame(roi_coords)\n",
    "        roi_coords_df.to_csv(os.path.join(roi_dir, 'spheres', 'sphere_coords_hemisphere.csv'), index=False)\n",
    "        print(f\"ROI coordinates saved to {os.path.join(roi_dir, 'spheres', 'sphere_coords_hemisphere.csv')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_roi_coords()\n",
    "    print(\"ROI coordinate extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.8.24 extract_roi_coords for subject specific rois\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_roi_coords():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(os.path.join(curr_dir, 'sub_info.csv'))\n",
    "    subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    #subs = ['sub-025']\n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = [(r1, r2) for r1 in runs for r2 in runs if r1 < r2]\n",
    "    \n",
    "    for ss in subs:\n",
    "        print(f'Processing subject: {ss}')\n",
    "        sub_dir = os.path.join(study_dir, ss, 'ses-01')\n",
    "        roi_dir = os.path.join(sub_dir, 'derivatives', 'rois')\n",
    "        parcel_dir = os.path.join(roi_dir, 'parcels')\n",
    "        temp_dir = os.path.join(raw_dir, ss, 'ses-01', 'derivatives', 'fsl', 'loc')\n",
    "        os.makedirs(os.path.join(roi_dir, 'spheres'), exist_ok=True)\n",
    "        roi_coords = []\n",
    "        \n",
    "        for idx, rc in enumerate(run_combos):\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = os.path.join(temp_dir, f'run-0{rn}', '1stLevel.feat', 'stats', 'zstat3_anat.nii.gz')\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "            \n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "            \n",
    "            # Load a single volume for visualization\n",
    "            sub_anat_path = os.path.join(temp_dir, f'run-0{rc[0]}', '1stLevel.feat', 'example_func.nii.gz')\n",
    "            if not os.path.exists(sub_anat_path):\n",
    "                print(f\"Anatomical image not found: {sub_anat_path}\")\n",
    "                continue\n",
    "            sub_anat = image.load_img(sub_anat_path)\n",
    "            \n",
    "            for pr in parcels:\n",
    "                roi_path = os.path.join(parcel_dir, f'{pr}.nii.gz')\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi_img = image.load_img(roi_path)\n",
    "                    masked_data = image.math_img('img1 * img2', img1=mean_zstat, img2=roi_img).get_fdata()\n",
    "                    peak_idx = np.unravel_index(np.argmax(masked_data), masked_data.shape)\n",
    "                    peak_coords = image.coord_transform(*peak_idx, mean_zstat.affine)\n",
    "                    \n",
    "                    roi_coords.append({\n",
    "                        'index': idx,  # Add index corresponding to run combination\n",
    "                        'task': 'loc',\n",
    "                        'roi': pr,\n",
    "                        'x': peak_coords[0],\n",
    "                        'y': peak_coords[1],\n",
    "                        'z': peak_coords[2]\n",
    "                    })\n",
    "                    \n",
    "                    # After finding peak_coords\n",
    "                    peak_voxel = np.round(peak_coords).astype(int)\n",
    "\n",
    "                    print(f\"ROI: {pr}, Run combination: {rc}\")\n",
    "                    print(f\"Peak coordinates: {peak_coords}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "        \n",
    "        roi_coords_df = pd.DataFrame(roi_coords)\n",
    "        roi_coords_df.to_csv(os.path.join(roi_dir, 'spheres', 'sphere_coords.csv'), index=False)\n",
    "        print(f\"ROI coordinates saved to {os.path.join(roi_dir, 'spheres', 'sphere_coords.csv')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_roi_coords()\n",
    "    print(\"ROI coordinate extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8/7/24 at 1:30 pm reviewed and confirmed # 8/6/24 at 10:30 pm Extract_roi_coords\n",
    "# it runs well and looks good but some of the coordinate are too similar i.e. identical for different runs, this wasn't a problem and confirmed in the below cell. \n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "mni_parcel_dir = f'{curr_dir}/roiParcels'\n",
    "\n",
    "def extract_roi_coords():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "    subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    #subs = ['sub-025']\n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = list(itertools.combinations(runs, 2))\n",
    "    \n",
    "    # Load MNI152 template for visualization\n",
    "    mni_template = image.load_img('/opt/fsl/6.0.3/data/standard/MNI152_T1_2mm_brain.nii.gz')\n",
    "    \n",
    "    for ss in subs:\n",
    "        print(f'Processing subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        os.makedirs(f'{roi_dir}/spheres', exist_ok=True)\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "        roi_coords = pd.DataFrame(columns=['index', 'task', 'roi', 'x', 'y', 'z'])\n",
    "        \n",
    "        index = 0\n",
    "        for rc in run_combos:\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = f'/lab_data/behrmannlab/vlad/hemispace/{ss}/ses-01/derivatives/fsl/loc/run-0{rn}/1stLevel.feat/stats/zstat3_mni.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "            \n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "            \n",
    "            for pr in parcels:\n",
    "                roi_path = f'{mni_parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    # Find peak voxel within ROI\n",
    "                    masked_data = image.math_img('img1 * img2', img1=mean_zstat, img2=roi).get_fdata()\n",
    "                    peak_idx = np.unravel_index(np.argmax(masked_data), masked_data.shape)\n",
    "                    peak_coords = image.coord_transform(*peak_idx, mean_zstat.affine)\n",
    "                    \n",
    "                    roi_coords = pd.concat([roi_coords, pd.DataFrame({\n",
    "                        'index': [index],\n",
    "                        'task': ['loc'],\n",
    "                        'roi': [pr],\n",
    "                        'x': [peak_coords[0]],\n",
    "                        'y': [peak_coords[1]],\n",
    "                        'z': [peak_coords[2]]\n",
    "                    })], ignore_index=True)\n",
    "                    \n",
    "                    # Visualize ROI and peak voxel on MNI template\n",
    "                    display = plotting.plot_roi(roi, bg_img=mni_template,\n",
    "                                                title=f'{ss} - {pr} - Runs {rc[0]}{rc[1]}')\n",
    "                    display.add_markers([peak_coords], marker_color='r', marker_size=100)\n",
    "                    #plt.savefig(f'{roi_dir}/{ss}_{pr}_runs{rc[0]}{rc[1]}_peak_mni.png')\n",
    "                    plt.close()\n",
    "                    \n",
    "                    print(f\"ROI: {pr}, Peak coordinates: {peak_coords}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "            \n",
    "            index += 1\n",
    "        \n",
    "        roi_coords.to_csv(f'{roi_dir}/spheres/sphere_coords.csv', index=False)\n",
    "        print(f\"ROI coordinates saved to {roi_dir}/spheres/sphere_coords.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_roi_coords()\n",
    "    print(\"ROI coordinate extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.7.24 1 pm, plots heat map of averaged and raw individual run's ROIs\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'hemispace'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "mni_parcel_dir = f'{curr_dir}/roiParcels'\n",
    "\n",
    "def visualize_roi_activation_raw():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "    #subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    subs = ['sub-025', 'sub-057', 'sub-059'] # Update this list as needed\n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = list(itertools.combinations(runs, 2))\n",
    "\n",
    "    # Load MNI152 template for visualization\n",
    "    mni_template = image.load_img('/opt/fsl/6.0.3/data/standard/MNI152_T1_2mm_brain.nii.gz')\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f'Visualizing activation for subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "\n",
    "        for rc in run_combos:\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = f'{exp_dir}/loc/run-0{rn}/1stLevel.feat/stats/zstat3_mni.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                    # Print summary statistics\n",
    "                    data = curr_run.get_fdata()\n",
    "                    print(f\"Run {rn} stats: mean={np.mean(data):.4f}, max={np.max(data):.4f}, min={np.min(data):.4f}, std={np.std(data):.4f}\")\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "            \n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "            \n",
    "            # Manual averaging\n",
    "            mean_data = np.mean([run.get_fdata() for run in all_runs], axis=0)\n",
    "            mean_zstat = image.new_img_like(all_runs[0], mean_data)\n",
    "            \n",
    "            # Print summary statistics of the averaged data\n",
    "            print(f\"Averaged data stats: mean={np.mean(mean_data):.4f}, max={np.max(mean_data):.4f}, min={np.min(mean_data):.4f}, std={np.std(mean_data):.4f}\")\n",
    "\n",
    "            for pr in parcels:\n",
    "                roi_path = f'{mni_parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    # Create a masked version of the mean_zstat image\n",
    "                    masked_zstat = image.math_img('img1 * img2', img1=mean_zstat, img2=roi)\n",
    "\n",
    "                    # Visualize the activation within the ROI\n",
    "                    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                    fig.suptitle(f'{ss} - {pr} - Runs {rc[0]}{rc[1]} Activation')\n",
    "\n",
    "                    # Sagittal view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template,\n",
    "                                           display_mode='x', cut_coords=1,\n",
    "                                           threshold=0, colorbar=True, axes=ax1)\n",
    "                    ax1.set_title('Sagittal')\n",
    "\n",
    "                    # Coronal view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template,\n",
    "                                           display_mode='y', cut_coords=1,\n",
    "                                           threshold=0, colorbar=True, axes=ax2)\n",
    "                    ax2.set_title('Coronal')\n",
    "\n",
    "                    # Axial view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template,\n",
    "                                           display_mode='z', cut_coords=1,\n",
    "                                           threshold=0, colorbar=True, axes=ax3)\n",
    "                    ax3.set_title('Axial')\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    #plt.savefig(f'{roi_dir}/{ss}_{pr}_runs{rc[0]}{rc[1]}_activation.png')\n",
    "                    #plt.close()\n",
    "                    print(f\"Activation map saved for ROI: {pr}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "\n",
    "    print(\"ROI activation visualization completed.\")\n",
    "\n",
    "def visualize_roi_activation_combos():\n",
    "    parcels = ['pIPS', 'LO']\n",
    "    sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "    #subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "    subs = ['sub-025', 'sub-057', 'sub-059']  # Update this list as needed\n",
    "    \n",
    "    runs = [1, 2, 3]\n",
    "    run_combos = list(itertools.combinations(runs, 2))\n",
    "\n",
    "    # Load MNI152 template for visualization\n",
    "    mni_template = image.load_img('/opt/fsl/6.0.3/data/standard/MNI152_T1_2mm_brain.nii.gz')\n",
    "\n",
    "    for ss in subs:\n",
    "        print(f'Visualizing activation for subject: {ss}')\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01'\n",
    "        roi_dir = f'{sub_dir}/derivatives/rois'\n",
    "        exp_dir = f'{sub_dir}/derivatives/fsl'\n",
    "\n",
    "        for rc in run_combos:\n",
    "            print(f\"Run combination: {rc}\")\n",
    "            all_runs = []\n",
    "            for rn in rc:\n",
    "                curr_run_path = f'{exp_dir}/loc/run-0{rn}/1stLevel.feat/stats/zstat3_mni.nii.gz'\n",
    "                if os.path.exists(curr_run_path):\n",
    "                    curr_run = image.load_img(curr_run_path)\n",
    "                    all_runs.append(curr_run)\n",
    "                else:\n",
    "                    print(f'File does not exist: {curr_run_path}')\n",
    "\n",
    "            if len(all_runs) != 2:\n",
    "                print(f\"Skipping combination {rc} due to missing data\")\n",
    "                continue\n",
    "\n",
    "            mean_zstat = image.mean_img(all_runs)\n",
    "\n",
    "            for pr in parcels:\n",
    "                roi_path = f'{mni_parcel_dir}/{pr}.nii.gz'\n",
    "                if os.path.exists(roi_path):\n",
    "                    roi = image.load_img(roi_path)\n",
    "                    \n",
    "                    # Create a masked version of the mean_zstat image\n",
    "                    masked_zstat = image.math_img('img1 * img2', img1=mean_zstat, img2=roi)\n",
    "                    \n",
    "                    # Visualize the activation within the ROI\n",
    "                    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                    fig.suptitle(f'{ss} - {pr} - Runs {rc[0]}{rc[1]} Activation')\n",
    "                    \n",
    "                    # Sagittal view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template, \n",
    "                                        display_mode='x', cut_coords=1, \n",
    "                                        threshold=0, colorbar=True, axes=ax1)\n",
    "                    ax1.set_title('Sagittal')\n",
    "\n",
    "                    # Coronal view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template, \n",
    "                                        display_mode='y', cut_coords=1, \n",
    "                                        threshold=0, colorbar=True, axes=ax2)\n",
    "                    ax2.set_title('Coronal')\n",
    "\n",
    "                    # Axial view\n",
    "                    plotting.plot_stat_map(masked_zstat, bg_img=mni_template, \n",
    "                                        display_mode='z', cut_coords=1, \n",
    "                                        threshold=0, colorbar=True, axes=ax3)\n",
    "                    ax3.set_title('Axial')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    #plt.savefig(f'{roi_dir}/{ss}_{pr}_runs{rc[0]}{rc[1]}_activation.png')\n",
    "                    #plt.close()\n",
    "\n",
    "                    print(f\"Activation map saved for ROI: {pr}\")\n",
    "                else:\n",
    "                    print(f'ROI file does not exist: {roi_path}')\n",
    "\n",
    "    print(\"ROI activation visualization completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #visualize_roi_activation_combos()\n",
    "    #visualize_roi_activation_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc_ppi native space with hemispheres\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, input_data\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import nibabel as nib\n",
    "import sys\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "subs = ['sub-068', 'sub-071', 'sub-083', 'sub-084']  # Update this list as needed\n",
    "rois = ['PFS', 'aIPS'] # Run for one ROI initially\n",
    "hemispheres = ['left', 'right']\n",
    "run_num = 3\n",
    "runs = list(range(1, run_num + 1))\n",
    "run_combos = [[rn1, rn2] for rn1 in range(1, run_num + 1) for rn2 in range(rn1 + 1, run_num + 1)]\n",
    "\n",
    "def extract_roi_sphere(img, coords):\n",
    "    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius=6)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    phys = np.mean(seed_time_series, axis=1).reshape(-1, 1)\n",
    "    return phys\n",
    "\n",
    "def make_psy_cov(runs, ss):\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    vols, tr = 184, 2.0\n",
    "    times = np.arange(0, vols * tr, tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for rn in runs:\n",
    "        ss_num = ss.split('-')[1]\n",
    "        obj_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_Object.txt'\n",
    "        scr_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_Scramble.txt'\n",
    "\n",
    "        if not os.path.exists(obj_cov_file) or not os.path.exists(scr_cov_file):\n",
    "            print(f'Covariate file not found for run {rn}')\n",
    "            continue\n",
    "\n",
    "        obj_cov = pd.read_csv(obj_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov = pd.read_csv(scr_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov['value'] *= -1\n",
    "        full_cov = pd.concat([full_cov, obj_cov, scr_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    cov = full_cov.to_numpy()\n",
    "    valid_onsets = cov[:, 0] < times[-1]\n",
    "    cov = cov[valid_onsets]\n",
    "\n",
    "    if cov.shape[0] == 0:\n",
    "        print('No valid covariate data after filtering. Returning zeros array.')\n",
    "        return np.zeros((vols, 1))\n",
    "\n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    return psy\n",
    "\n",
    "def conduct_analyses():\n",
    "    for ss in subs:\n",
    "        print(f\"Processing subject: {ss}\")\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01/'\n",
    "        roi_dir = f'{sub_dir}derivatives/rois'\n",
    "        temp_dir = f'{raw_dir}/{ss}/ses-01/derivatives/fsl/loc'\n",
    "        \n",
    "        roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords_hemisphere.csv')\n",
    "        \n",
    "        out_dir = f'{study_dir}/{ss}/ses-01/derivatives'\n",
    "        os.makedirs(f'{out_dir}/fc', exist_ok=True)\n",
    "        \n",
    "        # subject-specific brain mask\n",
    "        def get_subject_mask(ss):\n",
    "            mask_path  = f'{raw_dir}/{ss}/ses-01/anat/{ss}_ses-01_T1w_brain_mask.nii.gz'\n",
    "            return nib.load(mask_path)\n",
    "        \n",
    "        # Load subject-specific mask\n",
    "        whole_brain_mask = get_subject_mask(ss)\n",
    "        brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "        for tsk in ['loc']:\n",
    "            for rr in rois:\n",
    "                for hemi in hemispheres:\n",
    "                    print(f\"Processing ROI: {rr}, Hemisphere: {hemi}\")\n",
    "                    \n",
    "                    fc_file = f'{out_dir}/fc/{ss}_{rr}_{hemi}_{tsk}_fc.nii.gz'\n",
    "                    ppi_file = f'{out_dir}/fc/{ss}_{rr}_{hemi}_{tsk}_ppi.nii.gz'\n",
    "                    \n",
    "                    do_fc = not os.path.exists(fc_file)\n",
    "                    do_ppi = not os.path.exists(ppi_file)\n",
    "                    \n",
    "                    if not do_fc and not do_ppi:\n",
    "                        print(f'Both FC and PPI files for {rr} {hemi} already exist. Skipping...')\n",
    "                        continue\n",
    "                    \n",
    "                    all_runs_fc = []\n",
    "                    all_runs_ppi = []\n",
    "                    \n",
    "                    for rcn, rc in enumerate(run_combos):\n",
    "                        curr_coords = roi_coords[(roi_coords['index'] == rcn) & \n",
    "                                                 (roi_coords['task'] == tsk) & \n",
    "                                                 (roi_coords['roi'] == rr) &\n",
    "                                                 (roi_coords['hemisphere'] == hemi)]\n",
    "                        \n",
    "                        if curr_coords.empty:\n",
    "                            print(f\"No coordinates found for {rr}, {hemi}, run combo {rc}\")\n",
    "                            continue\n",
    "                        \n",
    "                        coords = curr_coords[['x', 'y', 'z']].values.tolist()[0]\n",
    "                        \n",
    "                        filtered_list = [image.clean_img(image.load_img(f'{temp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz'), standardize=True) for rn in rc]\n",
    "                        img4d = image.concat_imgs(filtered_list)\n",
    "                        \n",
    "                        phys = extract_roi_sphere(img4d, coords)\n",
    "                        \n",
    "                        # Ensure phys length matches the number of volumes\n",
    "                        if phys.shape[0] > 184 * len(rc):\n",
    "                            phys = phys[:184 * len(rc)]\n",
    "                        \n",
    "                        brain_time_series = brain_masker.fit_transform(img4d)\n",
    "                        \n",
    "                        if do_fc:\n",
    "                            # FC Analysis\n",
    "                            correlations = np.dot(brain_time_series.T, phys) / phys.shape[0]\n",
    "                            correlations = np.arctanh(correlations.ravel())\n",
    "                            correlation_img = brain_masker.inverse_transform(correlations)\n",
    "                            all_runs_fc.append(correlation_img)\n",
    "                        \n",
    "                        if do_ppi:\n",
    "                            # PPI Analysis\n",
    "                            psy = make_psy_cov(rc, ss)  # Generate psy for the current run combination\n",
    "                            \n",
    "                            # Ensure psy length matches phys\n",
    "                            if psy.shape[0] > phys.shape[0]:\n",
    "                                psy = psy[:phys.shape[0]]\n",
    "                            elif psy.shape[0] < phys.shape[0]:\n",
    "                                phys = phys[:psy.shape[0]]\n",
    "                                brain_time_series = brain_time_series[:psy.shape[0]]\n",
    "                            \n",
    "                            ppi_regressor = phys * psy\n",
    "                            ppi_correlations = np.dot(brain_time_series.T, ppi_regressor) / ppi_regressor.shape[0]\n",
    "                            ppi_correlations = np.arctanh(ppi_correlations.ravel())\n",
    "                            ppi_img = brain_masker.inverse_transform(ppi_correlations)\n",
    "                            all_runs_ppi.append(ppi_img)\n",
    "                    \n",
    "                    if do_fc:\n",
    "                        mean_fc = image.mean_img(all_runs_fc)\n",
    "                        nib.save(mean_fc, fc_file)\n",
    "                        print(f'Saved FC result for {rr} {hemi}')\n",
    "                    \n",
    "                    if do_ppi:\n",
    "                        mean_ppi = image.mean_img(all_runs_ppi)\n",
    "                        nib.save(mean_ppi, ppi_file)\n",
    "                        print(f'Saved PPI result for {rr} {hemi}')\n",
    "\n",
    "# Call the function\n",
    "conduct_analyses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc_ppi all in subject space\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image, input_data\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import nibabel as nib\n",
    "import sys\n",
    "\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "#subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "subs = ['sub-085', 'sub-087', 'sub-088', 'sub-093']  # Update this list as needed\n",
    "rois = ['LO', 'pIPS']\n",
    "run_num = 3\n",
    "runs = list(range(1, run_num + 1))\n",
    "run_combos = [[rn1, rn2] for rn1 in range(1, run_num + 1) for rn2 in range(rn1 + 1, run_num + 1)]\n",
    "\n",
    "def extract_roi_sphere(img, coords):\n",
    "    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius=6)\n",
    "    seed_time_series = roi_masker.fit_transform(img)\n",
    "    phys = np.mean(seed_time_series, axis=1).reshape(-1, 1)\n",
    "    return phys\n",
    "\n",
    "def make_psy_cov(runs, ss):\n",
    "    temp_dir = f'{raw_dir}/{ss}/ses-01'\n",
    "    cov_dir = f'{temp_dir}/covs'\n",
    "    vols, tr = 184, 2.0\n",
    "    times = np.arange(0, vols * tr, tr)\n",
    "    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])\n",
    "\n",
    "    for rn in runs:\n",
    "        ss_num = ss.split('-')[1]\n",
    "        obj_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_Object.txt'\n",
    "        scr_cov_file = f'{cov_dir}/catloc_{ss_num}_run-0{rn}_Scramble.txt'\n",
    "\n",
    "        if not os.path.exists(obj_cov_file) or not os.path.exists(scr_cov_file):\n",
    "            print(f'Covariate file not found for run {rn}')\n",
    "            continue\n",
    "\n",
    "        obj_cov = pd.read_csv(obj_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov = pd.read_csv(scr_cov_file, sep='\\t', header=None, names=['onset', 'duration', 'value'])\n",
    "        scr_cov['value'] *= -1\n",
    "        full_cov = pd.concat([full_cov, obj_cov, scr_cov])\n",
    "\n",
    "    full_cov = full_cov.sort_values(by=['onset']).reset_index(drop=True)\n",
    "    cov = full_cov.to_numpy()\n",
    "    valid_onsets = cov[:, 0] < times[-1]\n",
    "    cov = cov[valid_onsets]\n",
    "\n",
    "    if cov.shape[0] == 0:\n",
    "        print('No valid covariate data after filtering. Returning zeros array.')\n",
    "        return np.zeros((vols, 1))\n",
    "\n",
    "    psy, _ = compute_regressor(cov.T, 'spm', times)\n",
    "    return psy\n",
    "\n",
    "def conduct_analyses():\n",
    "    for ss in subs:\n",
    "        print(f\"Processing subject: {ss}\")\n",
    "        sub_dir = f'{study_dir}/{ss}/ses-01/'\n",
    "        roi_dir = f'{sub_dir}derivatives/rois'\n",
    "        temp_dir = f'{raw_dir}/{ss}/ses-01/derivatives/fsl/loc'\n",
    "        \n",
    "        roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords.csv')\n",
    "        \n",
    "        out_dir = f'{study_dir}/{ss}/ses-01/derivatives'\n",
    "        os.makedirs(f'{out_dir}/fc', exist_ok=True)\n",
    "        os.makedirs(f'{out_dir}/fc', exist_ok=True)\n",
    "        \n",
    "        # subject-specific brain mask\n",
    "        def get_subject_mask(ss):\n",
    "            mask_path  = f'{raw_dir}/{ss}/ses-01/anat/{ss}_ses-01_T1w_brain_mask.nii.gz'\n",
    "            return nib.load(mask_path)\n",
    "        \n",
    "        # Load subject-specific mask\n",
    "        whole_brain_mask = get_subject_mask(ss)\n",
    "        brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)\n",
    "\n",
    "        for tsk in ['loc']:\n",
    "            for rr in rois:\n",
    "                print(f\"Processing ROI: {rr}\")\n",
    "                \n",
    "                fc_file = f'{out_dir}/fc/{ss}_{rr}_{tsk}_fc.nii.gz'\n",
    "                ppi_file = f'{out_dir}/fc/{ss}_{rr}_{tsk}_ppi.nii.gz'\n",
    "                \n",
    "                do_fc = not os.path.exists(fc_file)\n",
    "                do_ppi = not os.path.exists(ppi_file)\n",
    "                \n",
    "                if not do_fc and not do_ppi:\n",
    "                    print(f'Both FC and PPI files for {rr} already exist. Skipping...')\n",
    "                    continue\n",
    "                \n",
    "                all_runs_fc = []\n",
    "                all_runs_ppi = []\n",
    "                \n",
    "                for rcn, rc in enumerate(run_combos):\n",
    "                    curr_coords = roi_coords[(roi_coords['index'] == rcn) & (roi_coords['task'] == tsk) & (roi_coords['roi'] == rr)]\n",
    "                    coords = curr_coords[['x', 'y', 'z']].values.tolist()[0]\n",
    "                    \n",
    "                    filtered_list = [image.clean_img(image.load_img(f'{temp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz'), standardize=True) for rn in rc]\n",
    "                    img4d = image.concat_imgs(filtered_list)\n",
    "                    \n",
    "                    phys = extract_roi_sphere(img4d, coords)\n",
    "                    \n",
    "                    # Ensure phys length matches the number of volumes\n",
    "                    if phys.shape[0] > 184 * len(rc):\n",
    "                        phys = phys[:184 * len(rc)]\n",
    "                    \n",
    "                    brain_time_series = brain_masker.fit_transform(img4d)\n",
    "                    \n",
    "                    if do_fc:\n",
    "                        # FC Analysis\n",
    "                        correlations = np.dot(brain_time_series.T, phys) / phys.shape[0]\n",
    "                        correlations = np.arctanh(correlations.ravel())\n",
    "                        correlation_img = brain_masker.inverse_transform(correlations)\n",
    "                        all_runs_fc.append(correlation_img)\n",
    "                    \n",
    "                    if do_ppi:\n",
    "                        # PPI Analysis\n",
    "                        psy = make_psy_cov(rc, ss)  # Generate psy for the current run combination\n",
    "                        \n",
    "                        # Ensure psy length matches phys\n",
    "                        if psy.shape[0] > phys.shape[0]:\n",
    "                            psy = psy[:phys.shape[0]]\n",
    "                        elif psy.shape[0] < phys.shape[0]:\n",
    "                            phys = phys[:psy.shape[0]]\n",
    "                            brain_time_series = brain_time_series[:psy.shape[0]]\n",
    "                        \n",
    "                        ppi_regressor = phys * psy\n",
    "                        ppi_correlations = np.dot(brain_time_series.T, ppi_regressor) / ppi_regressor.shape[0]\n",
    "                        ppi_correlations = np.arctanh(ppi_correlations.ravel())\n",
    "                        ppi_img = brain_masker.inverse_transform(ppi_correlations)\n",
    "                        all_runs_ppi.append(ppi_img)\n",
    "                \n",
    "                if do_fc:\n",
    "                    mean_fc = image.mean_img(all_runs_fc)\n",
    "                    nib.save(mean_fc, fc_file)\n",
    "                    print(f'Saved FC result for {rr}')\n",
    "                \n",
    "                if do_ppi:\n",
    "                    mean_ppi = image.mean_img(all_runs_ppi)\n",
    "                    nib.save(mean_ppi, ppi_file)\n",
    "                    print(f'Saved PPI result for {rr}')\n",
    "\n",
    "# Call the function\n",
    "conduct_analyses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### conversion is a flirt command and needs to be run in the terminal. ###\n",
    "## run hemi_subj2parcel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##to plot figures use visualize_fc_ppi.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85d6a1f04e70c5556da1eb33c5679a806be4c5365a0d8ae0b55875cb552fe2b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
