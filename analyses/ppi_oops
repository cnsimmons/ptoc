#oops didn't save new hope
#rois = params.rois

#Run to start
curr_dir = f'/user_data/csimmon2/git_repos/ptoc'

import sys
sys.path.insert(0,curr_dir)
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
import scipy.stats as stats
import scipy
import statsmodels.api as s
from sklearn import metrics

import pdb
import ptoc_params as params

from plotnine import *
#from plotnine import ggplot, aes, geom_point

#hide warnings
import warnings
warnings.filterwarnings('ignore')


#load additional libraries
from nilearn import image, plotting, input_data, glm
from nilearn.input_data import NiftiMasker
import nibabel as nib
import statsmodels.api as sm
from nilearn.datasets import load_mni152_brain_mask, load_mni152_template
from nilearn.glm.first_level import compute_regressor ##?????

data_dir = params.data_dir
results_dir = params.results_dir
fig_dir = params.fig_dir
raw_dir = params.raw_dir

sub_info = params.sub_info
task_info = params.task_info

suf = params.suf
rois = params.rois
hemis = params.hemis
#mni = load_mni152_brain_mask()

'''exp info'''
#load subject info
sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')
#mni = load_mni152_brain_mask()
#subs = ['sub-064']  # Run for one subject initially
#subs = sub_info['sub'].tolist()
##Just controls
subs = sub_info[sub_info['group'] == 'control']['sub'].tolist()
study = 'ptoc'
study_dir = f"/lab_data/behrmannlab/vlad/{study}"
out_dir = f'{study_dir}/derivatives/fc'
results_dir = '/user_data/csimmon2/GitHub_Repos/ptoc/results'
exp = ''
#rois = ['LO']  # Run for one ROI initially
#rois = ['LO', 'PFS', 'pIPS','aIPS', 'V1']
control_tasks = ['loc']
file_suf = ''

'''scan params'''
#tr = 1 #in the original code
#vols = 321 #in the original code
tr = 2 #ptoc_params
vols = 184 #ptoc_params

whole_brain_mask = load_mni152_brain_mask()
mni = load_mni152_template()
brain_masker = NiftiMasker(whole_brain_mask, smoothing_fwhm=0, standardize=True)

rois = ['LO']

'''run info'''
run_num =3
runs = list(range(1,run_num+1))
run_combos = []
#determine the number of left out run combos

for rn1 in range(1,run_num+1):
    for rn2 in range(rn1+1,run_num+1):
        run_combos.append([rn1,rn2])

#phys
def extract_roi_sphere(img, coords):
    roi_masker = input_data.NiftiSpheresMasker([tuple(coords)], radius = 6)
    seed_time_series = roi_masker.fit_transform(img)
    
    phys = np.mean(seed_time_series, axis= 1)
    phys = phys.reshape((phys.shape[0],1))
    
    return phys

#psy
def make_psy_cov(runs, ss):
    temp_dir = f'{raw_dir}/{ss}/ses-01'
    cov_dir = f'{temp_dir}/covs'
    
    # Only for a single run
    times = np.arange(0, vols * tr, tr)  # Create time array covering the whole run duration
    full_cov = pd.DataFrame(columns=['onset', 'duration', 'value'])
    
    for rn, run in enumerate(runs):
        ss_num = ss.split('-')[1]  # Strips the "sub-" from the subject number
        curr_cov = pd.read_csv(f'{cov_dir}/catloc_{ss_num}_run-0{run}_Object.txt', sep='\t', header=None, names=['onset', 'duration', 'value'])
        
        # Contrasting (negative) covariate
        curr_cont = pd.read_csv(f'{cov_dir}/catloc_{ss_num}_run-0{run}_Scramble.txt', sep='\t', header=None, names=['onset', 'duration', 'value'])
        curr_cont.iloc[:, 2] = curr_cont.iloc[:, 2] * -1  # Make contrasting cov negative
        
        curr_cov = curr_cov.append(curr_cont)  # Append to positive
        
        # Append to concatenated cov
        full_cov = full_cov.append(curr_cov)
    
    full_cov = full_cov.sort_values(by=['onset'])
    cov = full_cov.to_numpy()

    # Convolve to HRF
    psy, name = compute_regressor(cov.T, 'spm', times)
    
    # Debug: Print the shape of the created psy array
    print(f'Full covariate matrix shape: {cov.shape}')
    print(f'Created psy array shape: {psy.shape}')

    return psy


def conduct_ppi():
    for ss in subs:
        print(f'Processing subject: {ss}')
        sub_dir = f'{study_dir}/{ss}/ses-01/'  # Update with correct study directory
        roi_dir = f'{sub_dir}/derivatives/rois'
        raw_dir = params.raw_dir  # Update with correct raw directory
        temp_dir = f'{raw_dir}/{ss}/ses-01/derivatives/fsl/loc'
        
        roi_coords = pd.read_csv(f'{roi_dir}/spheres/sphere_coords.csv')

        # Ensure output directory exists
        out_dir = f'{study_dir}/{ss}/ses-01/derivatives/fc'
        os.makedirs(out_dir, exist_ok=True)
        print(f'Output directory ensured at {out_dir}')

        for tsk in ['loc']:
            for rr in rois:
                all_runs = []
                for rcn, rc in enumerate(run_combos):
                    curr_coords = roi_coords[(roi_coords['index'] == rcn) & (roi_coords['task'] == tsk) & (roi_coords['roi'] == rr)]

                    filtered_list = []
                    for rn in rc:
                        curr_run = image.load_img(f'{temp_dir}/run-0{rn}/1stLevel.feat/filtered_func_data_reg.nii.gz') 
                        curr_run = image.clean_img(curr_run, standardize=True)
                        filtered_list.append(curr_run)    
                    print('Loaded filtered data')
                    
                    img4d = image.concat_imgs(filtered_list)
                    print('Loaded 4D image') 
                    
                    phys = extract_roi_sphere(img4d, curr_coords[['x', 'y', 'z']].values.tolist()[0])
                    print('Extracted sphere') 
                    
                    # Load behavioral data
                    psy = make_psy_cov(rc, ss)  
                    print('Loaded psy cov')
                    
                    # Ensure phys and psy lengths match
                    assert phys.shape[0] == psy.shape[0], f"Length mismatch: phys={phys.shape[0]}, psy={psy.shape[0]}"
                    
                    # Combine phys (seed TS) and psy (task TS) into a regressor
                    confounds = pd.DataFrame(columns=['psy', 'phys'])
                    confounds['psy'] = psy[:, 0]
                    confounds['phys'] = phys[:, 0]
                    print('Combined psy and phys')

                    # Create PPI cov by multiplying psy * phys
                    ppi = psy * phys
                    ppi = ppi.reshape((ppi.shape[0], 1))
                    print('Created PPI')

                    # Extract brain time series
                    brain_time_series = brain_masker.fit_transform(img4d, confounds=[confounds])
                    brain_time_series_4FC = brain_masker.fit_transform(img4d)
                    print('Extracted brain TS')
                    
                    # Correlate interaction term to TS for voxels in the brain
                    seed_to_voxel_correlations = (np.dot(brain_time_series.T, ppi) / ppi.shape[0])
                    print(ss, rr, tsk, seed_to_voxel_correlations.max())
                    print('Correlated interaction term')
                    
                    # Correlate psy term
                    seed_to_voxel_correlations_psy = (np.dot(brain_time_series_4FC.T, psy) / psy.shape[0])
                    print('Correlated psy term')
                    
                    # Transform correlation back to brain space
                    seed_to_voxel_correlations = np.arctanh(seed_to_voxel_correlations)
                    print('Transformed correlation')
                    
                    # Transform correlation map back to brain
                    seed_to_voxel_correlations_img = brain_masker.inverse_transform(seed_to_voxel_correlations.T)
                    print('Transformed correlation map')

                    all_runs.append(seed_to_voxel_correlations_img)

                mean_fc = image.mean_img(all_runs)
                
                # Add try-except block to catch potential saving errors
                try:
                    ppi_file = f'{out_dir}/sub-{study}{ss}_{rr}_{tsk}_ppi.nii.gz'
                    fc_4fc_file = f'{out_dir}/sub-{study}{ss}_{rr}_{tsk}_fc_4FC.nii.gz'
                    nib.save(mean_fc, ppi_file) 
                    nib.save(mean_fc, fc_4fc_file)
                    print(f'Saved PPI file to {ppi_file}')
                    print(f'Saved FC 4FC file to {fc_4fc_file}')
                except Exception as e:
                    print(f'Error saving files: {e}')

# Call the function with your parameters
conduct_ppi()