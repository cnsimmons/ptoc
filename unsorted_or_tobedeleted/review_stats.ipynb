{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def partial_eta_squared(aov):\n",
    "    \"\"\"Calculate partial eta-squared for ANOVA results.\"\"\"\n",
    "    aov = aov.copy()\n",
    "    aov['pes'] = (aov['Num DF'] * aov['F Value']) / (aov['Num DF'] * aov['F Value'] + aov['Den DF'])\n",
    "    return aov\n",
    "\n",
    "def analyze_roi_data(data, experiment='exp1'):\n",
    "    \"\"\"Analyze ROI data with multiple comparison correction.\"\"\"\n",
    "    results = {}\n",
    "    all_tests = []\n",
    "    \n",
    "    if experiment == 'exp1':\n",
    "        conditions = ['object', 'scramble']\n",
    "        rois = ['LO', 'pIPS']\n",
    "    else:\n",
    "        conditions = ['tool', 'nontool']\n",
    "        rois = ['PFS', 'aIPS', 'LO', 'pIPS']\n",
    "        \n",
    "    for roi in rois:\n",
    "        for hemi in ['left', 'right']:\n",
    "            roi_data = data[(data['roi'] == roi) & (data['hemi'] == hemi)]\n",
    "            cond1_data = roi_data[roi_data['cond'] == conditions[0]]['mean_act'].values\n",
    "            cond2_data = roi_data[roi_data['cond'] == conditions[1]]['mean_act'].values\n",
    "            \n",
    "            # Calculate statistics\n",
    "            t_stat, p_val = ttest_rel(cond1_data, cond2_data)\n",
    "            mean_diff = np.mean(cond1_data - cond2_data)\n",
    "            se_diff = np.std(cond1_data - cond2_data) / np.sqrt(len(cond1_data))\n",
    "            d = mean_diff / np.sqrt((np.std(cond1_data)**2 + np.std(cond2_data)**2) / 2)\n",
    "            \n",
    "            # Store results\n",
    "            all_tests.append({\n",
    "                'roi': f'{hemi}_{roi}',\n",
    "                'p_value': p_val,\n",
    "                't_stat': t_stat,\n",
    "                'mean_diff': mean_diff,\n",
    "                'se': se_diff,\n",
    "                'cohens_d': d,\n",
    "                'n': len(cond1_data),\n",
    "                f'mean_{conditions[0]}': np.mean(cond1_data),\n",
    "                f'mean_{conditions[1]}': np.mean(cond2_data)\n",
    "            })\n",
    "    \n",
    "    # Apply Holm-Bonferroni correction\n",
    "    p_values = [test['p_value'] for test in all_tests]\n",
    "    _, p_corrected, _, _ = multipletests(p_values, method='holm')\n",
    "    \n",
    "    # Update results with corrected p-values\n",
    "    for test, p_corr in zip(all_tests, p_corrected):\n",
    "        results[test['roi']] = test\n",
    "        results[test['roi']]['p_corrected'] = p_corr\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_rmanova(data, factors):\n",
    "    \"\"\"Run repeated measures ANOVA with effect sizes.\"\"\"\n",
    "    aov = AnovaRM(data=data, \n",
    "                  depvar='mean_act',\n",
    "                  subject='sub',\n",
    "                  within=factors).fit()\n",
    "    \n",
    "    aov_table = partial_eta_squared(aov.anova_table)\n",
    "    return aov_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# Experiment 1\n",
    "exp1_results = pd.read_csv(\"/user_data/csimmon2/git_repos/ptoc/results/selectivity/selectivity_summary.csv\")\n",
    "\n",
    "filtered_exp1 = exp1_results[(exp1_results['group'] == 'control') & \n",
    "                            (exp1_results['roi'].isin(['LO', 'pIPS'])) &\n",
    "                            (exp1_results['sub'] != 'sub-084')]\n",
    "\n",
    "# Experiment 2\n",
    "exp2_results = pd.read_csv(\"/user_data/csimmon2/git_repos/ptoc/results/tools/selectivity/selectivity_summarytoolloc.csv\")\n",
    "filtered_exp2 = exp2_results[exp2_results['sub'].str.contains('spaceloc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC Analysis (Experiment 1)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# Import your parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "\n",
    "# Load data\n",
    "data_df = pd.read_csv(f\"{results_dir}/fc_ppi/matchvlad_seed_target_activations.csv\")\n",
    "fc_data = data_df[data_df['analysis'] == 'fc']\n",
    "\n",
    "# Compare hemispheric patterns\n",
    "\n",
    "# Ispilateral vs Contralateral\n",
    "diff = ipsi.values - contra.values  # Convert to numpy arrays for element-wise subtraction\n",
    "std_diff = np.std(diff, ddof=1) # Check for variance in differences\n",
    "if std_diff == 0:  # Handle case where standard deviation is zero\n",
    "    print(\"Standard deviation of differences is zero, preventing computation of Cohen's d.\")\n",
    "    d_ipsi = \"NaN (variance is zero)\"\n",
    "else:\n",
    "    # Compute Cohen's d for paired data\n",
    "    d_ipsi = np.mean(diff) / std_diff\n",
    "\n",
    "# Left vs Right pIPS seeds\n",
    "left_pips = fc_data[fc_data['seed_hemisphere'] == 'left']['mean_activation']\n",
    "right_pips = fc_data[fc_data['seed_hemisphere'] == 'right']['mean_activation']\n",
    "w_stat_seed, p_val_seed = stats.wilcoxon(left_pips, right_pips)\n",
    "# Independent effect size (Cohen's d for unpaired data)\n",
    "d_seed = (np.mean(left_pips) - np.mean(right_pips)) / (\n",
    "    np.sqrt((np.var(left_pips, ddof=1) + np.var(right_pips, ddof=1)) / 2) + 1e-10\n",
    ")\n",
    "\n",
    "# Left vs Right LO targets\n",
    "left_lo = fc_data[fc_data['target_hemisphere'] == 'left']['mean_activation']\n",
    "right_lo = fc_data[fc_data['target_hemisphere'] == 'right']['mean_activation']\n",
    "w_stat_target, p_val_target = stats.wilcoxon(left_lo, right_lo)\n",
    "# Independent effect size (Cohen's d for unpaired data)\n",
    "d_target = (np.mean(left_lo) - np.mean(right_lo)) / (\n",
    "    np.sqrt((np.var(left_lo, ddof=1) + np.var(right_lo, ddof=1)) / 2) + 1e-10\n",
    ")\n",
    "\n",
    "# Perform FDR correction for multiple comparisons\n",
    "p_values = [p_val_ipsi, p_val_seed, p_val_target]\n",
    "_, p_values_corrected = fdrcorrection(p_values)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nHemispheric Connectivity Comparisons:\")\n",
    "\n",
    "print(f\"Ipsilateral vs Contralateral:\")\n",
    "print(f\"W = {w_stat_ipsi}, p = {p_val_ipsi:.3f}, d = {d_ipsi}\")\n",
    "\n",
    "print(f\"\\nLeft vs Right pIPS seeds:\")\n",
    "print(f\"W = {w_stat_seed}, p = {p_val_seed:.3f} (FDR-corrected p = {p_values_corrected[1]:.3f}), d = {d_seed:.3f}\")\n",
    "print(f\"Mean Left = {np.mean(left_pips):.3f} ± {stats.sem(left_pips):.3f}\")\n",
    "print(f\"Mean Right = {np.mean(right_pips):.3f} ± {stats.sem(right_pips):.3f}\")\n",
    "\n",
    "print(f\"\\nLeft vs Right LO targets:\")\n",
    "print(f\"W = {w_stat_target}, p = {p_val_target:.3f} (FDR-corrected p = {p_values_corrected[2]:.3f}), d = {d_target:.3f}\")\n",
    "print(f\"Mean Left = {np.mean(left_lo):.3f} ± {stats.sem(left_lo):.3f}\")\n",
    "print(f\"Mean Right = {np.mean(right_lo):.3f} ± {stats.sem(right_lo):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fc data exp 1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def create_fc_plot(fc_data):\n",
    "    # Set style params\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # Create figure with extra space at bottom for legend\n",
    "    fig, ax = plt.subplots(figsize=(6, 7))\n",
    "    \n",
    "    # Define colors and markers\n",
    "    colors = {'left': '#31688E',  # blue\n",
    "             'right': '#7E4E90'}  # purple\n",
    "    markers = {'left': 'o',  # circle\n",
    "              'right': 's'}  # square\n",
    "    \n",
    "    # Calculate means and SEs for each connection\n",
    "    connections = []\n",
    "    means = []\n",
    "    ses = []\n",
    "    plot_colors = []\n",
    "    plot_markers = []\n",
    "    \n",
    "    for seed_hemi in ['left', 'right']:\n",
    "        for target_hemi in ['left', 'right']:\n",
    "            curr_data = fc_data[\n",
    "                (fc_data['seed_hemisphere'] == seed_hemi) &\n",
    "                (fc_data['target_hemisphere'] == target_hemi)\n",
    "            ]['mean_activation']\n",
    "            connections.append(f\"{seed_hemi}\\npIPS\")\n",
    "            means.append(np.mean(curr_data))\n",
    "            ses.append(np.std(curr_data) / np.sqrt(len(curr_data)))\n",
    "            plot_colors.append(colors[seed_hemi])\n",
    "            plot_markers.append(markers[target_hemi])\n",
    "    \n",
    "    # Plot\n",
    "    x = np.arange(len(connections))\n",
    "    \n",
    "    # Error bars and points\n",
    "    for i, (mean, se, color, marker) in enumerate(zip(means, ses, plot_colors, plot_markers)):\n",
    "        plt.errorbar(i, mean, yerr=se, fmt='none', color=color,\n",
    "                    capsize=5, capthick=1, elinewidth=2)\n",
    "        plt.scatter(i, mean, color=color, marker=marker, s=100,\n",
    "                   edgecolor='white', linewidth=1, zorder=3)\n",
    "    \n",
    "    # Create legend elements\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=colors['left'],\n",
    "               label='Left Seed', markersize=10, markeredgecolor='white'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=colors['right'],\n",
    "               label='Right Seed', markersize=10, markeredgecolor='white'),\n",
    "        Line2D([0], [0], marker='o', color='black',\n",
    "               label='Left Target', markersize=10, markerfacecolor='none'),\n",
    "        Line2D([0], [0], marker='s', color='black',\n",
    "               label='Right Target', markersize=10, markerfacecolor='none')\n",
    "    ]\n",
    "    \n",
    "    # Add legend below the plot\n",
    "    ax.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "             ncol=2, frameon=False)\n",
    "    \n",
    "    # Styling\n",
    "    plt.xticks(x, connections, rotation=30, ha='right')\n",
    "    plt.ylabel('Functional Connectivity\\n(Fisher Z)', fontsize=14)\n",
    "    plt.xlabel('Connection', fontsize=14)\n",
    "    \n",
    "    # Set y-axis minimum to 0 and fewer ticks\n",
    "    ax.set_ylim(bottom=0, top=0.2)\n",
    "    ax.set_yticks(np.arange(0, 0.21, 0.05))  # Set ticks at 0, 0.05, 0.10, 0.15, 0.20\n",
    "    \n",
    "    # Theme\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Run plot\n",
    "plot = create_fc_plot(fc_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC Figure\n",
    "\n",
    "# Functional Connectivity Group Averages - Inflated Surface Maps\n",
    "### NOTE THAT LEFT SHOWS LEFT SEED TO LEFT HEMISPHERE RIGHT SHOWS RIGHT SEED TO RIGHT HEMISPHERE\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from nilearn import image, plotting, datasets, surface\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def plot_inflated_brains(out_dir, rois, hemispheres):\n",
    "    # Get fsaverage surface data\n",
    "    fsaverage = datasets.fetch_surf_fsaverage()\n",
    "    \n",
    "    # First pass to determine global max across all ROIs\n",
    "    global_vmax = 0\n",
    "    for roi in rois:\n",
    "        for analysis_type in ['fc']:  \n",
    "            for hemi in hemispheres:\n",
    "                img_file = f'{out_dir}/{roi}_{hemi}_{analysis_type}_avg.nii.gz'\n",
    "                if os.path.exists(img_file):\n",
    "                    img = nib.load(img_file)\n",
    "                    data = img.get_fdata()\n",
    "                    global_vmax = max(global_vmax, np.abs(data).max())\n",
    "\n",
    "    # Create a single figure for all views\n",
    "    fig = plt.figure(figsize=(5.5, 5))\n",
    "    \n",
    "    # Create 2x2 grid of 3D axes\n",
    "    ax1 = fig.add_subplot(221, projection='3d')  # Top left - pIPS left lateral\n",
    "    ax2 = fig.add_subplot(222, projection='3d')  # Top right - pIPS right lateral\n",
    "    ax3 = fig.add_subplot(223, projection='3d')  # Bottom left - LO left lateral\n",
    "    ax4 = fig.add_subplot(224, projection='3d')  # Bottom right - LO right lateral\n",
    "    \n",
    "    # Add row titles\n",
    "    fig.text(0.5, 0.92, 'pIPS FC', va='center', ha='center', fontsize=12)\n",
    "    fig.text(0.5, 0.42, 'LO FC', va='center', ha='center', fontsize=12)\n",
    "\n",
    "    '''\n",
    "    # Set titles\n",
    "    ax1.set_title('pIPS left', pad=0)  # Reduced padding to match original\n",
    "    ax2.set_title('pIPS right', pad=0)\n",
    "    ax3.set_title('LO left', pad=0)\n",
    "    ax4.set_title('LO right', pad=0)\n",
    "    '''\n",
    "    \n",
    "    # Process each ROI and hemisphere\n",
    "    for roi_idx, roi in enumerate(rois):\n",
    "        for hemi_idx, hemi in enumerate(hemispheres):\n",
    "            img_file = f'{out_dir}/{roi}_{hemi}_fc_avg.nii.gz'\n",
    "            if os.path.exists(img_file):\n",
    "                img = nib.load(img_file)\n",
    "                surf_data = surface.vol_to_surf(img, fsaverage.pial_left if hemi == 'left' else fsaverage.pial_right)\n",
    "                \n",
    "                # Determine which axis to use\n",
    "                ax = [ax1, ax2, ax3, ax4][roi_idx * 2 + hemi_idx]\n",
    "                \n",
    "                # Plot lateral view\n",
    "                plotting.plot_surf_stat_map(\n",
    "                    surf_mesh=fsaverage.infl_left if hemi == 'left' else fsaverage.infl_right,\n",
    "                    stat_map=surf_data,\n",
    "                    hemi=hemi,\n",
    "                    view='lateral',\n",
    "                    bg_map=fsaverage.sulc_left if hemi == 'left' else fsaverage.sulc_right,\n",
    "                    colorbar=False, #title=f'{roi} {hemi} {analysis_type.upper()}',\n",
    "                    cmap='RdYlBu_r',\n",
    "                    axes=ax,\n",
    "                    threshold=0.12,\n",
    "                    vmax=global_vmax\n",
    "                )\n",
    "    \n",
    "    # Add colorbar at the bottom center\n",
    "    norm = Normalize(vmin=-global_vmax, vmax=global_vmax)\n",
    "    sm = ScalarMappable(cmap='RdYlBu_r', norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    # Create a new axes for the colorbar at the bottom center\n",
    "    cbar_ax = fig.add_axes([0.35, 0.05, 0.3, 0.02])  # [left, bottom, width, height]\n",
    "    plt.colorbar(sm, cax=cbar_ax, orientation='horizontal', label='Correlation')\n",
    "    cbar_ax.tick_params(labelsize=8)  # Smaller font size\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    study = 'ptoc'\n",
    "    study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "    results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "    \n",
    "    group_out_dir = f'{results_dir}/group_averages'\n",
    "    os.makedirs(group_out_dir, exist_ok=True)\n",
    "    \n",
    "    rois = ['pIPS', 'LO']\n",
    "    hemispheres = ['left', 'right']\n",
    "    \n",
    "    plot_inflated_brains(group_out_dir, rois, hemispheres)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC Analysis (Experiment 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined PPI (Experiment 1)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Directories\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "\n",
    "def calculate_effect_size(data1, data2=None):\n",
    "    \"\"\"Calculate effect size for one-sample or two-sample data\"\"\"\n",
    "    if data2 is None:  # one-sample\n",
    "        return np.mean(data1) / (np.std(data1, ddof=1) + 1e-10)\n",
    "    else:  # two-sample\n",
    "        diff = np.mean(data1) - np.mean(data2)\n",
    "        pooled_std = np.sqrt((np.var(data1, ddof=1) + np.var(data2, ddof=1)) / 2)\n",
    "        return diff / (pooled_std + 1e-10)\n",
    "\n",
    "def analyze_ppi_data_nonparametric(data_df):\n",
    "    \"\"\"Analyze PPI data using non-parametric tests\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Test each condition against 0 using Wilcoxon signed-rank test\n",
    "    conditions = []\n",
    "    for seed_hemi in ['left', 'right']:\n",
    "        for target_hemi in ['left', 'right']:\n",
    "            subset = data_df[\n",
    "                (data_df['seed_hemisphere'] == seed_hemi) &\n",
    "                (data_df['target_hemisphere'] == target_hemi)\n",
    "            ]['mean_activation']\n",
    "            \n",
    "            w_stat, p_val = stats.wilcoxon(subset)\n",
    "            d = calculate_effect_size(subset)\n",
    "            \n",
    "            conditions.append({\n",
    "                'connection': f\"{seed_hemi} pIPS - {target_hemi} LO\",\n",
    "                'W': w_stat,\n",
    "                'p': p_val,\n",
    "                'd': d,\n",
    "                'mean': np.mean(subset),\n",
    "                'sem': stats.sem(subset)\n",
    "            })\n",
    "    \n",
    "    # Apply FDR correction to zero-tests\n",
    "    conditions_df = pd.DataFrame(conditions)\n",
    "    _, conditions_df['p_fdr'] = fdrcorrection(conditions_df['p'])\n",
    "    results['conditions'] = conditions_df\n",
    "    \n",
    "    # 2. Friedman test for overall differences\n",
    "    # Reshape data for Friedman test\n",
    "    wide_data = pd.pivot_table(\n",
    "        data_df,\n",
    "        values='mean_activation',\n",
    "        index='subject',  # Make sure your data has a subject column\n",
    "        columns=['seed_hemisphere', 'target_hemisphere']\n",
    "    )\n",
    "    \n",
    "    chi2, friedman_p = stats.friedmanchisquare(*[wide_data[col] for col in wide_data.columns])\n",
    "    results['friedman'] = {\n",
    "        'chi2': chi2,\n",
    "        'p': friedman_p,\n",
    "        'df': len(wide_data.columns) - 1\n",
    "    }\n",
    "    \n",
    "    # 3. Post-hoc Wilcoxon signed-rank tests for hemispheric differences\n",
    "    post_hoc_results = []\n",
    "    \n",
    "    # Seed hemisphere comparison (collapsing across target)\n",
    "    left_pips = data_df[data_df['seed_hemisphere'] == 'left']['mean_activation']\n",
    "    right_pips = data_df[data_df['seed_hemisphere'] == 'right']['mean_activation']\n",
    "    w_stat_seed, p_val_seed = stats.wilcoxon(left_pips, right_pips)\n",
    "    d_seed = calculate_effect_size(left_pips, right_pips)\n",
    "    \n",
    "    post_hoc_results.append({\n",
    "        'comparison': 'Left pIPS vs Right pIPS',\n",
    "        'W': w_stat_seed,\n",
    "        'p_uncorrected': p_val_seed,\n",
    "        'd': d_seed,\n",
    "        'mean_diff': np.mean(left_pips) - np.mean(right_pips),\n",
    "        'left_mean': np.mean(left_pips),\n",
    "        'left_sem': stats.sem(left_pips),\n",
    "        'right_mean': np.mean(right_pips),\n",
    "        'right_sem': stats.sem(right_pips)\n",
    "    })\n",
    "    \n",
    "    # Target hemisphere comparison (collapsing across seed)\n",
    "    left_lo = data_df[data_df['target_hemisphere'] == 'left']['mean_activation']\n",
    "    right_lo = data_df[data_df['target_hemisphere'] == 'right']['mean_activation']\n",
    "    w_stat_target, p_val_target = stats.wilcoxon(left_lo, right_lo)\n",
    "    d_target = calculate_effect_size(left_lo, right_lo)\n",
    "    \n",
    "    post_hoc_results.append({\n",
    "        'comparison': 'Left LO vs Right LO',\n",
    "        'W': w_stat_target,\n",
    "        'p_uncorrected': p_val_target,\n",
    "        'd': d_target,\n",
    "        'mean_diff': np.mean(left_lo) - np.mean(right_lo),\n",
    "        'left_mean': np.mean(left_lo),\n",
    "        'left_sem': stats.sem(left_lo),\n",
    "        'right_mean': np.mean(right_lo),\n",
    "        'right_sem': stats.sem(right_lo)\n",
    "    })\n",
    "    \n",
    "    # Apply FDR correction to post-hoc tests\n",
    "    post_hoc_df = pd.DataFrame(post_hoc_results)\n",
    "    _, post_hoc_df['p_fdr'] = fdrcorrection(post_hoc_df['p_uncorrected'])\n",
    "    results['post_hoc'] = post_hoc_df\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Load and prepare data\n",
    "data_df = pd.read_csv(f\"{results_dir}/fc_ppi/matchvlad_seed_target_activations.csv\")\n",
    "ppi_data = data_df[data_df['analysis'] == 'ppi']\n",
    "\n",
    "# Run analysis\n",
    "results = analyze_ppi_data_nonparametric(ppi_data)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFriedman Test Results:\")\n",
    "print(f\"χ²({results['friedman']['df']}) = {results['friedman']['chi2']:.3f}, p = {results['friedman']['p']:.3f}\")\n",
    "\n",
    "print(\"\\nCondition Statistics (testing against 0):\")\n",
    "print(results['conditions'].round(3))\n",
    "\n",
    "print(\"\\nPost-hoc Tests:\")\n",
    "print(results['post_hoc'].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PPI data exp 1\n",
    "import numpy as np\n",
    "\n",
    "def create_ppi_plot(ppi_data):\n",
    "    # Set style params\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # Create figure with extra space for legend\n",
    "    fig, ax = plt.subplots(figsize=(6, 7))\n",
    "    \n",
    "    # Define colors and markers\n",
    "    colors = {'left': '#31688E',  # blue\n",
    "             'right': '#7E4E90'}  # purple\n",
    "    markers = {'left': 'o',  # circle\n",
    "              'right': 's'}  # square\n",
    "    \n",
    "    # Calculate means and SEs for each connection\n",
    "    connections = []\n",
    "    means = []\n",
    "    ses = []\n",
    "    plot_colors = []\n",
    "    plot_markers = []\n",
    "    \n",
    "    for seed_hemi in ['left', 'right']:\n",
    "        for target_hemi in ['left', 'right']:\n",
    "            curr_data = ppi_data[\n",
    "                (ppi_data['seed_hemisphere'] == seed_hemi) &\n",
    "                (ppi_data['target_hemisphere'] == target_hemi) &\n",
    "                (ppi_data['analysis'] == 'ppi')\n",
    "            ]['mean_activation']\n",
    "            connections.append(f\"{seed_hemi}\\npIPS\")\n",
    "            means.append(np.mean(curr_data))\n",
    "            ses.append(np.std(curr_data) / np.sqrt(len(curr_data)))\n",
    "            plot_colors.append(colors[seed_hemi])\n",
    "            plot_markers.append(markers[target_hemi])\n",
    "    \n",
    "    # Plot\n",
    "    x = np.arange(len(connections))\n",
    "    \n",
    "    # Error bars and points\n",
    "    for i, (mean, se, color, marker) in enumerate(zip(means, ses, plot_colors, plot_markers)):\n",
    "        plt.errorbar(i, mean, yerr=se, fmt='none', color=color,\n",
    "                    capsize=5, capthick=1, elinewidth=2)\n",
    "        plt.scatter(i, mean, color=color, marker=marker, s=100,\n",
    "                   edgecolor='white', linewidth=1, zorder=3)\n",
    "    \n",
    "    # Create legend elements\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=colors['left'],\n",
    "               label='Left Seed', markersize=10, markeredgecolor='white'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=colors['right'],\n",
    "               label='Right Seed', markersize=10, markeredgecolor='white'),\n",
    "        Line2D([0], [0], marker='o', color='black',\n",
    "               label='Left Target', markersize=10, markerfacecolor='none'),\n",
    "        Line2D([0], [0], marker='s', color='black',\n",
    "               label='Right Target', markersize=10, markerfacecolor='none')\n",
    "    ]\n",
    "    \n",
    "    # Add legend below the plot\n",
    "    ax.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "             ncol=2, frameon=False)\n",
    "    \n",
    "    # Styling\n",
    "    plt.xticks(x, connections, rotation=30, ha='right')\n",
    "    plt.ylabel('PPI Connectivity\\n(Task Modulation)', fontsize=14)\n",
    "    plt.xlabel('Connection', fontsize=14)\n",
    "    \n",
    "    # Set y-axis scale with tighter limits\n",
    "    # Add just a bit of padding above and below the data\n",
    "    data_range = max(means) - min(means)\n",
    "    padding = data_range * 0.1  # 10% padding\n",
    "    ymin = max(-0.05, min(means) - padding)  # Don't go below -0.05 if data doesn't warrant it\n",
    "    ymax = max(means) + padding\n",
    "    \n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_yticks(np.arange(np.floor(ymin*20)/20, ymax+0.02, 0.01))  # Ticks every 0.05\n",
    "    \n",
    "    # Theme\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Run plot\n",
    "plot = create_ppi_plot(data_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined PPI (Experiment 2)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Directories\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "output_dir = f'{curr_dir}/tools'\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "\n",
    "def calculate_effect_size(data1, data2=None):\n",
    "    \"\"\"Calculate effect size for one-sample or two-sample data\"\"\"\n",
    "    if data2 is None:  # one-sample\n",
    "        return np.mean(data1) / (np.std(data1, ddof=1) + 1e-10)\n",
    "    else:  # two-sample\n",
    "        diff = np.mean(data1) - np.mean(data2)\n",
    "        pooled_std = np.sqrt((np.var(data1, ddof=1) + np.var(data2, ddof=1)) / 2)\n",
    "        return diff / (pooled_std + 1e-10)\n",
    "\n",
    "def analyze_ppi_data_nonparametric(data_df):\n",
    "    \"\"\"Analyze PPI data using non-parametric tests including condition as a factor\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Overall Friedman test including condition\n",
    "    wide_data = pd.pivot_table(\n",
    "        data_df,\n",
    "        values='value',\n",
    "        index='subject',\n",
    "        columns=['condition', 'seed_roi', 'seed_hemi', 'target_hemi'],\n",
    "        aggfunc='first'\n",
    "    ).dropna()\n",
    "    \n",
    "    # Perform Friedman test on all columns (includes condition)\n",
    "    chi2, friedman_p = stats.friedmanchisquare(*[wide_data[col].values for col in wide_data.columns])\n",
    "    results['friedman'] = {\n",
    "        'chi2': chi2,\n",
    "        'p': friedman_p,\n",
    "        'df': len(wide_data.columns) - 1,\n",
    "        'n_subjects': len(wide_data),\n",
    "        'n_conditions': len(wide_data.columns),\n",
    "        'conditions': list(wide_data.columns)\n",
    "    }\n",
    "    \n",
    "    # 2. Test each connection against 0 (for both conditions)\n",
    "    zero_test_results = []\n",
    "    for condition in ['Tools', 'Nontools']:\n",
    "        for seed_roi in ['pIPS', 'aIPS']:\n",
    "            for seed_hemi in ['left', 'right']:\n",
    "                for target_hemi in ['left', 'right']:\n",
    "                    subset = data_df[\n",
    "                        (data_df['condition'] == condition) &\n",
    "                        (data_df['seed_roi'] == seed_roi) &\n",
    "                        (data_df['seed_hemi'] == seed_hemi) &\n",
    "                        (data_df['target_hemi'] == target_hemi)\n",
    "                    ]['value']\n",
    "                    \n",
    "                    w_stat, p_val = stats.wilcoxon(subset)\n",
    "                    d = calculate_effect_size(subset)\n",
    "                    \n",
    "                    zero_test_results.append({\n",
    "                        'condition': condition,\n",
    "                        'connection': f\"{seed_hemi} {seed_roi} - {target_hemi} LO\",\n",
    "                        'W': w_stat,\n",
    "                        'p': p_val,\n",
    "                        'd': d,\n",
    "                        'mean': np.mean(subset),\n",
    "                        'sem': stats.sem(subset)\n",
    "                    })\n",
    "    \n",
    "    # Apply FDR correction to all zero-tests together\n",
    "    zero_test_df = pd.DataFrame(zero_test_results)\n",
    "    _, zero_test_df['p_fdr'] = fdrcorrection(zero_test_df['p'])\n",
    "    results['zero_tests'] = zero_test_df\n",
    "    \n",
    "    # 3. Compare Tools vs Nontools for each connection\n",
    "    condition_comparisons = []\n",
    "    for seed_roi in ['pIPS', 'aIPS']:\n",
    "        for seed_hemi in ['left', 'right']:\n",
    "            for target_hemi in ['left', 'right']:\n",
    "                tools_data = data_df[\n",
    "                    (data_df['condition'] == 'Tools') &\n",
    "                    (data_df['seed_roi'] == seed_roi) &\n",
    "                    (data_df['seed_hemi'] == seed_hemi) &\n",
    "                    (data_df['target_hemi'] == target_hemi)\n",
    "                ]['value']\n",
    "                \n",
    "                nontools_data = data_df[\n",
    "                    (data_df['condition'] == 'Nontools') &\n",
    "                    (data_df['seed_roi'] == seed_roi) &\n",
    "                    (data_df['seed_hemi'] == seed_hemi) &\n",
    "                    (data_df['target_hemi'] == target_hemi)\n",
    "                ]['value']\n",
    "                \n",
    "                w_stat, p_val = stats.wilcoxon(tools_data, nontools_data)\n",
    "                d = calculate_effect_size(tools_data, nontools_data)\n",
    "                \n",
    "                condition_comparisons.append({\n",
    "                    'connection': f\"{seed_hemi} {seed_roi} - {target_hemi} LO\",\n",
    "                    'W': w_stat,\n",
    "                    'p': p_val,\n",
    "                    'd': d,\n",
    "                    'mean_diff': np.mean(tools_data) - np.mean(nontools_data),\n",
    "                    'tools_mean': np.mean(tools_data),\n",
    "                    'tools_sem': stats.sem(tools_data),\n",
    "                    'nontools_mean': np.mean(nontools_data),\n",
    "                    'nontools_sem': stats.sem(nontools_data)\n",
    "                })\n",
    "    \n",
    "    # Apply FDR correction to condition comparisons\n",
    "    condition_comp_df = pd.DataFrame(condition_comparisons)\n",
    "    _, condition_comp_df['p_fdr'] = fdrcorrection(condition_comp_df['p'])\n",
    "    results['condition_comparisons'] = condition_comp_df\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Load data\n",
    "tools_df = pd.read_csv(f\"{output_dir}/roi_ppi_sphere_summary_tools.csv\")\n",
    "nontools_df = pd.read_csv(f\"{output_dir}/roi_ppi_sphere_summary_nontools.csv\")\n",
    "\n",
    "# Add condition labels\n",
    "tools_df['condition'] = 'Tools'\n",
    "nontools_df['condition'] = 'Nontools'\n",
    "exp2_df = pd.concat([tools_df, nontools_df])\n",
    "\n",
    "# Run analysis\n",
    "results = analyze_ppi_data_nonparametric(exp2_df)\n",
    "\n",
    "# Save and print results\n",
    "with open(f\"{results_dir}/exp2_ppi_stats_summary.txt\", 'w') as f:\n",
    "    # Overall test\n",
    "    f.write(f\"Overall Friedman Test Results:\\n\")\n",
    "    f.write(f\"χ²({results['friedman']['df']}) = {results['friedman']['chi2']:.3f}, p = {results['friedman']['p']:.3f}\\n\")\n",
    "    f.write(f\"Number of subjects: {results['friedman']['n_subjects']}\\n\")\n",
    "    f.write(f\"Number of conditions: {results['friedman']['n_conditions']}\\n\\n\")\n",
    "    \n",
    "    # Zero tests by condition\n",
    "    f.write(\"Tests against zero:\\n\")\n",
    "    f.write(results['zero_tests'].round(3).to_string())\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    # Condition comparisons\n",
    "    f.write(\"Tools vs Nontools Comparisons:\\n\")\n",
    "    f.write(results['condition_comparisons'].round(3).to_string())\n",
    "\n",
    "# Print results to console\n",
    "print(f\"\\nOverall Friedman Test Results:\")\n",
    "print(f\"χ²({results['friedman']['df']}) = {results['friedman']['chi2']:.3f}, p = {results['friedman']['p']:.3f}\")\n",
    "print(f\"Number of subjects: {results['friedman']['n_subjects']}\")\n",
    "print(f\"Number of conditions: {results['friedman']['n_conditions']}\\n\")\n",
    "\n",
    "print(\"\\nTests against zero:\")\n",
    "print(results['zero_tests'].round(3))\n",
    "\n",
    "print(\"\\nTools vs Nontools Comparisons:\")\n",
    "print(results['condition_comparisons'].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp 1 GCA\n",
    "# nonparametric gca univariate analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# File paths\n",
    "base_dir = '/user_data/csimmon2/git_repos/ptoc'\n",
    "results_dir = f\"{base_dir}/results\"\n",
    "fig_dir = f\"{results_dir}/gca\"\n",
    "\n",
    "# Read the existing summary table\n",
    "summary_table_combined = pd.read_csv(f\"{fig_dir}/gca_summary_table_combined.csv\")\n",
    "\n",
    "# Apply FDR correction to the Wilcoxon p-values\n",
    "p_values = summary_table_combined['p_value'].values\n",
    "rejected, p_corrected = fdrcorrection(p_values, alpha=0.05, method='indep')\n",
    "\n",
    "# Update table with FDR results\n",
    "summary_table_combined['p_value_fdr'] = p_corrected\n",
    "summary_table_combined['significant_fdr'] = rejected\n",
    "\n",
    "# Save updated results\n",
    "summary_table_combined.to_csv(f\"{fig_dir}/gca_summary_table_combined_fdr.csv\", index=False)\n",
    "\n",
    "# Simple Cohen's d calculation\n",
    "def calculate_cohens_d(mean_diff, std_diff):\n",
    "    \"\"\"Calculate Cohen's d as simple standardized mean difference\"\"\"\n",
    "    return abs(mean_diff / std_diff)\n",
    "\n",
    "print(\"\\nCohen's d calculations:\")\n",
    "for _, row in summary_table_combined.iterrows():\n",
    "    d = calculate_cohens_d(row['Mean f_diff'], row['Std f_diff'])\n",
    "    print(f\"{row['origin']}-{row['target']} ({row['condition']}): d = {d:.2f}\")\n",
    "\n",
    "# Update and display results\n",
    "print(\"\\nAfter FDR correction:\")\n",
    "print(summary_table_combined)\n",
    "\n",
    "# Extract comparison p-values from the summary table\n",
    "object_lpips_llo = summary_table_combined[(summary_table_combined['condition'] == 'Object') & \n",
    "                                        (summary_table_combined['origin'] == 'lpIPS') & \n",
    "                                        (summary_table_combined['target'] == 'lLO')]['p_value_fdr'].values[0]\n",
    "\n",
    "object_lpips_rlo = summary_table_combined[(summary_table_combined['condition'] == 'Object') & \n",
    "                                        (summary_table_combined['origin'] == 'lpIPS') & \n",
    "                                        (summary_table_combined['target'] == 'rLO')]['p_value_fdr'].values[0]\n",
    "\n",
    "scramble_lpips_llo = summary_table_combined[(summary_table_combined['condition'] == 'Scramble') & \n",
    "                                          (summary_table_combined['origin'] == 'lpIPS') & \n",
    "                                          (summary_table_combined['target'] == 'lLO')]['p_value_fdr'].values[0]\n",
    "\n",
    "scramble_lpips_rlo = summary_table_combined[(summary_table_combined['condition'] == 'Scramble') & \n",
    "                                          (summary_table_combined['origin'] == 'lpIPS') & \n",
    "                                          (summary_table_combined['target'] == 'rLO')]['p_value_fdr'].values[0]\n",
    "\n",
    "# Save FDR-corrected Wilcoxon test results\n",
    "with open(f\"{fig_dir}/gca_roi_pair_combined_comparison_results_fdr.txt\", 'w') as f:\n",
    "    f.write(\"GCA ROI Pair Combined Comparison Results (Wilcoxon tests):\\n\\n\")\n",
    "    f.write(\"Object Condition:\\n\")\n",
    "    f.write(\"lpIPS-lLO vs rpIPS-lLO:\\n\")\n",
    "    f.write(f\"p_fdr = {object_lpips_llo:.4f}\\n\")\n",
    "    f.write(\"lpIPS-rLO vs rpIPS-rLO:\\n\")\n",
    "    f.write(f\"p_fdr = {object_lpips_rlo:.4f}\\n\")\n",
    "    f.write(\"\\nScramble Condition:\\n\")\n",
    "    f.write(\"lpIPS-lLO vs rpIPS-lLO:\\n\")\n",
    "    f.write(f\"p_fdr = {scramble_lpips_llo:.4f}\\n\")\n",
    "    f.write(\"lpIPS-rLO vs rpIPS-rLO:\\n\")\n",
    "    f.write(f\"p_fdr = {scramble_lpips_rlo:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiak_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
