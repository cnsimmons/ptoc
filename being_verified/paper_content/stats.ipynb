{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def partial_eta_squared(aov):\n",
    "    \"\"\"Calculate partial eta-squared for ANOVA results.\"\"\"\n",
    "    aov = aov.copy()\n",
    "    aov['pes'] = (aov['Num DF'] * aov['F Value']) / (aov['Num DF'] * aov['F Value'] + aov['Den DF'])\n",
    "    return aov\n",
    "\n",
    "def analyze_roi_data(data, experiment='exp1'):\n",
    "    \"\"\"Analyze ROI data with multiple comparison correction.\"\"\"\n",
    "    results = {}\n",
    "    all_tests = []\n",
    "    \n",
    "    if experiment == 'exp1':\n",
    "        conditions = ['object', 'scramble']\n",
    "        rois = ['LO', 'pIPS']\n",
    "    else:\n",
    "        conditions = ['tool', 'nontool']\n",
    "        rois = ['PFS', 'aIPS', 'LO', 'pIPS']\n",
    "        \n",
    "    for roi in rois:\n",
    "        for hemi in ['left', 'right']:\n",
    "            roi_data = data[(data['roi'] == roi) & (data['hemi'] == hemi)]\n",
    "            cond1_data = roi_data[roi_data['cond'] == conditions[0]]['mean_act'].values\n",
    "            cond2_data = roi_data[roi_data['cond'] == conditions[1]]['mean_act'].values\n",
    "            \n",
    "            # Calculate statistics\n",
    "            t_stat, p_val = ttest_rel(cond1_data, cond2_data)\n",
    "            mean_diff = np.mean(cond1_data - cond2_data)\n",
    "            se_diff = np.std(cond1_data - cond2_data) / np.sqrt(len(cond1_data))\n",
    "            d = mean_diff / np.sqrt((np.std(cond1_data)**2 + np.std(cond2_data)**2) / 2)\n",
    "            \n",
    "            # Store results\n",
    "            all_tests.append({\n",
    "                'roi': f'{hemi}_{roi}',\n",
    "                'p_value': p_val,\n",
    "                't_stat': t_stat,\n",
    "                'mean_diff': mean_diff,\n",
    "                'se': se_diff,\n",
    "                'cohens_d': d,\n",
    "                'n': len(cond1_data),\n",
    "                f'mean_{conditions[0]}': np.mean(cond1_data),\n",
    "                f'mean_{conditions[1]}': np.mean(cond2_data)\n",
    "            })\n",
    "    \n",
    "    # Apply Holm-Bonferroni correction\n",
    "    p_values = [test['p_value'] for test in all_tests]\n",
    "    _, p_corrected, _, _ = multipletests(p_values, method='holm')\n",
    "    \n",
    "    # Update results with corrected p-values\n",
    "    for test, p_corr in zip(all_tests, p_corrected):\n",
    "        results[test['roi']] = test\n",
    "        results[test['roi']]['p_corrected'] = p_corr\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_rmanova(data, factors):\n",
    "    \"\"\"Run repeated measures ANOVA with effect sizes.\"\"\"\n",
    "    aov = AnovaRM(data=data, \n",
    "                  depvar='mean_act',\n",
    "                  subject='sub',\n",
    "                  within=factors).fit()\n",
    "    \n",
    "    aov_table = partial_eta_squared(aov.anova_table)\n",
    "    return aov_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# Experiment 1\n",
    "exp1_results = pd.read_csv(\"/user_data/csimmon2/git_repos/ptoc/results/selectivity/selectivity_summary.csv\")\n",
    "\n",
    "filtered_exp1 = exp1_results[(exp1_results['group'] == 'control') & \n",
    "                            (exp1_results['roi'].isin(['LO', 'pIPS'])) &\n",
    "                            (exp1_results['sub'] != 'sub-084')]\n",
    "\n",
    "# Experiment 2\n",
    "exp2_results = pd.read_csv(\"/user_data/csimmon2/git_repos/ptoc/results/tools/selectivity/selectivity_summarytoolloc.csv\")\n",
    "filtered_exp2 = exp2_results[exp2_results['sub'].str.contains('spaceloc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 ANOVA Results:\n",
      "                  F Value  Num DF  Den DF        Pr > F       pes\n",
      "roi             39.763898     1.0    17.0  7.897722e-06  0.700514\n",
      "hemi            10.301246     1.0    17.0  5.140748e-03  0.377318\n",
      "cond            55.387486     1.0    17.0  9.623988e-07  0.765153\n",
      "roi:hemi         2.803147     1.0    17.0  1.123766e-01  0.141551\n",
      "roi:cond       108.745714     1.0    17.0  8.346158e-09  0.864807\n",
      "hemi:cond        2.746805     1.0    17.0  1.157867e-01  0.139101\n",
      "roi:hemi:cond    0.056390     1.0    17.0  8.151334e-01  0.003306\n",
      "\n",
      "Experiment 1 ROI Results:\n",
      "\n",
      "left_LO:\n",
      "t(17) = 8.141, p = 0.0000, p_corr = 0.0000\n",
      "Cohen's d = 2.474\n",
      "Mean difference = 2.526 ± 0.301\n",
      "\n",
      "right_LO:\n",
      "t(17) = 8.303, p = 0.0000, p_corr = 0.0000\n",
      "Cohen's d = 2.689\n",
      "Mean difference = 2.314 ± 0.271\n",
      "\n",
      "left_pIPS:\n",
      "t(17) = 3.815, p = 0.0014, p_corr = 0.0028\n",
      "Cohen's d = 1.233\n",
      "Mean difference = 0.851 ± 0.217\n",
      "\n",
      "right_pIPS:\n",
      "t(17) = 2.760, p = 0.0134, p_corr = 0.0134\n",
      "Cohen's d = 0.947\n",
      "Mean difference = 0.549 ± 0.193\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1 ROI Analysis\n",
    "# Full ANOVA\n",
    "exp1_anova = run_rmanova(filtered_exp1, ['roi', 'hemi', 'cond'])\n",
    "print(\"Experiment 1 ANOVA Results:\")\n",
    "print(exp1_anova)\n",
    "\n",
    "# ROI Analysis\n",
    "exp1_roi_results = analyze_roi_data(filtered_exp1, 'exp1')\n",
    "print(\"\\nExperiment 1 ROI Results:\")\n",
    "for roi, stats in exp1_roi_results.items():\n",
    "    print(f\"\\n{roi}:\")\n",
    "    print(f\"t({stats['n']-1}) = {stats['t_stat']:.3f}, p = {stats['p_value']:.4f}, p_corr = {stats['p_corrected']:.4f}\")\n",
    "    print(f\"Cohen's d = {stats['cohens_d']:.3f}\")\n",
    "    print(f\"Mean difference = {stats['mean_diff']:.3f} ± {stats['se']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2 ANOVA Results:\n",
      "                 F Value  Num DF  Den DF        Pr > F       pes\n",
      "roi            69.788835     3.0    51.0  4.595074e-18  0.804122\n",
      "hemi           25.586962     1.0    17.0  9.700100e-05  0.600817\n",
      "cond            1.697378     1.0    17.0  2.100038e-01  0.090782\n",
      "roi:hemi        1.617712     3.0    51.0  1.967325e-01  0.086891\n",
      "roi:cond       23.018004     3.0    51.0  1.468259e-09  0.575191\n",
      "hemi:cond      15.531839     1.0    17.0  1.053597e-03  0.477435\n",
      "roi:hemi:cond   1.616753     3.0    51.0  1.969531e-01  0.086844\n",
      "\n",
      "Experiment 2 ROI Results:\n",
      "\n",
      "left_PFS:\n",
      "t(17) = -2.917, p = 0.0096, p_corr = 0.0436\n",
      "Cohen's d = -0.374\n",
      "Mean difference = -0.230 ± 0.077\n",
      "\n",
      "right_PFS:\n",
      "t(17) = -2.545, p = 0.0209, p_corr = 0.0628\n",
      "Cohen's d = -0.437\n",
      "Mean difference = -0.293 ± 0.112\n",
      "\n",
      "left_aIPS:\n",
      "t(17) = 5.407, p = 0.0000, p_corr = 0.0004\n",
      "Cohen's d = 0.844\n",
      "Mean difference = 0.344 ± 0.062\n",
      "\n",
      "right_aIPS:\n",
      "t(17) = 3.430, p = 0.0032, p_corr = 0.0191\n",
      "Cohen's d = 0.729\n",
      "Mean difference = 0.225 ± 0.064\n",
      "\n",
      "left_LO:\n",
      "t(17) = 2.963, p = 0.0087, p_corr = 0.0436\n",
      "Cohen's d = 0.319\n",
      "Mean difference = 0.251 ± 0.082\n",
      "\n",
      "right_LO:\n",
      "t(17) = -0.166, p = 0.8701, p_corr = 0.8701\n",
      "Cohen's d = -0.025\n",
      "Mean difference = -0.019 ± 0.109\n",
      "\n",
      "left_pIPS:\n",
      "t(17) = 3.541, p = 0.0025, p_corr = 0.0176\n",
      "Cohen's d = 0.715\n",
      "Mean difference = 0.291 ± 0.080\n",
      "\n",
      "right_pIPS:\n",
      "t(17) = 1.550, p = 0.1396, p_corr = 0.2793\n",
      "Cohen's d = 0.278\n",
      "Mean difference = 0.119 ± 0.075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n## Pathway Analysis\\n# Separate ANOVAs for dorsal and ventral pathways\\ndorsal_data = filtered_exp2[filtered_exp2[\\'roi\\'].isin([\\'aIPS\\', \\'pIPS\\'])]\\nventral_data = filtered_exp2[filtered_exp2[\\'roi\\'].isin([\\'PFS\\', \\'LO\\'])]\\n\\ndorsal_anova = run_rmanova(dorsal_data, [\\'roi\\', \\'hemi\\', \\'cond\\'])\\nventral_anova = run_rmanova(ventral_data, [\\'roi\\', \\'hemi\\', \\'cond\\'])\\n    \\n# Dorsal pathway ANOVA\\ndorsal_data = filtered_exp2[filtered_exp2[\\'roi\\'].isin([\\'aIPS\\', \\'pIPS\\'])]\\ndorsal_anova = run_rmanova(dorsal_data, [\\'roi\\', \\'hemi\\', \\'cond\\'])\\nprint(\"Dorsal Pathway ANOVA Results:\")\\nprint(dorsal_anova)\\n\\n# Ventral pathway ANOVA\\nventral_data = filtered_exp2[filtered_exp2[\\'roi\\'].isin([\\'PFS\\', \\'LO\\'])]\\nventral_anova = run_rmanova(ventral_data, [\\'roi\\', \\'hemi\\', \\'cond\\'])\\nprint(\"Ventral Pathway ANOVA Results:\")\\nprint(ventral_anova)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 2 ROI Analysis\n",
    "# Full ANOVA\n",
    "exp2_anova = run_rmanova(filtered_exp2, ['roi', 'hemi', 'cond'])\n",
    "print(\"Experiment 2 ANOVA Results:\")\n",
    "print(exp2_anova)\n",
    "\n",
    "# ROI Analysis\n",
    "exp2_roi_results = analyze_roi_data(filtered_exp2, 'exp2')\n",
    "print(\"\\nExperiment 2 ROI Results:\")\n",
    "for roi, stats in exp2_roi_results.items():\n",
    "    print(f\"\\n{roi}:\")\n",
    "    print(f\"t({stats['n']-1}) = {stats['t_stat']:.3f}, p = {stats['p_value']:.4f}, p_corr = {stats['p_corrected']:.4f}\")\n",
    "    print(f\"Cohen's d = {stats['cohens_d']:.3f}\")\n",
    "    print(f\"Mean difference = {stats['mean_diff']:.3f} ± {stats['se']:.3f}\")\n",
    "\n",
    "'''\n",
    "## Pathway Analysis\n",
    "# Separate ANOVAs for dorsal and ventral pathways\n",
    "dorsal_data = filtered_exp2[filtered_exp2['roi'].isin(['aIPS', 'pIPS'])]\n",
    "ventral_data = filtered_exp2[filtered_exp2['roi'].isin(['PFS', 'LO'])]\n",
    "\n",
    "dorsal_anova = run_rmanova(dorsal_data, ['roi', 'hemi', 'cond'])\n",
    "ventral_anova = run_rmanova(ventral_data, ['roi', 'hemi', 'cond'])\n",
    "    \n",
    "# Dorsal pathway ANOVA\n",
    "dorsal_data = filtered_exp2[filtered_exp2['roi'].isin(['aIPS', 'pIPS'])]\n",
    "dorsal_anova = run_rmanova(dorsal_data, ['roi', 'hemi', 'cond'])\n",
    "print(\"Dorsal Pathway ANOVA Results:\")\n",
    "print(dorsal_anova)\n",
    "\n",
    "# Ventral pathway ANOVA\n",
    "ventral_data = filtered_exp2[filtered_exp2['roi'].isin(['PFS', 'LO'])]\n",
    "ventral_anova = run_rmanova(ventral_data, ['roi', 'hemi', 'cond'])\n",
    "print(\"Ventral Pathway ANOVA Results:\")\n",
    "print(ventral_anova)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FC and PPI Connectivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 1 Results:\n",
      "         seed    target     W      p      d   mean    sem  p_fdr\n",
      "0   pIPS_left   LO_left   3.0  0.000  1.340  0.035  0.006  0.000\n",
      "1   pIPS_left  LO_right  12.0  0.000  1.156  0.031  0.006  0.000\n",
      "2  pIPS_right   LO_left  13.0  0.000  1.137  0.028  0.006  0.000\n",
      "3  pIPS_right  LO_right  20.0  0.001  1.004  0.023  0.005  0.001\n",
      "\n",
      "Experiment 2 Results:\n",
      "          seed    target condition      W      p      d   mean    sem  p_fdr\n",
      "0    pIPS_left   LO_left     Tools  154.0  0.004  0.557  0.019  0.006  0.022\n",
      "1    pIPS_left   LO_left  Nontools  253.0  0.214  0.197  0.006  0.005  0.286\n",
      "2    pIPS_left  LO_right     Tools  166.0  0.008  0.526  0.018  0.006  0.025\n",
      "3    pIPS_left  LO_right  Nontools  248.0  0.187  0.218  0.007  0.005  0.286\n",
      "4   pIPS_right   LO_left     Tools  152.0  0.004  0.530  0.017  0.006  0.022\n",
      "5   pIPS_right   LO_left  Nontools  233.0  0.119  0.256  0.010  0.006  0.211\n",
      "6   pIPS_right  LO_right     Tools  212.0  0.058  0.376  0.015  0.007  0.115\n",
      "7   pIPS_right  LO_right  Nontools  292.0  0.529  0.079  0.003  0.006  0.564\n",
      "8    aIPS_left   LO_left     Tools  146.0  0.003  0.483  0.020  0.007  0.022\n",
      "9    aIPS_left   LO_left  Nontools  259.0  0.252  0.208  0.008  0.006  0.310\n",
      "10   aIPS_left  LO_right     Tools  161.0  0.006  0.449  0.022  0.008  0.024\n",
      "11   aIPS_left  LO_right  Nontools  281.0  0.423  0.146  0.005  0.006  0.483\n",
      "12  aIPS_right   LO_left     Tools  207.0  0.048  0.368  0.013  0.006  0.115\n",
      "13  aIPS_right   LO_left  Nontools  251.0  0.203  0.195  0.006  0.005  0.286\n",
      "14  aIPS_right  LO_right     Tools  212.0  0.058  0.346  0.015  0.007  0.115\n",
      "15  aIPS_right  LO_right  Nontools  321.0  0.858 -0.039 -0.001  0.006  0.858\n"
     ]
    }
   ],
   "source": [
    "# PPI Analysis || need to alter exp 1 to 18 subjects, currently 19.\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import statsmodels.api as sm\n",
    "from nilearn import image, plotting, input_data, glm\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nibabel as nib\n",
    "from nilearn.datasets import load_mni152_brain_mask, load_mni152_template\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Directories\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "output_dir = f'{curr_dir}/tools'\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "\n",
    "def calculate_effect_size(data):\n",
    "    \"\"\"Calculate Cohen's d\"\"\"\n",
    "    return np.mean(data) / np.std(data) if len(data) > 0 else np.nan\n",
    "\n",
    "def run_stats_analysis(df, value_col='value'):\n",
    "    \"\"\"Run Wilcoxon test and calculate effect size\"\"\"\n",
    "    w_stat, p_val = stats.wilcoxon(df[value_col])\n",
    "    d = calculate_effect_size(df[value_col])\n",
    "    return pd.Series({\n",
    "        'W': w_stat,\n",
    "        'p': p_val,\n",
    "        'd': d,\n",
    "        'mean': np.mean(df[value_col]),\n",
    "        'sem': stats.sem(df[value_col])\n",
    "    })\n",
    "\n",
    "# Load data\n",
    "exp1_df = pd.read_csv(f\"{results_dir}/fc_ppi/matchvlad_seed_target_activations.csv\")\n",
    "tools_df = pd.read_csv(f\"{output_dir}/roi_ppi_sphere_summary_tools.csv\")\n",
    "nontools_df = pd.read_csv(f\"{output_dir}/roi_ppi_sphere_summary_nontools.csv\")\n",
    "\n",
    "# Add condition labels for Exp2\n",
    "tools_df['condition'] = 'Tools'\n",
    "nontools_df['condition'] = 'Nontools'\n",
    "exp2_df = pd.concat([tools_df, nontools_df])\n",
    "\n",
    "def analyze_experiment(df, seed_rois, target_rois, exp_num):\n",
    "    results = []\n",
    "    hemispheres = ['left', 'right']\n",
    "    \n",
    "    for seed in seed_rois:\n",
    "        for seed_hemi in hemispheres:\n",
    "            for target in target_rois:\n",
    "                for target_hemi in hemispheres:\n",
    "                    if exp_num == 1:\n",
    "                        subset = df[\n",
    "                            (df['seed_roi'] == seed) & \n",
    "                            (df['seed_hemisphere'] == seed_hemi) &\n",
    "                            (df['target_roi'] == target) &\n",
    "                            (df['target_hemisphere'] == target_hemi) &\n",
    "                            (df['analysis'] == 'ppi')\n",
    "                        ]\n",
    "                        if len(subset) > 0:\n",
    "                            stats = run_stats_analysis(subset, value_col='mean_activation')\n",
    "                            results.append({\n",
    "                                'seed': f\"{seed}_{seed_hemi}\",\n",
    "                                'target': f\"{target}_{target_hemi}\",\n",
    "                                **stats\n",
    "                            })\n",
    "                    else:\n",
    "                        for condition in df['condition'].unique():\n",
    "                            subset = df[\n",
    "                                (df['seed_roi'] == seed) & \n",
    "                                (df['seed_hemi'] == seed_hemi) &\n",
    "                                (df['target_roi'] == target) &\n",
    "                                (df['target_hemi'] == target_hemi) &\n",
    "                                (df['condition'] == condition)\n",
    "                            ]\n",
    "                            if len(subset) > 0:\n",
    "                                stats = run_stats_analysis(subset)\n",
    "                                results.append({\n",
    "                                    'seed': f\"{seed}_{seed_hemi}\",\n",
    "                                    'target': f\"{target}_{target_hemi}\",\n",
    "                                    'condition': condition,\n",
    "                                    **stats\n",
    "                                })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run analyses\n",
    "exp1_results = analyze_experiment(exp1_df, ['pIPS'], ['LO'], 1)\n",
    "exp2_results = analyze_experiment(exp2_df, ['pIPS', 'aIPS'], ['LO'], 2)\n",
    "\n",
    "# Apply FDR correction\n",
    "for results_df in [exp1_results, exp2_results]:\n",
    "    if not results_df.empty and 'p' in results_df.columns:\n",
    "        p_values = results_df['p'].values\n",
    "        rejected, fdr_corrected = fdrcorrection(p_values)\n",
    "        results_df['p_fdr'] = fdr_corrected\n",
    "\n",
    "# Print and save results\n",
    "print(\"\\nExperiment 1 Results:\")\n",
    "print(exp1_results.round(3).to_string())\n",
    "print(\"\\nExperiment 2 Results:\")\n",
    "print(exp2_results.round(3).to_string())\n",
    "\n",
    "# Save detailed results\n",
    "exp1_results.to_csv(f\"{results_dir}/exp1_ppi_stats.csv\", index=False)\n",
    "exp2_results.to_csv(f\"{output_dir}/exp2_ppi_stats.csv\", index=False)\n",
    "\n",
    "# Save summary for manuscript\n",
    "with open(f\"{results_dir}/ppi_stats_summary.txt\", 'w') as f:\n",
    "    f.write(\"Experiment 1 (Object vs Scramble) PPI Results:\\n\")\n",
    "    for _, row in exp1_results.iterrows():\n",
    "        f.write(f\"\\n{row['seed']} -> {row['target']}\\n\")\n",
    "        f.write(f\"W = {row['W']:.0f}, p = {row['p']:.3f} (FDR p = {row['p_fdr']:.3f}), d = {row['d']:.2f}\\n\")\n",
    "        f.write(f\"Mean ± SEM: {row['mean']:.3f} ± {row['sem']:.3f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\nExperiment 2 (Tools vs Nontools) PPI Results:\\n\")\n",
    "    for _, row in exp2_results.iterrows():\n",
    "        f.write(f\"\\n{row['seed']} -> {row['target']} ({row['condition']})\\n\")\n",
    "        f.write(f\"W = {row['W']:.0f}, p = {row['p']:.3f} (FDR p = {row['p_fdr']:.3f}), d = {row['d']:.2f}\\n\")\n",
    "        f.write(f\"Mean ± SEM: {row['mean']:.3f} ± {row['sem']:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## exp 1 GCA - univariate analysis with correction\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# File paths\n",
    "base_dir = '/user_data/csimmon2/git_repos/ptoc'\n",
    "results_dir = f\"{base_dir}/results\"\n",
    "fig_dir = f\"{results_dir}/gca\"\n",
    "\n",
    "# Read the existing summary table\n",
    "summary_table_combined = pd.read_csv(f\"{fig_dir}/gca_summary_table_combined.csv\")\n",
    "\n",
    "# Apply FDR correction\n",
    "p_values = summary_table_combined['p_value'].values\n",
    "rejected, p_corrected = fdrcorrection(p_values, alpha=0.05, method='indep')\n",
    "\n",
    "# Update table with FDR results\n",
    "summary_table_combined['p_value_fdr'] = p_corrected\n",
    "summary_table_combined['significant_fdr'] = rejected\n",
    "\n",
    "# Save updated results\n",
    "summary_table_combined.to_csv(f\"{fig_dir}/gca_summary_table_combined_fdr.csv\", index=False)\n",
    "\n",
    "# Load t-test results from text file\n",
    "with open(f\"{fig_dir}/gca_roi_pair_combined_comparison_results.txt\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract p-values (assuming they're in the same order as your original script)\n",
    "t_test_pvals = []\n",
    "for line in lines:\n",
    "    if line.startswith('p-value:'):\n",
    "        t_test_pvals.append(float(line.split(': ')[1].strip()))\n",
    "\n",
    "# Apply FDR to t-tests\n",
    "rejected_t, p_corrected_t = fdrcorrection(t_test_pvals, alpha=0.05, method='indep')\n",
    "\n",
    "# Save FDR-corrected t-test results\n",
    "with open(f\"{fig_dir}/gca_roi_pair_combined_comparison_results_fdr.txt\", 'w') as f:\n",
    "    f.write(\"FDR-corrected p-values for paired t-tests:\\n\\n\")\n",
    "    f.write(f\"lpIPS-lLO vs rpIPS-lLO (Object): p_fdr = {p_corrected_t[0]:.4f}\\n\")\n",
    "    f.write(f\"lpIPS-rLO vs rpIPS-rLO (Object): p_fdr = {p_corrected_t[1]:.4f}\\n\")\n",
    "    f.write(f\"lpIPS-lLO vs rpIPS-lLO (Scramble): p_fdr = {p_corrected_t[2]:.4f}\\n\")\n",
    "    f.write(f\"lpIPS-rLO vs rpIPS-rLO (Scramble): p_fdr = {p_corrected_t[3]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original summary table:\n",
      "  origin target condition  Mean f_diff  Std f_diff  W_statistic  p_value  \\\n",
      "0  lpIPS    lLO    Object         7.71       11.70         21.0  0.00169   \n",
      "1  lpIPS    rLO    Object         7.49        9.01         10.0  0.00016   \n",
      "2  rpIPS    lLO    Object         1.82        8.12         61.0  0.18187   \n",
      "3  rpIPS    rLO    Object         1.58        9.33         66.0  0.25793   \n",
      "4  lpIPS    lLO  Scramble         1.05        3.73         71.0  0.35246   \n",
      "5  lpIPS    rLO  Scramble         0.82        6.17         65.0  0.24125   \n",
      "6  rpIPS    lLO  Scramble         0.63        5.05         89.0  0.82878   \n",
      "7  rpIPS    rLO  Scramble         0.79        4.10         79.0  0.54122   \n",
      "\n",
      "   Effect size  significant  \n",
      "0         0.93         True  \n",
      "1         1.18         True  \n",
      "2         0.32        False  \n",
      "3         0.24        False  \n",
      "4         0.40        False  \n",
      "5         0.19        False  \n",
      "6         0.18        False  \n",
      "7         0.27        False  \n",
      "\n",
      "After FDR correction:\n",
      "  origin target condition  Mean f_diff  Std f_diff  W_statistic  p_value  \\\n",
      "0  lpIPS    lLO    Object         7.71       11.70         21.0  0.00169   \n",
      "1  lpIPS    rLO    Object         7.49        9.01         10.0  0.00016   \n",
      "2  rpIPS    lLO    Object         1.82        8.12         61.0  0.18187   \n",
      "3  rpIPS    rLO    Object         1.58        9.33         66.0  0.25793   \n",
      "4  lpIPS    lLO  Scramble         1.05        3.73         71.0  0.35246   \n",
      "5  lpIPS    rLO  Scramble         0.82        6.17         65.0  0.24125   \n",
      "6  rpIPS    lLO  Scramble         0.63        5.05         89.0  0.82878   \n",
      "7  rpIPS    rLO  Scramble         0.79        4.10         79.0  0.54122   \n",
      "\n",
      "   Effect size  significant  p_value_fdr  significant_fdr  \n",
      "0         0.93         True     0.006760             True  \n",
      "1         1.18         True     0.001280             True  \n",
      "2         0.32        False     0.412688            False  \n",
      "3         0.24        False     0.412688            False  \n",
      "4         0.40        False     0.469947            False  \n",
      "5         0.19        False     0.412688            False  \n",
      "6         0.18        False     0.828780            False  \n",
      "7         0.27        False     0.618537            False  \n",
      "\n",
      "Saved to: /user_data/csimmon2/git_repos/ptoc/results/gca/gca_summary_table_combined_fdr.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# File paths\n",
    "base_dir = '/user_data/csimmon2/git_repos/ptoc'\n",
    "results_dir = f\"{base_dir}/results\"\n",
    "fig_dir = f\"{results_dir}/gca\"\n",
    "\n",
    "# Read the existing summary table\n",
    "summary_table_combined = pd.read_csv(f\"{fig_dir}/gca_summary_table_combined.csv\")\n",
    "print(\"Original summary table:\")\n",
    "print(summary_table_combined)\n",
    "\n",
    "# Apply FDR correction\n",
    "p_values = summary_table_combined['p_value'].values\n",
    "rejected, p_corrected = fdrcorrection(p_values, alpha=0.05, method='indep')\n",
    "\n",
    "# Update and display results\n",
    "summary_table_combined['p_value_fdr'] = p_corrected\n",
    "summary_table_combined['significant_fdr'] = rejected\n",
    "print(\"\\nAfter FDR correction:\")\n",
    "print(summary_table_combined)\n",
    "\n",
    "# Save updated results\n",
    "output_path = f\"{fig_dir}/gca_summary_table_combined_fdr.csv\"\n",
    "summary_table_combined.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/lab_data/behrmannlab/vlad/ptoc/sub-spaceloc2015/ses-01/derivatives/gca/combined_object_pIPS_left_mni.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nibabel/loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/lab_data/behrmannlab/vlad/ptoc/sub-spaceloc2015/ses-01/derivatives/gca/combined_object_pIPS_left_mni.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m subjects \u001b[38;5;241m=\u001b[39m [sub\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(base_path) \u001b[38;5;28;01mif\u001b[39;00m sub\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub-\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Run analysis\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m results, anova \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_gca\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[1;32m     81\u001b[0m results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/gca_stats.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[14], line 32\u001b[0m, in \u001b[0;36manalyze_gca\u001b[0;34m(subjects, rois, targets)\u001b[0m\n\u001b[1;32m     30\u001b[0m values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m subjects:\n\u001b[0;32m---> 32\u001b[0m     roi_val \u001b[38;5;241m=\u001b[39m \u001b[43mextract_roi_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(roi_val)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Store for ANOVA\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mextract_roi_values\u001b[0;34m(sub_id, roi, condition)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extract GCA values from ROI nifti\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sub-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/ses-01/derivatives/gca/combined_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcondition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mni.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 16\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(img\u001b[38;5;241m.\u001b[39mget_fdata())\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/nibabel/loadsave.py:102\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/lab_data/behrmannlab/vlad/ptoc/sub-spaceloc2015/ses-01/derivatives/gca/combined_object_pIPS_left_mni.nii.gz'"
     ]
    }
   ],
   "source": [
    "# exp 1 - extract gca summary\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "# Base paths\n",
    "base_path = '/lab_data/behrmannlab/vlad/ptoc'\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "\n",
    "def extract_roi_values(sub_id, roi, condition='object'):\n",
    "    \"\"\"Extract GCA values from ROI nifti\"\"\"\n",
    "    filepath = f'{base_path}/sub-{sub_id}/ses-01/derivatives/gca/combined_{condition}_{roi}_mni.nii.gz'\n",
    "    img = nib.load(filepath)\n",
    "    return np.mean(img.get_fdata()) # Or other extraction method based on your ROI definition\n",
    "\n",
    "def calculate_effect_size(data):\n",
    "    \"\"\"Calculate r effect size from Wilcoxon test\"\"\"\n",
    "    return np.abs(stats.wilcoxon(data)[0]) / np.sqrt(len(data) * 2)\n",
    "\n",
    "def analyze_gca(subjects, rois=['pIPS_left', 'pIPS_right'], targets=['LO_left', 'LO_right']):\n",
    "    results = []\n",
    "    data_for_anova = []\n",
    "    \n",
    "    # Extract values and run tests\n",
    "    for roi in rois:\n",
    "        for target in targets:\n",
    "            values = []\n",
    "            for sub in subjects:\n",
    "                roi_val = extract_roi_values(sub, roi)\n",
    "                values.append(roi_val)\n",
    "                \n",
    "                # Store for ANOVA\n",
    "                data_for_anova.append({\n",
    "                    'subject': sub,\n",
    "                    'ROI': roi.split('_')[0],\n",
    "                    'hemisphere': roi.split('_')[1],\n",
    "                    'target': target,\n",
    "                    'value': roi_val\n",
    "                })\n",
    "            \n",
    "            # Wilcoxon test against 0\n",
    "            w_stat, p_val = stats.wilcoxon(values)\n",
    "            effect_r = calculate_effect_size(values)\n",
    "            \n",
    "            results.append({\n",
    "                'seed': roi,\n",
    "                'target': target,\n",
    "                'W': w_stat,\n",
    "                'p': p_val,\n",
    "                'r': effect_r,\n",
    "                'mean': np.mean(values),\n",
    "                'sem': stats.sem(values)\n",
    "            })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # FDR correction\n",
    "    _, fdr_corrected = fdrcorrection(results_df['p'])\n",
    "    results_df['p_fdr'] = fdr_corrected\n",
    "    \n",
    "    # ANOVA\n",
    "    anova_df = pd.DataFrame(data_for_anova)\n",
    "    aov = pg.rm_anova(data=anova_df,\n",
    "                      dv='value',\n",
    "                      within=['ROI', 'hemisphere'],\n",
    "                      subject='subject')\n",
    "    \n",
    "    return results_df, aov\n",
    "\n",
    "# Get subject list\n",
    "subjects = [sub.replace('sub-', '') for sub in os.listdir(base_path) if sub.startswith('sub-')]\n",
    "\n",
    "# Run analysis\n",
    "results, anova = analyze_gca(subjects)\n",
    "\n",
    "# Save results\n",
    "results.to_csv(f\"{results_dir}/gca_stats.csv\", index=False)\n",
    "anova.to_csv(f\"{results_dir}/gca_anova.csv\", index=False)\n",
    "\n",
    "# Print formatted results\n",
    "print(\"\\nGCA Results:\")\n",
    "print(results.round(3).to_string())\n",
    "print(\"\\nANOVA Results:\")\n",
    "print(anova.round(3).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
