{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Correlation Analysis: Testing Dorsal Independence\n",
    "\n",
    "Analysis of pIPS connectivity after regressing out ventral (LO) influence.\n",
    "\n",
    "**Research Question**: Is dorsal pathway connectivity during object viewing independent of ventral pathway activity, or does it represent passive spillover?\n",
    "\n",
    "**Approach**: Compare original pIPS FC maps with 'cleaned' pIPS FC maps (ventral variance removed) to assess:\n",
    "1. How much connectivity survives the cleaning process\n",
    "2. Spatial patterns of remaining connectivity \n",
    "3. Changes in dorsal-ventral overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nilearn import image, plotting, datasets\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from scipy import stats\n",
    "from sklearn.metrics import jaccard_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [

# Set up paths
study_dir = "/lab_data/behrmannlab/vlad/ptoc"
results_dir = "/user_data/csimmon2/git_repos/ptoc/results"
curr_dir = "/user_data/csimmon2/git_repos/ptoc"

# Load subject info
sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')
subjects = sub_info[sub_info['group'] == 'control']['sub'].tolist()

print(f"Found {len(subjects)} control subjects")

#%% Helper Functions

def load_fc_maps(subjects, analysis_type, roi, hemisphere, task='loc'):
    """Load FC maps for all subjects"""
    maps = []
    valid_subjects = []
    
    for sub in subjects:
        if analysis_type == 'original':
            filepath = f"{study_dir}/{sub}/ses-01/derivatives/fc_mni/{sub}_{roi}_{hemisphere}_{task}_fc_mni.nii.gz"
        elif analysis_type == 'cleaned':
            filepath = f"{study_dir}/{sub}/ses-01/derivatives/fc_mni/{sub}_{roi}_clean_{hemisphere}_{task}_fc_mni.nii.gz"
        
        if os.path.exists(filepath):
            maps.append(filepath)
            valid_subjects.append(sub)
        else:
            print(f"Missing: {filepath}")
    
    print(f"Found {len(maps)} {analysis_type} {roi} {hemisphere} maps")
    return maps, valid_subjects

def compute_group_stats(maps, mask=None):
    """Compute group-level statistics"""
    if not maps:
        return None
        
    # Load all maps
    imgs = [nib.load(map_path) for map_path in maps]
    
    # Compute one-sample t-test
    group_img = image.mean_img(imgs)
    
    # Convert to z-scores if needed
    if mask is not None:
        masker = NiftiMasker(mask_img=mask)
        data = masker.fit_transform(imgs)
        t_stats, p_vals = stats.ttest_1samp(data, 0, axis=0)
        t_img = masker.inverse_transform(t_stats)
        return group_img, t_img
    else:
        return group_img, None

def compute_dice_coefficient(img1, img2, threshold=2.3):
    """Compute Dice coefficient between two statistical maps"""
    # Threshold images
    mask1 = image.math_img(f'img > {threshold}', img=img1)
    mask2 = image.math_img(f'img > {threshold}', img=img2)
    
    # Get binary arrays
    data1 = mask1.get_fdata().flatten()
    data2 = mask2.get_fdata().flatten()
    
    # Remove NaN values
    valid = ~(np.isnan(data1) | np.isnan(data2))
    data1, data2 = data1[valid], data2[valid]
    
    # Compute Dice coefficient
    intersection = np.sum(data1 * data2)
    dice = (2 * intersection) / (np.sum(data1) + np.sum(data2))
    
    return dice

#%% Load Data

print("Loading FC maps...")

# Load original pIPS maps
pips_orig_left, subs_pips_orig_left = load_fc_maps(subjects, 'original', 'pIPS', 'left')
pips_orig_right, subs_pips_orig_right = load_fc_maps(subjects, 'original', 'pIPS', 'right')

# Load cleaned pIPS maps  
pips_clean_left, subs_pips_clean_left = load_fc_maps(subjects, 'cleaned', 'pIPS', 'left')
pips_clean_right, subs_pips_clean_right = load_fc_maps(subjects, 'cleaned', 'pIPS', 'right')

# Load LO maps for comparison
lo_orig_left, subs_lo_left = load_fc_maps(subjects, 'original', 'LO', 'left')
lo_orig_right, subs_lo_right = load_fc_maps(subjects, 'original', 'LO', 'right')

#%% Compute Group Statistics

print("Computing group statistics...")

# Get MNI brain mask
mni_mask = datasets.load_mni152_brain_mask()

# Original pIPS
pips_orig_left_mean, pips_orig_left_t = compute_group_stats(pips_orig_left, mni_mask)
pips_orig_right_mean, pips_orig_right_t = compute_group_stats(pips_orig_right, mni_mask)

# Cleaned pIPS
pips_clean_left_mean, pips_clean_left_t = compute_group_stats(pips_clean_left, mni_mask)
pips_clean_right_mean, pips_clean_right_t = compute_group_stats(pips_clean_right, mni_mask)

# LO for comparison
lo_left_mean, lo_left_t = compute_group_stats(lo_orig_left, mni_mask)
lo_right_mean, lo_right_t = compute_group_stats(lo_orig_right, mni_mask)

#%% Compute Difference Maps

print("Computing difference maps...")

# Difference: Original - Cleaned (what was removed)
if pips_orig_left_mean and pips_clean_left_mean:
    diff_left = image.math_img('img1 - img2', 
                               img1=pips_orig_left_mean, 
                               img2=pips_clean_left_mean)

if pips_orig_right_mean and pips_clean_right_mean:
    diff_right = image.math_img('img1 - img2', 
                                img1=pips_orig_right_mean, 
                                img2=pips_clean_right_mean)

#%% Visualization

print("Creating visualizations...")

# Set up figure
fig = plt.figure(figsize=(20, 24))

# Left Hemisphere Analysis
if pips_orig_left_mean and pips_clean_left_mean:
    # Original pIPS Left
    ax1 = plt.subplot(6, 2, 1)
    plotting.plot_stat_map(pips_orig_left_mean, 
                          title='Original pIPS Left FC',
                          threshold=0.1,
                          axes=ax1,
                          colorbar=True)
    
    # Cleaned pIPS Left  
    ax2 = plt.subplot(6, 2, 2)
    plotting.plot_stat_map(pips_clean_left_mean,
                          title='Cleaned pIPS Left FC', 
                          threshold=0.1,
                          axes=ax2,
                          colorbar=True)
    
    # Difference Left
    ax3 = plt.subplot(6, 2, 3)
    plotting.plot_stat_map(diff_left,
                          title='Difference Left (Original - Cleaned)',
                          threshold=0.05,
                          axes=ax3,
                          colorbar=True,
                          cmap='RdBu_r')

# Right Hemisphere Analysis  
if pips_orig_right_mean and pips_clean_right_mean:
    # Original pIPS Right
    ax4 = plt.subplot(6, 2, 4)
    plotting.plot_stat_map(pips_orig_right_mean,
                          title='Original pIPS Right FC',
                          threshold=0.1,
                          axes=ax4,
                          colorbar=True)
    
    # Cleaned pIPS Right
    ax5 = plt.subplot(6, 2, 5)  
    plotting.plot_stat_map(pips_clean_right_mean,
                          title='Cleaned pIPS Right FC',
                          threshold=0.1,
                          axes=ax5,
                          colorbar=True)
    
    # Difference Right
    ax6 = plt.subplot(6, 2, 6)
    plotting.plot_stat_map(diff_right,
                          title='Difference Right (Original - Cleaned)', 
                          threshold=0.05,
                          axes=ax6,
                          colorbar=True,
                          cmap='RdBu_r')

# LO Reference Maps
if lo_left_mean:
    ax7 = plt.subplot(6, 2, 7)
    plotting.plot_stat_map(lo_left_mean,
                          title='LO Left FC (Reference)',
                          threshold=0.1,
                          axes=ax7,
                          colorbar=True)

if lo_right_mean:
    ax8 = plt.subplot(6, 2, 8)
    plotting.plot_stat_map(lo_right_mean,
                          title='LO Right FC (Reference)',
                          threshold=0.1,
                          axes=ax8,
                          colorbar=True)

plt.tight_layout()
plt.savefig(f'{results_dir}/partial_correlation_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

#%% Quantitative Analysis

print("\n" + "="*50)
print("QUANTITATIVE ANALYSIS")
print("="*50)

# Compute overlap metrics
results_df = pd.DataFrame()

hemispheres = ['left', 'right']
for hemi in hemispheres:
    if hemi == 'left':
        orig_mean = pips_orig_left_mean
        clean_mean = pips_clean_left_mean  
        lo_mean = lo_left_mean
        orig_t = pips_orig_left_t
        clean_t = pips_clean_left_t
    else:
        orig_mean = pips_orig_right_mean
        clean_mean = pips_clean_right_mean
        lo_mean = lo_right_mean
        orig_t = pips_orig_right_t
        clean_t = pips_clean_right_t
    
    if orig_mean and clean_mean and lo_mean:
        # Dice coefficients
        dice_orig_lo = compute_dice_coefficient(orig_mean, lo_mean)
        dice_clean_lo = compute_dice_coefficient(clean_mean, lo_mean)
        dice_orig_clean = compute_dice_coefficient(orig_mean, clean_mean)
        
        # Count significant voxels (if t-stats available)
        if orig_t and clean_t:
            orig_sig_voxels = np.sum(np.abs(orig_t.get_fdata()) > 2.3)
            clean_sig_voxels = np.sum(np.abs(clean_t.get_fdata()) > 2.3)
            percent_retained = (clean_sig_voxels / orig_sig_voxels) * 100 if orig_sig_voxels > 0 else 0
        else:
            orig_sig_voxels = clean_sig_voxels = percent_retained = np.nan
        
        # Store results
        results_df = pd.concat([results_df, pd.DataFrame({
            'hemisphere': [hemi],
            'dice_original_LO': [dice_orig_lo],
            'dice_cleaned_LO': [dice_clean_lo], 
            'dice_original_cleaned': [dice_orig_clean],
            'orig_sig_voxels': [orig_sig_voxels],
            'clean_sig_voxels': [clean_sig_voxels],
            'percent_connectivity_retained': [percent_retained]
        })], ignore_index=True)

# Display results
print("\nOVERLAP ANALYSIS:")
print(results_df.round(3))

# Statistical significance of changes
print("\nSTATISTICAL SUMMARY:")
for hemi in hemispheres:
    hemi_data = results_df[results_df['hemisphere'] == hemi]
    if not hemi_data.empty:
        row = hemi_data.iloc[0]
        print(f"\n{hemi.upper()} HEMISPHERE:")
        print(f"  Original pIPS-LO overlap: {row['dice_original_LO']:.3f}")
        print(f"  Cleaned pIPS-LO overlap:  {row['dice_cleaned_LO']:.3f}")
        print(f"  Reduction in overlap:     {row['dice_original_LO'] - row['dice_cleaned_LO']:.3f}")
        print(f"  Connectivity retained:    {row['percent_connectivity_retained']:.1f}%")

#%% Save Results

results_df.to_csv(f'{results_dir}/partial_correlation_metrics.csv', index=False)
print(f"\nResults saved to: {results_dir}/partial_correlation_metrics.csv")

#%% Interpretation

print("\n" + "="*50) 
print("INTERPRETATION GUIDE")
print("="*50)

print("""
KEY QUESTIONS TO ASK:

1. CONNECTIVITY RETENTION:
   - If >70% connectivity retained → Strong evidence for dorsal independence
   - If 30-70% retained → Moderate independence with some ventral dependence  
   - If <30% retained → Suggests significant ventral dependence

2. OVERLAP REDUCTION:
   - Large reduction in pIPS-LO overlap → Successful removal of shared variance
   - Small reduction → Limited shared variance to begin with

3. SPATIAL PATTERNS:
   - Check difference maps: What regions show largest changes?
   - Are remaining connections in expected dorsal areas?
   - Do cleaned maps still show object-selective patterns?

4. HEMISPHERIC DIFFERENCES:
   - Do left/right show similar patterns?
   - Any hemisphere-specific effects?
""")

print("\nANALYSIS COMPLETE!")
print("Review the visualizations and metrics to determine dorsal pathway independence.")