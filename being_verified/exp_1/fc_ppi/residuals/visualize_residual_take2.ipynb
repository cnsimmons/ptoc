# Updated Visualization Notebook - Consistent with FC/PPI Pipeline
# Run the consistent_threshold_analysis.py script FIRST, then use this notebook

import os
import numpy as np
import pandas as pd
import nibabel as nib
import matplotlib.pyplot as plt
from nilearn import plotting, image

# Set up paths
results_dir = "/user_data/csimmon2/git_repos/ptoc/results"
thresh_dir = f"{results_dir}/partial_correlation_thresh"

print("Loading consistently thresholded results...")

# Load the results from the threshold analysis script
results_df = pd.read_csv(f'{thresh_dir}/retention_analysis_results.csv')
print("\nRETENTION ANALYSIS RESULTS:")
print(results_df.round(3))

# Load thresholded images for visualization
hemispheres = ['left', 'right']
thresh_imgs = {}

for hemi in hemispheres:
    # Load consistently thresholded images (created by threshold script)
    orig_file = f'{thresh_dir}/pIPS_{hemi}_original_thresh.nii.gz'
    clean_file = f'{thresh_dir}/pIPS_{hemi}_cleaned_thresh.nii.gz'
    
    if os.path.exists(orig_file) and os.path.exists(clean_file):
        thresh_imgs[f'orig_{hemi}'] = nib.load(orig_file)
        thresh_imgs[f'clean_{hemi}'] = nib.load(clean_file)
        print(f"Loaded thresholded images for {hemi} hemisphere")
    else:
        print(f"Missing thresholded images for {hemi} hemisphere")

# === MAIN VISUALIZATION ===
print("\nCreating publication-ready visualization...")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

for i, hemi in enumerate(hemispheres):
    if f'orig_{hemi}' in thresh_imgs and f'clean_{hemi}' in thresh_imgs:
        
        # Get retention value for this hemisphere
        hemi_results = results_df[results_df['hemisphere'] == hemi]
        if not hemi_results.empty:
            retention = hemi_results['percent_retained'].iloc[0]
            orig_voxels = hemi_results['orig_sig_voxels'].iloc[0]
            clean_voxels = hemi_results['clean_sig_voxels'].iloc[0]
            
            # Original connectivity
            plotting.plot_stat_map(thresh_imgs[f'orig_{hemi}'], 
                                  axes=axes[i, 0],
                                  title=f'Original pIPS {hemi.title()}\n{orig_voxels:,} significant voxels',
                                  threshold=0.01,  # Small threshold since already thresholded
                                  colorbar=True,
                                  vmax=None)  # Auto-scale
            
            # Cleaned connectivity
            plotting.plot_stat_map(thresh_imgs[f'clean_{hemi}'], 
                                  axes=axes[i, 1],
                                  title=f'Independent pIPS {hemi.title()}\n{clean_voxels:,} voxels ({retention:.1f}% retained)',
                                  threshold=0.01,  # Small threshold since already thresholded  
                                  colorbar=True,
                                  vmax=None)  # Auto-scale

# Add overall title and interpretation
mean_retention = results_df['percent_retained'].mean()
if mean_retention > 70:
    interpretation = "Strong Evidence for Dorsal Independence"
elif mean_retention > 30:
    interpretation = "Moderate Evidence for Dorsal Independence"
else:
    interpretation = "Limited Evidence for Dorsal Independence"

fig.suptitle(f'Partial Correlation Analysis: Testing Dorsal Independence\n{interpretation} (Mean Retention: {mean_retention:.1f}%)', 
             fontsize=14, fontweight='bold', y=0.95)

plt.tight_layout()
plt.savefig(f'{thresh_dir}/final_visualization.png', dpi=300, bbox_inches='tight')
plt.show()

# === QUANTITATIVE SUMMARY ===
print(f"\n{'='*60}")
print("QUANTITATIVE ANALYSIS SUMMARY")
print(f"{'='*60}")

for _, row in results_df.iterrows():
    hemi = row['hemisphere']
    retention = row['percent_retained']
    orig_voxels = row['orig_sig_voxels']
    clean_voxels = row['clean_sig_voxels']
    thresh_val = row['clean_threshold']
    
    print(f"\n{hemi.upper()} HEMISPHERE:")
    print(f"  Original significant voxels: {orig_voxels:,}")
    print(f"  Cleaned significant voxels: {clean_voxels:,}")
    print(f"  Connectivity retention: {retention:.1f}%")
    print(f"  FDR threshold applied: {thresh_val:.3f}")
    
    # Interpretation for this hemisphere
    if retention > 70:
        hemi_interp = "STRONG independence"
    elif retention > 30:
        hemi_interp = "MODERATE independence"
    else:
        hemi_interp = "LIMITED independence"
    print(f"  → {hemi_interp}")

# === METHOD VALIDATION ===
print(f"\n{'='*60}")
print("METHOD VALIDATION")
print(f"{'='*60}")

print("✓ Same FDR correction (α=0.05) as FC/PPI analyses")
print("✓ Same cluster threshold (>5 voxels) as FC/PPI analyses") 
print("✓ Same z-scoring procedure as FC/PPI analyses")
print("✓ Same positive-values-only approach as FC/PPI analyses")
print("✓ Same voxel counting method as standard neuroimaging practice")

# === SCIENTIFIC CONCLUSION ===
print(f"\n{'='*60}")
print("SCIENTIFIC CONCLUSION")
print(f"{'='*60}")

print(f"Mean connectivity retention across hemispheres: {mean_retention:.1f}%")
print(f"\nInterpretation: {interpretation}")

print(f"\nThis analysis demonstrates that {mean_retention:.1f}% of statistically significant")
print("dorsal pathway connectivity during object viewing persists even after removing")
print("shared variance with ventral pathway activity.")

if mean_retention > 70:
    print("\nThis high retention rate provides strong evidence against the passive")
    print("spillover hypothesis and supports independent dorsal computations during")
    print("object processing.")
elif mean_retention > 30:
    print("\nThis moderate retention rate suggests dorsal pathways have some")
    print("independent processing capabilities but also significant dependence")
    print("on ventral pathway activity.")
else:
    print("\nThis low retention rate suggests significant dependence on ventral") 
    print("pathway activity, with limited independent dorsal processing.")

print(f"\nResults are consistent with established FC/PPI analysis pipeline")
print(f"and use identical statistical thresholding procedures.")

# Save final summary
summary_dict = {
    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'n_subjects_left': results_df[results_df['hemisphere']=='left']['n_subjects'].iloc[0],
    'n_subjects_right': results_df[results_df['hemisphere']=='right']['n_subjects'].iloc[0],
    'retention_left': results_df[results_df['hemisphere']=='left']['percent_retained'].iloc[0],
    'retention_right': results_df[results_df['hemisphere']=='right']['percent_retained'].iloc[0], 
    'mean_retention': mean_retention,
    'interpretation': interpretation,
    'fdr_alpha': 0.05,
    'cluster_threshold': 5
}

summary_df = pd.DataFrame([summary_dict])
summary_df.to_csv(f'{thresh_dir}/analysis_summary.csv', index=False)

print(f"\nComplete results saved to: {thresh_dir}/")
print("Files generated:")
print(f"  - retention_analysis_results.csv")
print(f"  - analysis_summary.csv") 
print(f"  - final_visualization.png")
print(f"  - pIPS_left_comparison.png")
print(f"  - pIPS_right_comparison.png")