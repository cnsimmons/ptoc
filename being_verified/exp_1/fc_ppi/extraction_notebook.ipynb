{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK FILE AVAILABILITY\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Import parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "\n",
    "# Load subject information\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "subjects = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "\n",
    "# Define the ROIs we're interested in\n",
    "rois = ['pIPS', 'LO', 'PFS', 'aIPS']\n",
    "hemispheres = ['left', 'right']\n",
    "analysis_types = ['fc', 'ppi']  # Check both fc and ppi\n",
    "task = 'loc'\n",
    "\n",
    "# Check all subjects\n",
    "summary = {}\n",
    "file_counts = {analysis: {roi: {hemi: 0 for hemi in hemispheres} for roi in rois} for analysis in analysis_types}\n",
    "\n",
    "for subject in subjects:\n",
    "    print(f\"\\nChecking available files for subject: {subject}\")\n",
    "    \n",
    "    # Check for expected files\n",
    "    expected_files = []\n",
    "    found_files = []\n",
    "    missing_files = []\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        print(f\"\\n  {analysis_type.upper()} files:\")\n",
    "        \n",
    "        for roi in rois:\n",
    "            for hemisphere in hemispheres:\n",
    "                filename = f\"{subject}_{roi}_{hemisphere}_{task}_{analysis_type}.nii.gz\"\n",
    "                filepath = os.path.join(study_dir, subject, 'ses-01', 'derivatives', 'fc', filename)\n",
    "                expected_files.append(filepath)\n",
    "                \n",
    "                if os.path.exists(filepath):\n",
    "                    found_files.append(filepath)\n",
    "                    file_counts[analysis_type][roi][hemisphere] += 1\n",
    "                    print(f\"  ✓ Found: {filename}\")\n",
    "                else:\n",
    "                    missing_files.append(filepath)\n",
    "                    print(f\"  ✗ Missing: {filename}\")\n",
    "    \n",
    "    # Also list all available files in the directory\n",
    "    fc_dir = os.path.join(study_dir, subject, 'ses-01', 'derivatives', 'fc')\n",
    "    if os.path.exists(fc_dir):\n",
    "        all_files = [f for f in os.listdir(fc_dir) if f.endswith('.nii.gz')]\n",
    "        print(f\"\\n  Found {len(all_files)} total .nii.gz files in directory\")\n",
    "    else:\n",
    "        print(f\"\\n  Directory does not exist: {fc_dir}\")\n",
    "        all_files = []\n",
    "    \n",
    "    # Save summary for this subject\n",
    "    summary[subject] = {\n",
    "        'total_expected': len(expected_files),\n",
    "        'total_found': len(found_files),\n",
    "        'total_in_dir': len(all_files)\n",
    "    }\n",
    "\n",
    "# Print overall summary\n",
    "print(\"\\n==== SUMMARY ====\")\n",
    "print(f\"Total subjects checked: {len(subjects)}\")\n",
    "\n",
    "# Print table of ROI availability for both analysis types\n",
    "for analysis_type in analysis_types:\n",
    "    print(f\"\\n{analysis_type.upper()} ROI availability across subjects:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'ROI':<10} {'Left':<10} {'Right':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    for roi in rois:\n",
    "        left_count = file_counts[analysis_type][roi]['left']\n",
    "        right_count = file_counts[analysis_type][roi]['right']\n",
    "        print(f\"{roi:<10} {left_count:<10} {right_count:<10}\")\n",
    "\n",
    "# Print subject-level summary\n",
    "print(\"\\nSubject-level summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Subject':<10} {'Expected':<10} {'Found':<10} {'Total Files':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for subject, stats in summary.items():\n",
    "    print(f\"{subject:<10} {stats['total_expected']:<10} {stats['total_found']:<10} {stats['total_in_dir']:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting connectivity extraction for fc, ppi...\n",
      "\n",
      "=======================================\n",
      "Processing subject: sub-025\n",
      "=======================================\n",
      "\n",
      "Processing fc analysis for sub-025\n",
      "Found 8 fc seed files for sub-025\n",
      "  Extracted: pIPS-left → LO-left: 0.1770\n",
      "  Extracted: pIPS-left → LO-right: 0.1502\n"
     ]
    }
   ],
   "source": [
    "# ROI functional connectivity extraction script\n",
    "# better run as a single script as it takes a while to run\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Import parameters\n",
    "curr_dir = f'/user_data/csimmon2/git_repos/ptoc'\n",
    "sys.path.insert(0, curr_dir)\n",
    "import ptoc_params as params\n",
    "\n",
    "# Set up directories and parameters\n",
    "study = 'ptoc'\n",
    "study_dir = f\"/lab_data/behrmannlab/vlad/{study}\"\n",
    "results_dir = '/user_data/csimmon2/git_repos/ptoc/results'\n",
    "raw_dir = params.raw_dir\n",
    "\n",
    "# Load subject information\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "subjects = sub_info[sub_info['group'] == 'control']['sub'].tolist()\n",
    "\n",
    "# Define the ROIs we're interested in\n",
    "rois = ['pIPS', 'LO', 'PFS', 'aIPS']\n",
    "hemispheres = ['left', 'right']\n",
    "analysis_types = ['fc', 'ppi']  # Process both fc and ppi\n",
    "task = 'loc'\n",
    "\n",
    "def create_roi_masker(coords):\n",
    "    return NiftiSpheresMasker([tuple(coords)], radius=6)\n",
    "\n",
    "def extract_mean_activation(results_img, roi_masker):\n",
    "    roi_data = roi_masker.fit_transform(results_img)\n",
    "    return np.mean(roi_data)\n",
    "\n",
    "def process_subjects():\n",
    "    results = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    for subject in subjects:\n",
    "        print(f\"\\n=======================================\")\n",
    "        print(f\"Processing subject: {subject}\")\n",
    "        print(f\"=======================================\")\n",
    "            \n",
    "        # Load ROI coordinates for all ROIs\n",
    "        roi_dir = f'{study_dir}/{subject}/ses-01/derivatives/rois'\n",
    "        roi_coords_file = f'{roi_dir}/spheres/sphere_coords_hemisphere.csv'\n",
    "        \n",
    "        if not os.path.exists(roi_coords_file):\n",
    "            print(f\"No coordinates file found for {subject}\")\n",
    "            continue\n",
    "            \n",
    "        roi_coords = pd.read_csv(roi_coords_file)\n",
    "        \n",
    "        # Create ROI maskers for all ROIs\n",
    "        roi_maskers = {}\n",
    "        for roi in rois:\n",
    "            for hemisphere in hemispheres:\n",
    "                curr_coords = roi_coords[\n",
    "                    (roi_coords['task'] == task) & \n",
    "                    (roi_coords['roi'] == roi) &\n",
    "                    (roi_coords['hemisphere'] == hemisphere)\n",
    "                ]\n",
    "                \n",
    "                if curr_coords.empty:\n",
    "                    print(f\"No coordinates found for {roi}, {hemisphere}, {task}\")\n",
    "                    continue\n",
    "                \n",
    "                coords = curr_coords[['x', 'y', 'z']].values.tolist()[0]\n",
    "                roi_maskers[(roi, hemisphere)] = create_roi_masker(coords)\n",
    "        \n",
    "        # Process each analysis type\n",
    "        for curr_analysis in analysis_types:\n",
    "            print(f\"\\nProcessing {curr_analysis} analysis for {subject}\")\n",
    "            \n",
    "            # Check for seed files\n",
    "            seed_files = []\n",
    "            for roi in rois:\n",
    "                for hemisphere in hemispheres:\n",
    "                    filename = f\"{subject}_{roi}_{hemisphere}_{task}_{curr_analysis}.nii.gz\"\n",
    "                    filepath = os.path.join(study_dir, subject, 'ses-01', 'derivatives', 'fc', filename)\n",
    "                    if os.path.exists(filepath):\n",
    "                        seed_files.append((roi, hemisphere, filepath))\n",
    "                    else:\n",
    "                        print(f\"File not found: {filename}\")\n",
    "            \n",
    "            if not seed_files:\n",
    "                print(f\"No {curr_analysis} seed files found for {subject}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Found {len(seed_files)} {curr_analysis} seed files for {subject}\")\n",
    "            \n",
    "            # Process each seed file\n",
    "            for seed_roi, seed_hemisphere, seed_file_path in seed_files:\n",
    "                # Load the seed results image\n",
    "                seed_img = nib.load(seed_file_path)\n",
    "                \n",
    "                # Extract mean activation in all target ROIs (except the seed ROI)\n",
    "                for target_roi in rois:\n",
    "                    # Skip self-connections\n",
    "                    if target_roi == seed_roi:\n",
    "                        continue\n",
    "                        \n",
    "                    for target_hemisphere in hemispheres:\n",
    "                        target_masker = roi_maskers.get((target_roi, target_hemisphere))\n",
    "                        if target_masker is None:\n",
    "                            continue\n",
    "                        \n",
    "                        # Extract mean activation\n",
    "                        try:\n",
    "                            mean_activation = extract_mean_activation(seed_img, target_masker)\n",
    "                            processed_count += 1\n",
    "                            \n",
    "                            # Store the results\n",
    "                            results.append({\n",
    "                                'subject': subject,\n",
    "                                'seed_roi': seed_roi,\n",
    "                                'seed_hemisphere': seed_hemisphere,\n",
    "                                'target_roi': target_roi,\n",
    "                                'target_hemisphere': target_hemisphere,\n",
    "                                'task': task,\n",
    "                                'analysis': curr_analysis,\n",
    "                                'mean_activation': mean_activation\n",
    "                            })\n",
    "                            \n",
    "                            print(f\"  Extracted: {seed_roi}-{seed_hemisphere} → {target_roi}-{target_hemisphere}: {mean_activation:.4f}\")\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error extracting activation for {seed_roi}-{seed_hemisphere} to {target_roi}-{target_hemisphere}: {e}\")\n",
    "    \n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        print(\"No results were generated. Check the script output for errors.\")\n",
    "        return None\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    output_file = os.path.join(results_dir, 'fc_ppi', 'all_roi_connectivity.csv')\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    print(f\"Total connections processed: {processed_count}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Run the processing\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Starting connectivity extraction for {', '.join(analysis_types)}...\")\n",
    "    start_time = time.time()\n",
    "    results_df = process_subjects()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    if results_df is not None:\n",
    "        print(f\"Processing completed in {(end_time - start_time)/60:.2f} minutes\")\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nSummary of extracted data:\")\n",
    "        print(f\"Total subjects: {results_df['subject'].nunique()}\")\n",
    "        print(f\"Total connections: {len(results_df)}\")\n",
    "        \n",
    "        # Count by analysis type\n",
    "        fc_count = len(results_df[results_df['analysis'] == 'fc'])\n",
    "        ppi_count = len(results_df[results_df['analysis'] == 'ppi'])\n",
    "        print(f\"FC connections: {fc_count}\")\n",
    "        print(f\"PPI connections: {ppi_count}\")\n",
    "        \n",
    "        # Connections by ROI pair\n",
    "        print(\"\\nConnections by ROI pair:\")\n",
    "        for seed_roi in rois:\n",
    "            for target_roi in rois:\n",
    "                if seed_roi != target_roi:\n",
    "                    count = len(results_df[(results_df['seed_roi'] == seed_roi) & \n",
    "                                          (results_df['target_roi'] == target_roi)])\n",
    "                    print(f\"{seed_roi} → {target_roi}: {count}\")\n",
    "    else:\n",
    "        print(\"No results were generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiak_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
